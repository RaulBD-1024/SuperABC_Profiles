"""
S√∫per ABC & Perfiles - App Interactiva
=====================================

Versi√≥n mejorada:
- ABC por contribuci√≥n (el usuario define cortes A/B por criterio)
- Combinaci√≥n de dos criterios en AA..CC
- Resumen extendido (incluye % ventas por categor√≠a)
- Perfiles solicitados (l√≠neas por orden, cubicaje por orden, d√≠as, tabla cruzada)
- CSV export con nombres sanitizados (sin caracteres especiales)
- Generaci√≥n opcional de informe PDF (requiere reportlab + matplotlib)
"""

import io
import unicodedata
import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st

import statsmodels.api as sm
from prophet import Prophet
from prophet.plot import plot_plotly, plot_components_plotly


# Para generar PDF/plots
try:
    import matplotlib.pyplot as plt
    from reportlab.lib.pagesizes import letter
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table
    from reportlab.lib.styles import getSampleStyleSheet
    PDF_LIBS_AVAILABLE = True
except Exception:
    PDF_LIBS_AVAILABLE = False

# -------------------------------
# Utilidades
# -------------------------------

def sanitize_filename(s: str) -> str:
    # elimina acentos y caracteres especiales, deja ascii y guiones bajos
    s = str(s)
    s = unicodedata.normalize('NFKD', s)
    s = s.encode('ascii', 'ignore').decode('ascii')
    s = s.replace(' ', '_')
    allowed = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_-"
    return ''.join(c for c in s if c in allowed)

def sanitize_colnames(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [unicodedata.normalize('NFKD', str(c)).encode('ascii','ignore').decode('ascii') for c in df.columns]
    df.columns = [c.replace(' ', '_') for c in df.columns]
    return df

def minmax_normalize(s: pd.Series) -> pd.Series:
    s = s.fillna(0)
    rng = s.max() - s.min()
    if rng == 0:
        return pd.Series(np.zeros(len(s)), index=s.index)
    return (s - s.min()) / rng

@st.cache_data(show_spinner=False)
def read_excel_bytes(file_bytes: bytes, sheet_name=None) -> pd.DataFrame:
    return pd.read_excel(io.BytesIO(file_bytes), sheet_name=sheet_name, engine='openpyxl')

# ABC por contribuci√≥n acumulada

def safe_col(df: pd.DataFrame, name: str, alt_names=None):
    """Busca una columna tolerando espacios, may√∫sculas/min√∫sculas o nombres alternativos."""
    if alt_names is None:
        alt_names = []
    # Diccionario para b√∫squeda insensible a may√∫sculas/min√∫sculas y espacios
    alt = {c.strip().lower(): c for c in df.columns}
    key = name.strip().lower()
    # Revisar nombre principal
    if key in alt:
        return df[alt[key]]
    # Revisar nombres alternativos
    for alt_name in alt_names:
        k = alt_name.strip().lower()
        if k in alt:
            return df[alt[k]]
    raise KeyError(f"No se encontr√≥ la columna requerida: {name}")


def cycle_count_freq(zone: str) -> str:
    return {'Oro':'Semanal/Mensual','Plata':'Mensual/Trimestral','Bronce':'Trimestral/Semestral'}.get(zone, 'Trimestral')


def abc_by_contribution(series: pd.Series, A_cut: float, B_cut: float) -> pd.Series:
    df_tmp = series.rename('metric').to_frame()
    df_tmp = df_tmp.sort_values('metric', ascending=False)
    total = df_tmp['metric'].sum()
    if total <= 0:
        return pd.Series('C', index=series.index)
    df_tmp['cum_contrib'] = df_tmp['metric'].cumsum() / total
    df_tmp['cls'] = np.where(df_tmp['cum_contrib'] <= A_cut, 'A', np.where(df_tmp['cum_contrib'] <= B_cut, 'B', 'C'))
    return df_tmp['cls'].reindex(series.index)

# Map zone from combined class

def map_zone(clase: str) -> str:
    if clase in {'AA','AB','AC'}:
        return 'Oro'
    if clase in {'BA','BB','BC'}:
        return 'Plata'
    return 'Bronce'

def policy_by_demand(cv: float, intermittency: float) -> str:
    if intermittency >= 0.5:
        return 'RTP-EOQ (items intermitentes)'
    if cv < 0.5:
        return 'ROP-OUL (alta estabilidad)'
    if cv < 1.0:
        return 'ROP-EOQ (variabilidad media)'
    return 'RTP-EOQ (alta variabilidad)'

# Fill rates nuevos (usar guion ASCII)

def target_fill_rate(zone: str) -> str:
    if zone == 'Oro':
        return '99-90%'
    if zone == 'Plata':
        return '89-80%'
    if zone == 'Bronce':
        return '70-80%'
    return '80-90%'

# Week floor
from datetime import datetime

def week_floor(dt: pd.Series) -> pd.Series:
    return dt.dt.to_period('W-MON').dt.start_time

# -------------------------------
# UI
# -------------------------------
st.set_page_config(page_title='S√∫per ABC & Perfiles', layout='wide')
st.title('üì¶ S√∫per ABC Interactivo & Perfiles de √ìrdenes')

st.markdown("""
Bienvenido a la aplicaci√≥n **S√∫per ABC & Perfiles** üöÄ  

Esta herramienta permite analizar los productos de tu portafolio mediante una clasificaci√≥n **S√∫per ABC**, combinando dos criterios (ej. ventas y cubicaje).  
El flujo de uso es el siguiente:

1. **Carga de archivo**: Sube un archivo Excel/CSV con la informaci√≥n de tus productos (ventas, cubicaje, pedidos, etc.).  
2. **Definici√≥n de cortes**: Elige los porcentajes que delimitan las categor√≠as A, B y C seg√∫n tu criterio.  
3. **Clasificaci√≥n S√∫per ABC**: Los productos se clasifican autom√°ticamente en las categor√≠as combinadas **AA..CC**.  
4. **Resumen por categor√≠a**: Se muestra una tabla con:
   - Cantidad de √≠tems por clase  
   - Zona de bodega y pol√≠tica de inventario sugerida  
   - Fill Rate objetivo  
   - **IRA (√çndice de Rotaci√≥n Aceptable)** seg√∫n la clase  
   - Ventas y porcentaje de participaci√≥n  
5. **Perfiles adicionales**: Podr√°s ver indicadores sobre l√≠neas por orden, cubicaje por orden, d√≠as de inventario y tablas cruzadas.  
6. **Exportaci√≥n**: Toda la informaci√≥n puede descargarse en un PDF o CSV para reportes.  

‚ÑπÔ∏è Esta aplicaci√≥n est√° pensada como apoyo para decisiones de **gesti√≥n de inventario y almacenamiento**, facilitando el an√°lisis ABC tradicional y extendido.
""")

# -------------------------------
# Advertencia sobre formato del Excel
# -------------------------------
st.info("""
üìÇ **Configuraci√≥n del archivo Excel requerida:**

El archivo debe contener **exactamente** las siguientes columnas (respetando los nombres, aunque la aplicaci√≥n es tolerante a espacios y may√∫sculas/min√∫sculas):

- `Art√≠culo` ‚Üí Identificador √∫nico del producto  
- `Unid. Vend` ‚Üí Cantidad de unidades vendidas  
- `Monto venta` ‚Üí Monto total de venta  
- `Volumen total (p3) o Volumen total (m3)` ‚Üí Volumen total del producto. Puede estar en **pies¬≥** o **metros¬≥**. La unidad se selecciona en el panel lateral y se convertir√° autom√°ticamente para los c√°lculos internos.  
- `Num. Doc` ‚Üí N√∫mero de documento / pedido  
- `Fecha Doc` ‚Üí Fecha del documento/pedido en formato DD/MM/AAAA. 

‚ö†Ô∏è **Importante:** Si alguna columna no existe o tiene un nombre diferente, la aplicaci√≥n no podr√° procesar los datos correctamente.  
Aseg√∫rate de seleccionar la unidad correcta en la barra lateral para que los c√°lculos de volumen sean consistentes.
""")

with st.sidebar:
    st.header('1) Cargar datos')
    uploaded_file = st.file_uploader('Excel de ventas/ordenes', type=['xlsx','xls'])
    sheet_name = st.text_input('Hoja (opcional)')
    unit_vol = st.selectbox('Unidad de volumen', ['pies3 (p3)','metros3 (m3)'])
    vol_factor = 35.3147 if unit_vol == 'metros3 (m3)' else 1.0

    # Permitir al usuario definir el volumen de una tarima
    default_tarima = 42.38 if unit_vol == 'pies3 (p3)' else 1.2
    vol_tarima = st.number_input(
        'Volumen de una tarima completa',
        min_value=0.01,
        value=default_tarima,
        help='Define el volumen de una tarima en la unidad seleccionada'
    )
    # Guardar en session_state para usarlo en PDF y an√°lisis
    st.session_state['vol_tarima'] = vol_tarima

    st.header('2) Criterios ABC (elige dos)')
    criterios = {
        'Popularidad': 'popularidad',
        'Rotacion': 'rotacion_sem',
        'Ventas': 'ventas',
        'Volumen': 'volumen'
    }
    crit1 = st.selectbox('Criterio 1', list(criterios.keys()), index=0)
    crit2 = st.selectbox('Criterio 2', [c for c in criterios.keys() if c != crit1], index=0)

    st.header('3) Cortes ABC por contribucion (A, B)')
    A_cut_1 = st.slider(f'A (criterio {crit1})', 50, 95, 80) / 100.0
    B_cut_1 = st.slider(f'B (criterio {crit1})', int(A_cut_1*100)+1, 99, 95) / 100.0
    A_cut_2 = st.slider(f'A (criterio {crit2})', 50, 95, 80) / 100.0
    B_cut_2 = st.slider(f'B (criterio {crit2})', int(A_cut_2*100)+1, 99, 95) / 100.0

    st.session_state['A_cut_1'] = A_cut_1
    st.session_state['B_cut_1'] = B_cut_1
    st.session_state['A_cut_2'] = A_cut_2
    st.session_state['B_cut_2'] = B_cut_2

    st.header('4) Exportar')
    want_csv = st.checkbox('Permitir descarga Excel', True)
    gen_pdf = st.checkbox('Generar informe PDF', False)

if uploaded_file is None:
    st.info('Sube un Excel para comenzar')
    st.stop()

# -------------------------------
# Leer datos
# -------------------------------
try:
    df = read_excel_bytes(uploaded_file.read(), sheet_name=sheet_name or None)
    # Limpiar espacios y may√∫sculas/min√∫sculas
    df['Art√≠culo_LIMPIO'] = df['Art√≠culo'].astype(str).str.strip().str.upper()
except Exception as e:
    st.error(f'Error leyendo Excel: {e}')
    st.stop()

# map columns tolerant
try:
    art = df['Art√≠culo_LIMPIO']
    unid = pd.to_numeric(safe_col(df, 'Unid. Vend'), errors='coerce').fillna(0)
    monto = pd.to_numeric(safe_col(df, 'Monto venta'), errors='coerce').fillna(0)
    vol = pd.to_numeric(safe_col(df, 'Volumen total (p3)', alt_names=['Volumen total (m3)', 'Volumen total']), errors='coerce').fillna(0) * vol_factor
    numdoc = safe_col(df, 'Num. Doc').astype(str)
    fecha = pd.to_datetime(safe_col(df, 'Fecha Doc'), errors='coerce')
except Exception as e:
    st.error(f'Error mapeando columnas: {e}')
    st.stop()

base = pd.DataFrame({
    'Articulo': art,
    'Unidades': unid,
    'Monto': monto,
    'Volumen_p3': vol,
    'NumDoc': numdoc,
    'Fecha': fecha,
    'Cajas_vendidas': pd.to_numeric(safe_col(df, 'Cajas vend.'), errors='coerce').fillna(0)
}).dropna(subset=['Fecha'])

# Guardar base en session_state para usarlo en PDF y perfiles
st.session_state['base'] = base

if len(base) == 0:
    st.error('No hay registros con fecha valida')
    st.stop()

st.write("Primeras filas de base:")
st.dataframe(base.head())
st.write("Suma Unidades:", base['Unidades'].sum())
st.write("Suma Cajas_vendidas:", base['Cajas_vendidas'].sum())

# -------------------------------
# Calcular Super ABC
# -------------------------------
st.subheader('‚ñ∂Ô∏è Control de secciones')

if st.button('1) Calcular S√∫per ABC'):
    by_item = base.groupby('Articulo').agg(
        popularidad=('NumDoc','nunique'),
        unidades=('Unidades','sum'),
        ventas=('Monto','sum'),
        volumen=('Volumen_p3','sum'),
        lineas=('NumDoc','count')
    )
    # rotacion semanal
    days_range = (base['Fecha'].max() - base['Fecha'].min()).days + 1
    weeks_range = max(1, days_range/7)
    by_item['rotacion_sem'] = by_item['unidades'] / weeks_range

    key1 = criterios[crit1]
    key2 = criterios[crit2]

    by_item['ABC_1'] = abc_by_contribution(by_item[key1], A_cut_1, B_cut_1)
    by_item['ABC_2'] = abc_by_contribution(by_item[key2], A_cut_2, B_cut_2)
    by_item['Clase_SuperABC'] = by_item['ABC_1'].astype(str) + by_item['ABC_2'].astype(str)

    # Mostrar art√≠culos con problemas de clasificaci√≥n
    problemas = by_item[by_item['ABC_1'].isna() | by_item['ABC_2'].isna() | by_item['Clase_SuperABC'].str.contains('nan')]
    if not problemas.empty:
        st.warning(f"Hay {len(problemas)} art√≠culos sin clase v√°lida. Mira la tabla abajo para revisar:")
        st.dataframe(problemas)
    else:
        st.info("Todos los art√≠culos tienen clase v√°lida.")

    # stats semanales
    base['WeekStart'] = week_floor(base['Fecha'])
    weekly = base.groupby(['Articulo','WeekStart']).agg(units=('Unidades','sum')).reset_index()
    stats = weekly.pivot_table(index='Articulo', values='units', aggfunc=[np.mean, np.std, lambda x: (x==0).mean()])
    stats.columns = ['mean_week','std_week','intermittency']
    by_item = by_item.join(stats, how='left')
    by_item['cv'] = by_item['std_week'] / by_item['mean_week'].replace(0, np.nan)
    by_item['cv'] = by_item['cv'].fillna(np.inf)
    by_item['intermittency'] = by_item['intermittency'].fillna(1.0)

    by_item['Zona_Bodega'] = by_item['Clase_SuperABC'].apply(map_zone)
    by_item['Pol√≠tica_Inv'] = [policy_by_demand(cv, ii) for cv, ii in zip(by_item['cv'], by_item['intermittency'])]
    by_item['FillRate_obj'] = by_item['Zona_Bodega'].apply(target_fill_rate)
    by_item['Frecuencia_Recuento'] = by_item['Zona_Bodega'].apply(cycle_count_freq)

    st.session_state['by_item'] = by_item
    st.session_state['crit1_name'] = crit1
    st.session_state['crit2_name'] = crit2
    st.success('S√∫per ABC calculado correctamente üéØ')

    # -------------------------------
    # Guardar by_item limpio como perfil
    # -------------------------------
    export_df = by_item.reset_index().copy()
    export_df.columns = [unicodedata.normalize('NFKD', str(c)).encode('ascii','ignore').decode('ascii') for c in export_df.columns]

    if 'FillRate_obj' in export_df.columns:
        export_df['FillRate_obj'] = export_df['FillRate_obj'].astype(str).str.replace('‚Äì','-', regex=False).str.replace('‚Äî','-', regex=False)

    export_df = sanitize_colnames(export_df)
    st.session_state['perfil_by_item_sanitizado'] = export_df


    # --- Comparaci√≥n de art√≠culos √∫nicos para detectar p√©rdidas ---
    articulos_excel = set(df['Art√≠culo'].astype(str).unique())
    articulos_base = set(base['Articulo'].unique())
    articulos_by_item = set(by_item.index)

    faltan_en_base = articulos_excel - articulos_base
    faltan_en_by_item = articulos_base - articulos_by_item

    st.write(f"Total art√≠culos en Excel: {len(articulos_excel)}")
    st.write(f"Total art√≠culos en base (con fecha v√°lida): {len(articulos_base)}")
    st.write(f"Total art√≠culos en by_item (agrupados): {len(articulos_by_item)}")

    if faltan_en_base:
        st.warning(f"Art√≠culos en Excel pero no en base (probablemente por fecha vac√≠a o inv√°lida): {faltan_en_base}")
    if faltan_en_by_item:
        st.warning(f"Art√≠culos en base pero no en by_item (posible error de agrupaci√≥n): {faltan_en_by_item}")
    if not faltan_en_base and not faltan_en_by_item:
        st.info("No se pierden art√≠culos en ninguna etapa del procesamiento.")
# -------------------------------
# Mostrar resumen y perfiles
# -------------------------------
def ira_by_class(clase: str) -> str:
    mapping = {
        'AA': '> 95%',
        'AB': '94% - 95%',
        'AC': '92% - 94%',
        'BA': '90% - 92%',
        'BB': '88% - 90%',
        'BC': '86% - 88%',
        'CA': '84% - 86%',
        'CB': '82% - 84%',
        'CC': '< 80%'
    }
    return mapping.get(clase, 'N/A')

if 'by_item' in st.session_state:
    by_item = st.session_state['by_item']

    if st.button('2) Mostrar tabla resumen y perfiles'):
        st.subheader('üìã Resumen por categor√≠a (AA..CC)')
        summary = by_item.groupby('Clase_SuperABC').agg(
            Cantidad=('ABC_1','count'),
            Zona_Bodega=('Zona_Bodega','first'),
            Politica=('Pol√≠tica_Inv','first'),
            FillRate=('FillRate_obj','first'),
            Ventas=('ventas','sum'),
            Frecuencia_Recuento=('Frecuencia_Recuento','first')
        ).reset_index()

        # Insertar columna IRA despu√©s de FillRate
        summary['IRA'] = summary['Clase_SuperABC'].apply(ira_by_class)

        summary['Porcentaje'] = (summary['Cantidad']/summary['Cantidad'].sum()*100).round(2)
        total_sales = summary['Ventas'].sum()
        summary['% Ventas'] = (100 * summary['Ventas'] / (total_sales if total_sales>0 else 1)).round(2)

        # Ordenar categor√≠as
        order = [a+b for a in 'ABC' for b in 'ABC']
        summary['_ord'] = summary['Clase_SuperABC'].apply(lambda x: order.index(x) if x in order else 999)
        summary = summary.sort_values('_ord').drop(columns=['_ord'])

        # Reordenar columnas para que IRA quede despu√©s de FillRate
        cols = ['Clase_SuperABC','Cantidad','Zona_Bodega','Politica','FillRate','IRA',
                'Frecuencia_Recuento','Ventas','Porcentaje','% Ventas']
        summary = summary[cols]

        st.dataframe(summary)
        st.session_state['perfil_resumen'] = summary

        # Perfil: lineas por orden (distribucion %)
        st.subheader('% de √≥rdenes por # l√≠neas')
        lines_per_order = base.groupby('NumDoc').agg(lineas=('Articulo','nunique')).reset_index()
        dist_lines = lines_per_order.groupby('lineas').size().rename('conteo').reset_index()
        total_orders = dist_lines['conteo'].sum()
        dist_lines['%_ordenes'] = 100 * dist_lines['conteo']/ (total_orders if total_orders>0 else 1)
        st.dataframe(dist_lines.sort_values('lineas'))
        fig_lines = px.bar(dist_lines.sort_values('lineas'), x='lineas', y='%_ordenes', labels={'lineas':'L√≠neas por orden','%_ordenes':'% de √≥rdenes'})
        st.plotly_chart(fig_lines, use_container_width=True)

        st.session_state['perfil_lineas'] = dist_lines

        # Perfil: cubicaje por orden
        st.subheader('% de √≥rdenes por rango de volumen (pies¬≥)')
        cubic_per_order = base.groupby('NumDoc').agg(volumen_total=('Volumen_p3','sum')).reset_index()
        vol_bins = [-1,1,2,5,10,20,50,1e9]
        vol_labels = ['‚â§1','1-2','2-5','5-10','10-20','20-50','>50']
        cubic_per_order['vol_bin'] = pd.cut(cubic_per_order['volumen_total'], bins=vol_bins, labels=vol_labels)
        dist_cubic = cubic_per_order.groupby('vol_bin').size().rename('conteo').reset_index()
        total_orders2 = dist_cubic['conteo'].sum()
        dist_cubic['%_ordenes'] = 100 * dist_cubic['conteo']/ (total_orders2 if total_orders2>0 else 1)
        st.dataframe(dist_cubic)
        fig_cubic = px.bar(dist_cubic, x='vol_bin', y='%_ordenes', labels={'vol_bin':'Rango volumen (pies¬≥)','%_ordenes':'% de √≥rdenes'})
        st.plotly_chart(fig_cubic, use_container_width=True)

        st.session_state['perfil_cubicaje'] = dist_cubic

        # Distribucion por dia de la semana
        st.subheader('Distribuci√≥n de √≥rdenes por d√≠a de la semana')
        orders_dates = base.groupby('NumDoc').agg(fecha=('Fecha','max')).reset_index()
        orders_dates['dia'] = orders_dates['fecha'].dt.day_name()
        mapping_days = {'Monday':'Lunes','Tuesday':'Martes','Wednesday':'Mi√©rcoles','Thursday':'Jueves','Friday':'Viernes','Saturday':'S√°bado','Sunday':'Domingo'}
        orders_dates['dia'] = orders_dates['dia'].replace(mapping_days)
        day_order = ['Lunes','Martes','Mi√©rcoles','Jueves','Viernes','S√°bado','Domingo']
        dist_days = orders_dates.groupby('dia').size().reindex(day_order).fillna(0).astype(int).rename('conteo').reset_index()
        dist_days['%_ordenes'] = 100 * dist_days['conteo'] / (dist_days['conteo'].sum() if dist_days['conteo'].sum()>0 else 1)
        st.dataframe(dist_days)
        fig_days = px.bar(dist_days, x='dia', y='%_ordenes', labels={'dia':'D√≠a','%_ordenes':'% de √≥rdenes'})
        st.plotly_chart(fig_days, use_container_width=True)

        st.session_state['perfil_dias'] = dist_days

        # Preparar datos
        lv = base.groupby('NumDoc').agg(
            lineas=('Articulo','nunique'),
            volumen_total=('Volumen_p3','sum')
        ).reset_index()

        # Par√°metro: volumen de una tarima completa (ajusta seg√∫n tu operaci√≥n)
        VOLUMEN_TARIMA = st.session_state.get('vol_tarima', 42.38)

        # % de carga unitaria respecto a una tarima
        lv['%_carga_unidad'] = 100 * lv['volumen_total'] / VOLUMEN_TARIMA
        lv['%_carga_unidad'] = lv['%_carga_unidad'].clip(upper=100)  # m√°ximo 100%

        # Bins para % de carga unitaria
        carga_bins = list(range(0, 105, 5))
        carga_labels = [f'{i}-{i+5}%' for i in range(0, 100, 5)]
        lv['r_carga'] = pd.cut(lv['%_carga_unidad'], bins=carga_bins, labels=carga_labels, right=True, include_lowest=True)
        
        # Distribuci√≥n cruzada: % l√≠neas de pedido vs % carga unitaria
        dist_incremento = lv.groupby(['r_carga']).agg(
            pedidos=('NumDoc', 'count'),
            lineas_prom=('lineas', 'mean')
        ).reset_index()
        dist_incremento['%_lineas_pedido'] = 100 * dist_incremento['pedidos'] / dist_incremento['pedidos'].sum()

        st.subheader('Distribuci√≥n por incremento de pedidos (% carga unitaria vs % de l√≠neas de pedido)')
        st.dataframe(dist_incremento.rename(columns={'%_lineas_pedido': '% de l√≠neas de pedido'}))
        fig_incremento = px.bar(
            dist_incremento,
            x='r_carga',
            y='%_lineas_pedido',
            labels={'r_carga': '% de carga unitaria (tarima)', '%_lineas_pedido': '% de l√≠neas de pedido'},
            title='% de l√≠neas de pedido por % de carga unitaria'
        )
        st.plotly_chart(fig_incremento, use_container_width=True)

        st.session_state['perfil_carga'] = dist_incremento

        # -------------------------------
        # Tabla cruzada l√≠neas x volumen por pedido
        # -------------------------------
        st.subheader('Tabla cruzada: L√≠neas por pedido vs pies¬≥ por pedido')

        # Categor√≠as
        line_labels = ['1','2-5','6-9','10+']
        lv['r_lineas'] = pd.cut(lv['lineas'], bins=[0,1,6,10,1e9], labels=line_labels, right=True, include_lowest=True)

        vol_labels = ['0-1','1-2','2-5','5-10','10-20','20+']
        lv['r_vol'] = pd.cut(lv['volumen_total'], bins=[0,1,2,5,10,20,1e9], labels=vol_labels, right=True, include_lowest=True)

        # Desglose de pedidos por rango de l√≠neas (incluyendo volumen)
        st.subheader('Desglose de pedidos por rango de l√≠neas')
        for rango in line_labels:
            pedidos_rango = lv[lv['r_lineas'] == rango][['NumDoc', 'lineas', 'volumen_total', 'r_vol']]
            st.markdown(f"**Rango {rango}: {len(pedidos_rango)} pedidos**")
            st.dataframe(pedidos_rango.reset_index(drop=True))

        # Conteo de pedidos por l√≠nea y volumen
        ct_counts = pd.crosstab(lv['r_lineas'], lv['r_vol'], dropna=False)

        # Totales de l√≠nea y % pedidos por l√≠nea
        ct_counts['Totales'] = ct_counts.sum(axis=1)
        ct_counts['% pedidos'] = (ct_counts['Totales'] / ct_counts['Totales'].sum() * 100).round(2)

        # üîπ Total de l√≠neas (sumando l√≠neas, no volumen)
        pivot_lines = pd.pivot_table(
            lv,
            index='r_lineas',
            values='lineas',
            aggfunc='sum',
            fill_value=0
        )
        total_lines_global = pivot_lines['lineas'].sum()
        pivot_lines['% linea'] = (pivot_lines['lineas'] / (total_lines_global if total_lines_global>0 else 1) * 100).round(2)

        # Crear tabla final con columnas en orden deseado
        table_final = pd.DataFrame(index=line_labels, columns=vol_labels + ['Totales','% pedidos','Total_Linea','% linea'])
        table_final[vol_labels] = ct_counts[vol_labels]
        table_final['Totales'] = ct_counts['Totales']
        table_final['% pedidos'] = ct_counts['% pedidos']
        table_final['Total_Linea'] = pivot_lines['lineas']
        table_final['% linea'] = pivot_lines['% linea']

        # Fila Totales
        totales_row = table_final[vol_labels].sum()
        totales_row['Totales'] = table_final['Totales'].sum()
        totales_row['% pedidos'] = 100
        totales_row['Total_Linea'] = table_final['Total_Linea'].sum()
        totales_row['% linea'] = 100
        table_final.loc['Totales'] = totales_row

        # Fila % pedidos (por columna)
        pct_pedidos_row = (table_final.loc[line_labels, vol_labels].sum() / table_final['Totales'].sum() * 100).round(2)
        pct_pedidos_row['Totales'] = 100
        pct_pedidos_row['% pedidos'] = np.nan
        pct_pedidos_row['Total_Linea'] = np.nan
        pct_pedidos_row['% linea'] = np.nan
        table_final.loc['% pedidos'] = pct_pedidos_row

        # Fila Espacio total (volumen)
        espacio_total_row = lv.groupby('r_vol')['volumen_total'].sum()
        espacio_total_row = espacio_total_row.reindex(vol_labels, fill_value=0)
        espacio_total_row['Totales'] = espacio_total_row.sum()
        espacio_total_row['% pedidos'] = np.nan
        espacio_total_row['Total_Linea'] = np.nan       # No calcular para espacio total
        espacio_total_row['% linea'] = np.nan           # No calcular para espacio total
        table_final.loc['Espacio total'] = espacio_total_row

        # Renombrar √≠ndice
        table_final.index.name = 'L√≠neas por orden / Volumen por orden'

        # Mostrar tabla
        st.dataframe(table_final.round(2))

        st.session_state['perfil_cruzado'] = table_final

        # Pareto popularidad
        st.subheader('Pareto de popularidad de √≠tems (picks acumulados)')
        pareto = by_item.sort_values('popularidad', ascending=False)[['popularidad']].copy()
        pareto['cum_picks'] = pareto['popularidad'].cumsum()
        total_picks = pareto['popularidad'].sum()
        pareto['cum_pct_picks'] = 100 * pareto['cum_picks'] / (total_picks if total_picks>0 else 1)
        pareto['sku_rank'] = np.arange(1, len(pareto)+1)
        pareto['pct_sku'] = 100 * pareto['sku_rank'] / len(pareto)
        st.dataframe(pareto.head(20))
        fig_pareto = px.line(pareto, x='pct_sku', y='cum_pct_picks', labels={'pct_sku':'% de SKU (acumulado)','cum_pct_picks':'% de picks (acumulado)'}, title='Curva de Pareto ‚Äì Popularidad')
        st.plotly_chart(fig_pareto, use_container_width=True)

        st.session_state['perfil_pareto'] = pareto


    # -------------------------------
    # Exportar CSV (sanitizado)
    # -------------------------------

    # -------------------------------
    # Datos generales
    # -------------------------------
    file_name = st.session_state.get('file_name', uploaded_file.name if uploaded_file else 'Archivo no registrado')
    sheet_used = st.session_state.get('sheet_name', sheet_name or 'Hoja no registrada')
    vol_units = st.session_state.get('vol_units', unit_vol)
    crit1 = st.session_state.get('crit1_name', crit1)
    crit2 = st.session_state.get('crit2_name', crit2)
    A_cut_1 = st.session_state['A_cut_1']
    B_cut_1 = st.session_state['B_cut_1']
    A_cut_2 = st.session_state['A_cut_2']
    B_cut_2 = st.session_state['B_cut_2']

    # -------------------------------
    # Crear hoja Portada
    # -------------------------------
    portada_data = {
        'Campo': [
            'Documento le√≠do',
            'Hoja utilizada',
            'Unidades de volumen',
            'Criterio principal',
            'Criterio secundario',
            'Corte A (Rotaci√≥n)',
            'Corte B (Rotaci√≥n)',
            'Corte A (Popularidad)',
            'Corte B (Popularidad)'
        ],
        'Valor': [
            file_name,
            sheet_used,
            vol_units,
            crit1,
            crit2,
            A_cut_1,
            B_cut_1,
            A_cut_2,
            B_cut_2
        ]
    }

    df_portada = pd.DataFrame(portada_data)


    if want_csv:
        if st.button("üì• Exportar perfiles a Excel"):
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
                # Hoja Portada primero
                df_portada.to_excel(writer, sheet_name='Portada', index=False)
                for key, df in st.session_state.items():
                    if key.startswith("perfil_") and isinstance(df, pd.DataFrame):
                        hoja = key.replace("perfil_", "")[:30]  # hoja ‚â§ 31 chars
                        df.to_excel(writer, sheet_name=hoja, index=False)

            st.download_button(
                "üìä Descargar Excel con perfiles",
                data=buffer.getvalue(),
                file_name="perfiles_distribuciones.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        


if 'by_item' in st.session_state:
    by_item = st.session_state['by_item']
    base = st.session_state['base']

    st.header('üîÆ Forecasting de Demanda por Art√≠culo')

    # Selecci√≥n de art√≠culo
    articulos = sorted(base['Articulo'].unique())
    articulo_sel = st.selectbox('Selecciona Art√≠culo para pron√≥stico', articulos, key='forecast_articulo')

    # Per√≠odo y cantidad de forecast
    periodo_forecast = st.selectbox('Periodo de forecast', ['Mensual', 'Semanal'], index=0)
    n_periods = st.number_input(f'Per√≠odos a pronosticar ({periodo_forecast.lower()})', min_value=1, max_value=52, value=4, step=1)

    # Unidad a pronosticar
    unidad_forecast = st.selectbox('Unidad a pronosticar', ['Unidades vendidas', 'Cajas vendidas'], index=0)
    columna_forecast = 'Unidades' if unidad_forecast=='Unidades vendidas' else 'Cajas_vendidas'

    # Filtrar datos
    base_art = base[base['Articulo']==articulo_sel].copy()
    if base_art.empty:
        st.warning("No hay registros para ese art√≠culo.")
        st.stop()
    for col in ['Unidades','Cajas_vendidas']:
        base_art[col] = pd.to_numeric(base_art.get(col,0), errors='coerce').fillna(0)

    # Serie hist√≥rica
    orders_df = base_art.groupby('NumDoc').agg(Fecha=('Fecha','max'),
                                               Unidades=('Unidades','sum'),
                                               Cajas_vendidas=('Cajas_vendidas','sum')).reset_index()
    resample_freq = 'MS' if periodo_forecast=='Mensual' else 'W-MON'
    date_offset = pd.DateOffset(months=1) if periodo_forecast=='Mensual' else pd.DateOffset(weeks=1)
    ts_art = orders_df.set_index('Fecha')[columna_forecast].resample(resample_freq).sum().fillna(0)
    st.subheader("Serie hist√≥rica")
    st.line_chart(ts_art)

    import numpy as np
    import pandas as pd
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.metrics import mean_absolute_error, mean_squared_error
    import plotly.graph_objects as go

    # Modelos
    modelos = ['Media m√≥vil (4 periodos)','Holt-Winters','Prophet','Random Forest']
    forecasts_dict = {}
    resultados = []

    for modelo in modelos:
        try:
            last_index = ts_art.index[-1]
            future_index = pd.date_range(start=last_index + date_offset, periods=n_periods, freq=resample_freq)
            forecast_future = None
            forecast_hist = None

            # ---------------- Media M√≥vil ----------------
            if modelo=='Media m√≥vil (4 periodos)':
                ma = ts_art.rolling(window=4, min_periods=1).mean().shift(1)
                ma = ma.fillna(ts_art)  # reemplazar NaN iniciales
                forecast_future = pd.Series([ma.iloc[-1]]*n_periods, index=future_index)
                forecast_hist = ma

            # ---------------- Holt-Winters ----------------
            elif modelo=='Holt-Winters':
                if len(ts_art) >= 2:
                    # Detectar estacionalidad autom√°ticamente si hay suficientes ciclos
                    period = None
                    if periodo_forecast=='Mensual' and len(ts_art) >= 24:
                        period = 12
                    elif periodo_forecast=='Semanal' and len(ts_art) >= 104:
                        period = 52

                    hw = sm.tsa.ExponentialSmoothing(
                        ts_art,
                        trend='add',
                        seasonal='add' if period else None,
                        seasonal_periods=period,
                        initialization_method="estimated"
                    ).fit()
                    forecast_future = pd.Series(hw.forecast(n_periods).values, index=future_index)
                    forecast_hist = hw.fittedvalues
                else:
                    st.info("Holt-Winters omitido por pocos datos.")

            # ---------------- Prophet ----------------
            elif modelo=='Prophet':
                from prophet import Prophet
                df_prophet = ts_art.reset_index().rename(columns={'Fecha':'ds', columna_forecast:'y'})
                
                if len(df_prophet) >= 3:
                    # Decidir autom√°ticamente la estacionalidad
                    yearly = False
                    weekly = False
                    daily = False  # normalmente no se usa para datos semanales/mensuales

                    if periodo_forecast=='Mensual' and len(ts_art) >= 24:
                        yearly = True
                    if periodo_forecast=='Semanal':
                        if len(ts_art) >= 104:
                            yearly = True
                        if len(ts_art) >= 8:
                            weekly = True

                    m = Prophet(yearly_seasonality=yearly,
                                weekly_seasonality=weekly,
                                daily_seasonality=daily)
                    m.fit(df_prophet)
                    future_all = m.make_future_dataframe(periods=n_periods, freq=resample_freq)
                    forecast = m.predict(future_all)
                    # Forzar valores positivos para forecast futuro
                    forecast_future = pd.Series(np.maximum(forecast['yhat'].tail(n_periods).values, 0),
                                                index=forecast['ds'].tail(n_periods))
                    forecast_hist = pd.Series(forecast['yhat'].iloc[:len(ts_art)].values, index=ts_art.index)


            # ---------------- Random Forest ----------------
            elif modelo=='Random Forest':
                df_ml = ts_art.copy().reset_index()
                df_ml.rename(columns={'Fecha':'Periodo', columna_forecast:'y'}, inplace=True)
                # Reindexar a frecuencia continua y rellenar vac√≠os
                df_ml = df_ml.set_index('Periodo').asfreq(resample_freq, fill_value=0).reset_index()
                max_lag = 4
                for lag in range(1, max_lag+1):
                    df_ml[f'lag_{lag}'] = df_ml['y'].shift(lag)
                    df_ml[f'lag_{lag}'].fillna(df_ml['y'].iloc[0], inplace=True)  # Rellenar NaN iniciales

                X = df_ml[[f'lag_{i}' for i in range(1, max_lag+1)]].to_numpy()
                y = df_ml['y'].to_numpy()
                rf = RandomForestRegressor(n_estimators=200, random_state=42)
                rf.fit(X, y)

                # Forecast futuro
                last_values = list(df_ml.iloc[-1][[f'lag_{i}' for i in range(1, max_lag+1)]])
                preds_future = []
                for _ in range(n_periods):
                    pred = rf.predict([last_values])[0]
                    pred = max(pred, 0)
                    preds_future.append(pred)
                    last_values = [pred] + last_values[:-1]
                forecast_future = pd.Series(preds_future, index=future_index)

                # Forecast hist√≥rico
                forecast_hist = pd.Series(rf.predict(X), index=df_ml['Periodo'])
                forecast_hist = forecast_hist.reindex(ts_art.index, method='ffill')

            # Guardar resultados y m√©tricas
            if forecast_future is not None:
                forecasts_dict[modelo] = {'future':forecast_future, 'hist':forecast_hist}
                if forecast_hist is not None and len(forecast_hist)==len(ts_art):
                    y_true = ts_art.values
                    y_pred = forecast_hist.values
                    mae = mean_absolute_error(y_true, y_pred)
                    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
                    mape = np.mean(np.abs((y_true-y_pred)/(y_true+1e-9)))*100
                    # Detectar posibles valores absurdos
                    mape_warning = mape > 1000  # umbral arbitrario para advertencia
                    if mape_warning:
                        st.warning(f"‚ö†Ô∏è El MAPE del modelo '{modelo}' es extremadamente alto ({mape:.2f}%). Esto puede ocurrir por valores cercanos a cero en la serie hist√≥rica y puede no reflejar un error realista. Use el MAPE sim√©trico (SMAPE) como referencia.")
                    smape = 100 * np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred) + 1e-9))
                    resultados.append({'Modelo':modelo,'MAE':mae,'RMSE':rmse,'MAPE (%)':mape,'SMAPE (%)':smape})

        except Exception as e:
            st.warning(f"{modelo} omitido: {e}")
            
    # ----------- Tabla de m√©tricas -----------
    df_resultados = pd.DataFrame(resultados)
    if not df_resultados.empty:
        st.subheader("üìä Comparaci√≥n de m√©tricas")
        st.dataframe(df_resultados.round(2).sort_values('RMSE'))

    # ----------- Selecci√≥n de modelos a mostrar -----------
    modelos_disp = st.multiselect("Selecciona modelos a mostrar en la gr√°fica", list(forecasts_dict.keys()), default=list(forecasts_dict.keys()))

    # ----------- Gr√°fico interactivo con Plotly -----------
    st.subheader("üìà Comparativa interactiva de forecasts")
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=ts_art.index, y=ts_art.values, mode='lines+markers', name='Observado', line=dict(color='black', width=3)))
    for modelo in modelos_disp:
        data = forecasts_dict[modelo]
        if data['hist'] is not None:
            fig.add_trace(go.Scatter(x=data['hist'].index, y=data['hist'].values, mode='lines', name=f"{modelo} (hist)", line=dict(dash='dot')))
        fig.add_trace(go.Scatter(x=data['future'].index, y=data['future'].values, mode='lines+markers', name=f"{modelo} (futuro)"))
    fig.update_layout(hovermode='x unified', xaxis_title='Fecha', yaxis_title=columna_forecast)
    st.plotly_chart(fig, use_container_width=True)

    # ----------- Descarga ZIP -----------
    import io, zipfile
    buffer = io.BytesIO()
    with zipfile.ZipFile(buffer, 'w') as zf:
        if not df_resultados.empty:
            zf.writestr("comparacion_metricas.csv", df_resultados.round(2).to_csv(index=False))
        all_forecasts = pd.DataFrame({m:data['future'] for m,data in forecasts_dict.items()})
        all_forecasts.index.name='Periodo'
        all_forecasts.reset_index(inplace=True)
        zf.writestr("forecasts_modelos.csv", all_forecasts.round(2).to_csv(index=False))
    st.download_button("üì• Descargar resultados completos (ZIP)", data=buffer.getvalue(),
                       file_name=f"forecast_completo_{articulo_sel}.zip", mime="application/zip")


# -------------------------------
# Generar PDF completo robusto y profesional (mejorado)
# -------------------------------
if gen_pdf:
    if not PDF_LIBS_AVAILABLE:
        st.error('Para generar PDFs instala: pip install reportlab matplotlib')
    else:
        if st.button('4) Generar informe PDF'):
            from reportlab.lib import colors
            from reportlab.platypus import TableStyle, Image, PageBreak
            from reportlab.pdfgen import canvas
            from reportlab.lib.units import cm, mm
            from reportlab.platypus import BaseDocTemplate, Frame, PageTemplate
            import io, matplotlib.pyplot as plt

            # --- Pie de p√°gina con numeraci√≥n
            def add_page_number(canvas, doc):
                page_num = canvas.getPageNumber()
                text = f"P√°gina {page_num}"
                canvas.setFont('Helvetica', 8)
                canvas.drawRightString(200*mm, 10*mm, text)

            buffer = io.BytesIO()
            doc = BaseDocTemplate(
                buffer,
                pagesize=letter,
                rightMargin=25, leftMargin=25,
                topMargin=25, bottomMargin=18
            )
            frame = Frame(doc.leftMargin, doc.bottomMargin,
                          doc.width, doc.height, id='normal')
            template = PageTemplate(id='with-number',
                                    frames=frame,
                                    onPage=add_page_number)
            doc.addPageTemplates([template])

            styles = getSampleStyleSheet()
            elems = []

            # -------------------------------
            # Encabezado
            # -------------------------------
            elems.append(Paragraph('üìä Informe de An√°lisis - S√∫per ABC & Perfiles', styles['Title']))
            elems.append(Spacer(1, 14))

            # -------------------------------
            # Texto explicativo inicial
            # -------------------------------
            intro_text = """
            <b>Clasificaci√≥n de zonas de bodega:</b><br/>
            - <b>Zona Oro (Close to door, close to floor):</b> √Årea de mayor valor, ubicada estrat√©gicamente cerca de las puertas de entrada y salida de la bodega. Se destina a los productos de <b>alta rotaci√≥n</b>, minimizando tiempo de viaje y esfuerzo de los operarios.<br/>
            - <b>Zona Plata (Close to floor):</b> Ubicada a una distancia media de las puertas. Se utiliza para productos de <b>rotaci√≥n media</b>. El tiempo de acceso es moderado.<br/>
            - <b>Zona Bronce (Far from door, far from floor):</b> √Årea m√°s alejada de las puertas. Reservada para productos de <b>baja rotaci√≥n</b>. Aunque implica mayor tiempo de acceso, la baja frecuencia de movimiento lo justifica.<br/><br/>

            <b>Pol√≠ticas de inventario:</b><br/>
            - <b>ROP-OUL:</b> Reordenar al alcanzar el punto de pedido (ROP), con un l√≠mite superior (OUL) para evitar exceso de inventario.<br/>
            - <b>RTP-EOQ:</b> Pol√≠tica de revisi√≥n peri√≥dica (RTP), aplicando el tama√±o de lote econ√≥mico (EOQ) como cantidad √≥ptima de pedido.<br/>
            - <b>ROP-EOQ:</b> Pol√≠tica de reorden continuo (ROP), usando el EOQ como lote de reposici√≥n.<br/><br/>

            <b>Fill rate:</b> M√©trica de nivel de servicio que mide el porcentaje de demanda atendida en el primer intento con el inventario disponible. Un fill rate alto indica capacidad de satisfacer pedidos sin generar faltantes.<br/><br/>

            <b>IRA (Inventory Record Accuracy):</b> KPI que mide la exactitud del inventario, comparando los registros te√≥ricos del sistema con la realidad f√≠sica del stock disponible en un almac√©n. Un IRA alto indica que la informaci√≥n del sistema es confiable, lo que permite una gesti√≥n de inventarios m√°s eficiente, reduciendo p√©rdidas, excedentes y retrasos en los pedidos.  <br/><br/>

            <b>Recuento c√≠clico:</b> Estrategia de control de inventarios que consiste en revisar y contar de forma peri√≥dica subgrupos de productos a lo largo del a√±o. Se enfoca m√°s en art√≠culos cr√≠ticos o de mayor rotaci√≥n (categor√≠a A o AA), garantizando precisi√≥n de inventario sin necesidad de inventarios generales completos.
            """

            elems.append(Paragraph(intro_text, styles['Normal']))
            elems.append(Spacer(1, 14))

            # -------------------------------
            # Datos generales
            # -------------------------------
            file_name = st.session_state.get('file_name', uploaded_file.name if uploaded_file else 'Archivo no registrado')
            sheet_used = st.session_state.get('sheet_name', sheet_name or 'Hoja no registrada')
            vol_units = st.session_state.get('vol_units', unit_vol)
            crit1 = st.session_state.get('crit1_name', crit1)
            crit2 = st.session_state.get('crit2_name', crit2)
            A_cut_1 = st.session_state['A_cut_1']
            B_cut_1 = st.session_state['B_cut_1']
            A_cut_2 = st.session_state['A_cut_2']
            B_cut_2 = st.session_state['B_cut_2']

            general_info = f"""
            <b>Documento le√≠do:</b> {file_name}<br/>
            <b>Hoja utilizada:</b> {sheet_used}<br/>
            <b>Unidades de volumen:</b> {vol_units}<br/>
            <b>Criterio principal:</b> {crit1}<br/>
            <b>Criterio secundario:</b> {crit2}<br/>
            <b>Corte A ({st.session_state['crit1_name']}):</b> {A_cut_1*100:.1f}%<br/>
            <b>Corte B ({st.session_state['crit1_name']}):</b> {B_cut_1*100:.1f}%<br/>
            <b>Corte A ({st.session_state['crit2_name']}):</b> {A_cut_2*100:.1f}%<br/>
            <b>Corte B ({st.session_state['crit2_name']}):</b> {B_cut_2*100:.1f}%<br/>
            """
            elems.append(Paragraph(general_info, styles['Normal']))
            elems.append(Spacer(1, 12))

            by_item = st.session_state['by_item']
            base = st.session_state['base']

            # -------------------------------
            # Tabla resumen Super ABC (columnas compactas)
            # -------------------------------
            summary_table = by_item.groupby('Clase_SuperABC').agg(
                Cantidad=('ABC_1','count'),
                Zona_Bodega=('Zona_Bodega','first'),
                Politica=('Pol√≠tica_Inv','first'),
                FillRate=('FillRate_obj','first'),
                Frecuencia_Recuento=('Frecuencia_Recuento','first'),
                Ventas=('ventas','sum')
            ).reset_index()

            summary_table['Porcentaje'] = (summary_table['Cantidad']/summary_table['Cantidad'].sum()*100).round(2)
            total_sales = summary_table['Ventas'].sum()
            summary_table['% Ventas'] = (100 * summary_table['Ventas'] / (total_sales if total_sales>0 else 1)).round(2)
            summary_table['Ventas'] = summary_table['Ventas'].round(2)

            # üëâ Definir IRA seg√∫n categor√≠a
            ira_map = {
                'AA': '> 95%',
                'AB': '94% - 95%',
                'AC': '92% - 94%',
                'BA': '90% - 92%',
                'BB': '88% - 90%',
                'BC': '86% - 88%',
                'CA': '84% - 86%',
                'CB': '82% - 84%',
                'CC': '< 80%'
            }
            summary_table['IRA'] = summary_table['Clase_SuperABC'].map(ira_map)

            # Reordenar columnas para poner IRA despu√©s de FillRate
            cols = list(summary_table.columns)
            insert_pos = cols.index('FillRate') + 1
            cols = cols[:insert_pos] + ['IRA'] + cols[insert_pos:-1]  # dejamos % Ventas al final
            summary_table = summary_table[cols]

            # preparar datos y anchos
            data = [list(summary_table.columns)] + summary_table.round(2).astype(str).values.tolist()
            col_widths = []
            for col in summary_table.columns:
                if col in ['Cantidad','Zona_Bodega','FillRate','IRA']:
                    col_widths.append(45)
                elif col in ['Ventas','Porcentaje','% Ventas']:
                    col_widths.append(50)
                elif col in ['Clase_SuperABC','Frecuencia_Recuento']:
                    col_widths.append(70)
                else:
                    col_widths.append(97)

            t = Table(data, colWidths=col_widths, hAlign='CENTER')
            t.setStyle(TableStyle([
                ('GRID', (0,0), (-1,-1), 0.5, colors.black),
                ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),
                ('FONTSIZE', (0,0), (-1,-1), 7),
                ('ALIGN',(0,0),(-1,-1),'CENTER')
            ]))
            elems.append(Paragraph('üìë Resumen por categor√≠a (AA..CC)', styles['Heading2']))
            elems.append(t)
            elems.append(PageBreak())

            # -------------------------------
            # Funci√≥n auxiliar para a√±adir figuras
            # -------------------------------
            def add_fig(fig, title='', width=450, height=240):
                img_buf = io.BytesIO()
                fig.tight_layout()
                fig.savefig(img_buf, format='png', dpi=130)
                plt.close(fig)
                img_buf.seek(0)
                elems.append(Paragraph(title, styles['Heading3']))
                elems.append(Image(img_buf, width=width, height=height))
                elems.append(Spacer(1, 12))
            # -------------------------------
            # Gr√°fica Pareto
            # -------------------------------

            pareto = by_item.sort_values('popularidad', ascending=False).copy()
            pareto['cum_picks'] = pareto['popularidad'].cumsum()
            total_picks = pareto['popularidad'].sum()
            pareto['cum_pct_picks'] = 100*pareto['cum_picks']/(total_picks if total_picks>0 else 1)
            pareto['pct_sku'] = 100 * np.arange(1,len(pareto)+1)/len(pareto)
            fig1, ax1 = plt.subplots(figsize=(6,3))
            ax1.plot(pareto['pct_sku'], pareto['cum_pct_picks'], marker='o')
            ax1.set_xlabel('% SKU (acumulado)')
            ax1.set_ylabel('% picks (acumulado)')
            ax1.set_title('Distribuci√≥n de popularidad')
            add_fig(fig1, 'Pareto de popularidad')
                        
            pareto_intro = """
            Este perfil muestra qu√© porcentaje acumulado de los movimientos de picking corresponde a qu√© porcentaje acumulado de SKUs seg√∫n el principio de Pareto (muchos triviales, pocos vitales). 
            Permite identificar los productos que concentran la mayor parte de la actividad y que deben recibir prioridad en la bodega.
            """
            elems.append(Paragraph(pareto_intro, styles['Normal']))
            elems.append(Spacer(1, 6))

            elems.append(PageBreak())

            # -------------------------------
            # L√≠neas por orden
            # -------------------------------
            lines_per_order = base.groupby('NumDoc').agg(lineas=('Articulo','nunique')).reset_index()
            dist_lines = lines_per_order.groupby('lineas').size().rename('conteo').reset_index()
            total_orders = dist_lines['conteo'].sum()
            dist_lines['%_ordenes'] = 100*dist_lines['conteo']/(total_orders if total_orders>0 else 1)
            fig2, ax2 = plt.subplots(figsize=(6,3))
            ax2.bar(dist_lines['lineas'].astype(str), dist_lines['%_ordenes'])
            ax2.set_xlabel('L√≠neas por orden')
            ax2.set_ylabel('% de √≥rdenes')
            ax2.set_title('Distribuci√≥n de l√≠neas por orden')
            add_fig(fig2, 'L√≠neas por orden')
            
            lines_intro = """
            Este perfil muestra cu√°ntas l√≠neas (SKUs distintos) tiene cada pedido y qu√© porcentaje de √≥rdenes corresponde a cada cantidad de l√≠neas. 
            Permite evaluar la complejidad de los pedidos y planificar recursos de picking y personal.
            """
            elems.append(Paragraph(lines_intro, styles['Normal']))
            elems.append(Spacer(1, 6))
            elems.append(PageBreak())

            # -------------------------------
            # Cubicaje por orden
            # -------------------------------

            cubic_per_order = base.groupby('NumDoc').agg(volumen_total=('Volumen_p3','sum')).reset_index()
            vol_bins = [-1,1,2,5,10,20,50,1e9]
            vol_labels = ['‚â§1','1-2','2-5','5-10','10-20','20-50','>50']
            cubic_per_order['vol_bin'] = pd.cut(cubic_per_order['volumen_total'], bins=vol_bins, labels=vol_labels)
            dist_cubic = cubic_per_order.groupby('vol_bin').size().rename('conteo').reset_index()
            total_orders2 = dist_cubic['conteo'].sum()
            dist_cubic['%_ordenes'] = 100*dist_cubic['conteo']/(total_orders2 if total_orders2>0 else 1)
            fig3, ax3 = plt.subplots(figsize=(6,3))
            ax3.bar(dist_cubic['vol_bin'].astype(str), dist_cubic['%_ordenes'])
            ax3.set_xlabel('Rango volumen (pies¬≥)')
            ax3.set_ylabel('% de √≥rdenes')
            ax3.set_title('Distribuci√≥n de volumen por orden')
            add_fig(fig3, 'Volumen por orden')

            cubic_intro = """
            El presente perfil ilustra mediante una gr√°fica el rango de volumen total de los pedidos y su porcentaje sobre el total de √≥rdenes. 
            Es √∫til para dimensionar espacio de almacenamiento, cajas, pallets y veh√≠culos de transporte, seg√∫n requerimientos de espacio y rotaci√≥n.
            """
            elems.append(Paragraph(cubic_intro, styles['Normal']))
            elems.append(Spacer(1, 6))
            elems.append(PageBreak())

            # Recalcular lv y dist_incremento para el PDF
            lv = base.groupby('NumDoc').agg(
                lineas=('Articulo','nunique'),
                volumen_total=('Volumen_p3','sum')
            ).reset_index()

            VOLUMEN_TARIMA = st.session_state.get('vol_tarima', 42.38)
            lv['%_carga_unidad'] = 100 * lv['volumen_total'] / VOLUMEN_TARIMA
            lv['%_carga_unidad'] = lv['%_carga_unidad'].clip(upper=100)
            carga_bins = list(range(0, 105, 5))
            carga_labels = [f'{i}-{i+5}%' for i in range(0, 100, 5)]
            lv['r_carga'] = pd.cut(lv['%_carga_unidad'], bins=carga_bins, labels=carga_labels, right=True, include_lowest=True)
            dist_incremento = lv.groupby(['r_carga']).agg(
                pedidos=('NumDoc', 'count'),
                lineas_prom=('lineas', 'mean')
            ).reset_index()
            dist_incremento['%_lineas_pedido'] = 100 * dist_incremento['pedidos'] / dist_incremento['pedidos'].sum()

            # Gr√°fica de incremento de pedidos (carga unitaria vs % l√≠neas de pedido)
            fig_inc, ax_inc = plt.subplots(figsize=(6,3))
            ax_inc.bar(dist_incremento['r_carga'].astype(str), dist_incremento['%_lineas_pedido'])
            ax_inc.set_xlabel('% de carga unitaria (tarima)')
            ax_inc.set_ylabel('% de l√≠neas de pedido')
            ax_inc.set_title('Distribuci√≥n por incremento de pedidos')
            plt.setp(ax_inc.get_xticklabels(), rotation=60, ha='right', fontsize=7)  # Rota y reduce fuente
            add_fig(fig_inc, 'Distribuci√≥n por incremento de pedidos')

            inc_intro = """
            Esta gr√°fica muestra la proporci√≥n de l√≠neas de pedido seg√∫n el porcentaje de carga unitaria (por ejemplo, respecto a una tarima completa).
            Permite visualizar cu√°ntos pedidos representan cargas parciales o completas, facilitando la planificaci√≥n log√≠stica y el uso eficiente de espacio.
            """
            elems.append(Paragraph(inc_intro, styles['Normal']))
            elems.append(Spacer(1, 6))
            elems.append(PageBreak())

            # -------------------------------
            # Distribuci√≥n por d√≠a de la semana
            # -------------------------------

            orders_dates = base.groupby('NumDoc').agg(fecha=('Fecha','max')).reset_index()
            orders_dates['dia'] = orders_dates['fecha'].dt.day_name()
            mapping_days = {'Monday':'Lunes','Tuesday':'Martes','Wednesday':'Mi√©rcoles','Thursday':'Jueves',
                            'Friday':'Viernes','Saturday':'S√°bado','Sunday':'Domingo'}
            orders_dates['dia'] = orders_dates['dia'].replace(mapping_days)
            day_order = ['Lunes','Martes','Mi√©rcoles','Jueves','Viernes','S√°bado','Domingo']
            dist_days = orders_dates.groupby('dia').size().reindex(day_order).fillna(0).astype(int).rename('conteo').reset_index()
            dist_days['%_ordenes'] = 100*dist_days['conteo']/dist_days['conteo'].sum()
            fig4, ax4 = plt.subplots(figsize=(6,3))
            ax4.bar(dist_days['dia'], dist_days['%_ordenes'])
            ax4.set_xlabel('D√≠a')
            ax4.set_ylabel('% de √≥rdenes')
            ax4.set_title('Distribuci√≥n de √≥rdenes por d√≠a de la semana')
            add_fig(fig4, '√ìrdenes por d√≠a de la semana')

            days_intro = """
            Este muestra c√≥mo se distribuyen los pedidos a lo largo de la semana y su porcentaje sobre el total. 
            Permite planificar personal, turnos y recursos log√≠sticos en funci√≥n de los picos y valles de demanda, identificando qu√© d√≠as presentan mayor ingreso de √≥rdenes.
            """
            elems.append(Paragraph(days_intro, styles['Normal']))
            elems.append(PageBreak())

            # -------------------------------
            # Tabla cruzada l√≠neas x volumen con % pedidos, Totales y Total L√≠nea
            # -------------------------------

            lv = base.groupby('NumDoc').agg(
                lineas=('Articulo','nunique'),
                volumen_total=('Volumen_p3','sum')
            ).reset_index()

            # Definir rangos (misma l√≥gica que en Streamlit)
            line_labels = ['1','2-5','6-9','10+']
            vol_labels2 = ['0-1','1-2','2-5','5-10','10-20','20+']

            # Categorizar (igual que en la app)
            lv['r_lineas'] = pd.cut(lv['lineas'], bins=[0,1,5,9,1e9], labels=line_labels, right=True, include_lowest=True)
            lv['r_vol'] = pd.cut(lv['volumen_total'], bins=[0,1,2,5,10,20,1e9], labels=vol_labels2, right=True, include_lowest=True)

            # Conteos y totales
            ct_counts = pd.crosstab(lv['r_lineas'], lv['r_vol'], dropna=False)
            ct_counts = ct_counts.reindex(index=line_labels, columns=vol_labels2, fill_value=0)
            ct_counts['Totales'] = ct_counts.sum(axis=1)

            # üîπ Total de l√≠neas (sumando l√≠neas, no volumen)
            pivot_lines = pd.pivot_table(
                lv, index='r_lineas',
                values='lineas', aggfunc='sum', fill_value=0
            ).reindex(index=line_labels, fill_value=0)
            pivot_lines['% linea'] = (pivot_lines['lineas'] / pivot_lines['lineas'].sum() * 100).round(2)

            # Volumen total (solo para fila de "Espacio total")
            pivot_vol = pd.pivot_table(
                lv, index='r_lineas', columns='r_vol',
                values='volumen_total', aggfunc='sum', fill_value=0
            ).reindex(index=line_labels, columns=vol_labels2, fill_value=0).round(2)

            # Construir tabla combinada
            data_cross = []

            # Encabezado combinado
            data_cross.append(
                ['L√≠neas por orden'] 
                + ['Volumen por pedido (pies¬≥)']*len(vol_labels2) 
                + ['Totales','% pedidos','Total L√≠nea','% l√≠nea']
            )
            data_cross.append(
                [''] + vol_labels2 + ['Totales','% pedidos','Total L√≠nea','% l√≠nea']
            )

            # Filas por r_lineas
            for idx in line_labels:
                row_counts = ct_counts.loc[idx, vol_labels2].tolist()
                row_total = ct_counts.loc[idx, 'Totales']
                row_pct_pedidos = (row_total / ct_counts['Totales'].sum() * 100).round(2)
                row_total_linea = int(pivot_lines.loc[idx, 'lineas'])  # üîπ ahora es la suma de l√≠neas
                row_pct_linea = float(pivot_lines.loc[idx, '% linea'])
                data_cross.append([idx] + row_counts + [row_total, row_pct_pedidos, row_total_linea, row_pct_linea])

            # üëâ Fila de Totales
            tot_row_counts = ct_counts[vol_labels2].sum().tolist()
            tot_total = ct_counts['Totales'].sum()
            tot_pct_pedidos = 100.0
            tot_total_linea = int(pivot_lines['lineas'].sum())  # üîπ total l√≠neas global
            tot_pct_linea = 100.0
            data_cross.append(['Totales'] + tot_row_counts + [tot_total, tot_pct_pedidos, tot_total_linea, tot_pct_linea])

            # Fila de % pedidos (por columna de volumen + total)
            pct_pedidos_cols = (ct_counts[vol_labels2].sum() / ct_counts['Totales'].sum() * 100).round(2).tolist()
            pct_pedidos_total = round(sum(pct_pedidos_cols), 2)
            row_pct_pedidos = ['% pedidos'] + pct_pedidos_cols + [pct_pedidos_total, '', '', '']
            data_cross.append(row_pct_pedidos)

            # Fila de volumen total por columna
            vol_values = pivot_vol[vol_labels2].sum().round(2).tolist()
            row_vol_total = ['Espacio total'] + vol_values + [pivot_vol.values.sum().round(2), '', '', '']
            data_cross.append(row_vol_total)

            # Configurar tabla PDF
            col_widths_cross = [50] + [50]*len(vol_labels2) + [50,50,50,50]
            t_cross = Table(data_cross, colWidths=col_widths_cross, hAlign='CENTER')
            t_cross.setStyle(TableStyle([
                ('SPAN',(1,0),(len(vol_labels2),0)),  # unir fila 0 columnas de volumen
                ('SPAN',(len(vol_labels2)+1,0),(len(vol_labels2)+1,1)),  # Totales
                ('SPAN',(len(vol_labels2)+2,0),(len(vol_labels2)+2,1)),  # % pedidos
                ('SPAN',(len(vol_labels2)+3,0),(len(vol_labels2)+3,1)),  # Total L√≠nea
                ('SPAN',(len(vol_labels2)+4,0),(len(vol_labels2)+4,1)),  # % l√≠nea
                ('GRID',(0,0),(-1,-1),0.5,colors.black),
                ('BACKGROUND',(0,0),(-1,1),colors.lightgrey),
                ('BACKGROUND',(0,-3),(-1,-3),colors.lightgrey),  # Totales fila
                ('BACKGROUND',(0,-2),(-1,-2),colors.whitesmoke),  # % pedidos
                ('BACKGROUND',(0,-1),(-1,-1),colors.whitesmoke),  # espacio total
                ('FONTSIZE',(0,0),(-1,-1),6),
                ('ALIGN',(0,0),(-1,-1),'CENTER'),
                ('VALIGN',(0,0),(-1,-1),'MIDDLE')
            ]))
            elems.append(Paragraph('Tabla cruzada: l√≠neas por orden vs volumen', styles['Heading2']))
            cross_intro = """
            Permite ver cu√°ntos pedidos combinan cierta cantidad de l√≠neas con un rango de volumen determinado, 
            junto con totales, porcentaje de pedidos y porcentaje de l√≠neas. 
            Esto ayuda a identificar combinaciones de pedidos frecuentes o cr√≠ticas y optimizar la disposici√≥n de la bodega y flujos de picking.
            """
            elems.append(Paragraph(cross_intro, styles['Normal']))
            elems.append(Spacer(1, 6))
            elems.append(t_cross)
            elems.append(Spacer(1, 10))


            # -------------------------------
            # Construir PDF
            # -------------------------------
            doc.build(elems)
            buffer.seek(0)
            st.download_button(
                'üìÑ Descargar Informe PDF',
                data=buffer.getvalue(),
                file_name='informe_super_abc_completo.pdf',
                mime='application/pdf'
            )

st.success('Listo. Ajusta cortes y vuelve a calcular seg√∫n necesites.')
