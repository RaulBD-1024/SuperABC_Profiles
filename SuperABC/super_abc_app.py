"""
Inventory Insight App Interactiva
=====================================

Versi√≥n mejorada:
- ABC por contribuci√≥n (el usuario define cortes A/B por criterio)
- Combinaci√≥n de dos criterios en AA..CC
- Resumen extendido (incluye % ventas por categor√≠a)
- Perfiles solicitados (l√≠neas por orden, cubicaje por orden, d√≠as, tabla cruzada)
- CSV export con nombres sanitizados (sin caracteres especiales)
- Generaci√≥n opcional de informe PDF (requiere reportlab + matplotlib)
"""

import io
import unicodedata
import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st

import statsmodels.api as sm
from prophet import Prophet
from prophet.plot import plot_plotly, plot_components_plotly


# Para generar PDF/plots
try:
    import matplotlib.pyplot as plt
    from reportlab.lib.pagesizes import letter
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table
    from reportlab.lib.styles import getSampleStyleSheet
    PDF_LIBS_AVAILABLE = True
except Exception:
    PDF_LIBS_AVAILABLE = False

# -------------------------------
# Utilidades
# -------------------------------

def sanitize_filename(s: str) -> str:
    # elimina acentos y caracteres especiales, deja ascii y guiones bajos
    s = str(s)
    s = unicodedata.normalize('NFKD', s)
    s = s.encode('ascii', 'ignore').decode('ascii')
    s = s.replace(' ', '_')
    allowed = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_-"
    return ''.join(c for c in s if c in allowed)

def sanitize_colnames(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [unicodedata.normalize('NFKD', str(c)).encode('ascii','ignore').decode('ascii') for c in df.columns]
    df.columns = [c.replace(' ', '_') for c in df.columns]
    return df

def minmax_normalize(s: pd.Series) -> pd.Series:
    s = s.fillna(0)
    rng = s.max() - s.min()
    if rng == 0:
        return pd.Series(np.zeros(len(s)), index=s.index)
    return (s - s.min()) / rng

@st.cache_data(show_spinner=False, ttl=3600)  # Cache por 1 hora
def read_excel_bytes(file_bytes: bytes, sheet_name=None):
    """
    Lee un archivo Excel desde bytes.
    
    Args:
        file_bytes: Bytes del archivo Excel
        sheet_name: Nombre de la hoja a leer (None para todas las hojas)
    
    Returns:
        DataFrame si sheet_name est√° especificado, dict si no
    """
    try:
        if sheet_name:
            # Leer hoja espec√≠fica
            return pd.read_excel(io.BytesIO(file_bytes), sheet_name=sheet_name, engine='openpyxl')
        else:
            # Leer todas las hojas
            return pd.read_excel(io.BytesIO(file_bytes), sheet_name=None, engine='openpyxl')
    except Exception as e:
        # Si falla con openpyxl, intentar con xlrd para archivos .xls
        try:
            return pd.read_excel(io.BytesIO(file_bytes), sheet_name=sheet_name, engine='xlrd')
        except:
            raise e

# ABC por contribuci√≥n acumulada

def safe_col(df: pd.DataFrame, name: str, alt_names=None):
    """Busca una columna tolerando espacios, may√∫sculas/min√∫sculas o nombres alternativos."""
    if alt_names is None:
        alt_names = []
    # Diccionario para b√∫squeda insensible a may√∫sculas/min√∫sculas y espacios
    alt = {c.strip().lower(): c for c in df.columns}
    key = name.strip().lower()
    # Revisar nombre principal
    if key in alt:
        return df[alt[key]]
    # Revisar nombres alternativos
    for alt_name in alt_names:
        k = alt_name.strip().lower()
        if k in alt:
            return df[alt[k]]
    raise KeyError(f"No se encontr√≥ la columna requerida: {name}")


def cycle_count_freq(zone: str) -> str:
    return {'Oro':'Semanal/Mensual','Plata':'Mensual/Trimestral','Bronce':'Trimestral/Semestral'}.get(zone, 'Trimestral')


def abc_by_contribution(series: pd.Series, A_cut: float, B_cut: float) -> pd.Series:
    df_tmp = series.rename('metric').to_frame()
    df_tmp = df_tmp.sort_values('metric', ascending=False)
    total = df_tmp['metric'].sum()
    if total <= 0:
        return pd.Series('C', index=series.index)
    df_tmp['cum_contrib'] = df_tmp['metric'].cumsum() / total
    df_tmp['cls'] = np.where(df_tmp['cum_contrib'] <= A_cut, 'A', np.where(df_tmp['cum_contrib'] <= B_cut, 'B', 'C'))
    return df_tmp['cls'].reindex(series.index)

@st.cache_data(show_spinner=False, ttl=1800)  # Cache por 30 minutos
def generate_super_abc_combinations(by_item: pd.DataFrame, criterios_seleccionados: list, cortes_abc: dict, criterios_map: dict) -> pd.DataFrame:
    """
    Genera todas las combinaciones posibles de clasificaciones ABC para m√∫ltiples criterios.
    
    Args:
        by_item: DataFrame con m√©tricas por art√≠culo
        criterios_seleccionados: Lista de criterios seleccionados
        cortes_abc: Diccionario con los cortes A y B para cada criterio
        criterios_map: Mapeo de nombres de criterios a columnas del DataFrame
    
    Returns:
        DataFrame con las clasificaciones ABC para cada criterio y la combinaci√≥n final
    """
    import itertools
    
    # Calcular clasificaci√≥n ABC para cada criterio
    for criterio in criterios_seleccionados:
        col_name = criterios_map[criterio]
        A_cut = cortes_abc[criterio]['A']
        B_cut = cortes_abc[criterio]['B']
        by_item[f'ABC_{criterio}'] = abc_by_contribution(by_item[col_name], A_cut, B_cut)
    
    # Generar todas las combinaciones posibles
    abc_values = ['A', 'B', 'C']
    combinaciones = list(itertools.product(abc_values, repeat=len(criterios_seleccionados)))
    
    # Crear la clasificaci√≥n combinada
    def create_combination_class(row):
        combination = ''.join([row[f'ABC_{criterio}'] for criterio in criterios_seleccionados])
        return combination
    
    by_item['Clase_SuperABC'] = by_item.apply(create_combination_class, axis=1)
    
    return by_item

# Map zone from combined class

def map_zone(clase: str) -> str:
    """
    Mapea una clase de S√∫per ABC a una zona de bodega.
    Para m√∫ltiples criterios, se basa en la prioridad de las letras A, B, C.
    """
    # Si tiene al menos una A, va a Oro
    if 'A' in clase:
        return 'Oro'
    # Si tiene al menos una B (y no A), va a Plata
    elif 'B' in clase:
        return 'Plata'
    # Si solo tiene C, va a Bronce
    else:
        return 'Bronce'

def policy_by_demand(cv: float, intermittency: float) -> str:
    if intermittency >= 0.5:
        return 'RTP-EOQ (items intermitentes)'
    if cv < 0.5:
        return 'ROP-OUL (alta estabilidad)'
    if cv < 1.0:
        return 'ROP-EOQ (variabilidad media)'
    return 'RTP-EOQ (alta variabilidad)'

# Fill rates nuevos (usar guion ASCII)

def target_fill_rate(zone: str) -> str:
    if zone == 'Oro':
        return '99-90%'
    if zone == 'Plata':
        return '89-80%'
    if zone == 'Bronce':
        return '70-80%'
    return '80-90%'

# Week floor
from datetime import datetime

def week_floor(dt: pd.Series) -> pd.Series:
    return dt.dt.to_period('W-MON').dt.start_time

# -------------------------------
# UI
# -------------------------------
st.set_page_config(page_title='Inventory Insight App', layout='wide')
st.title('üì¶ Inventory Insight App')

st.markdown("""
Bienvenido a **Inventory Insight App** üöÄ  

Esta herramienta integral permite analizar y optimizar la gesti√≥n de inventarios mediante una clasificaci√≥n **S√∫per ABC** multi-criterio, an√°lisis de distribuci√≥n de bodega y pron√≥sticos avanzados.  

### üéØ **Funcionalidades Principales:**

#### üìä **1. An√°lisis S√∫per ABC Multi-Criterio**
- Clasificaci√≥n combinada de productos seg√∫n el principio de Pareto
- M√∫ltiples criterios simult√°neos (ventas, popularidad, rotaci√≥n, volumen)
- Pol√≠ticas de inventario personalizadas por categor√≠a
- Zonificaci√≥n autom√°tica de bodega (Oro, Plata, Bronce)

#### üèóÔ∏è **2. Distribuci√≥n Inteligente de Bodega**
- An√°lisis detallado por SKU con c√°lculos de inventario √≥ptimo
- C√°lculo de racks, pallets y espacio necesario por categor√≠a
- Tablas de vol√∫menes y distribuci√≥n porcentual
- Optimizaci√≥n de utilizaci√≥n de espacio

#### üìà **3. Perfiles de Actividad Avanzados**
- An√°lisis de Pareto de popularidad
- Distribuci√≥n de l√≠neas por pedido
- Perfiles de cubicaje y carga unitaria
- An√°lisis cruzado l√≠neas vs volumen

#### üîÆ **4. Pron√≥sticos y Forecasting**
- Pron√≥sticos individuales por SKU
- Pron√≥sticos por categor√≠a ABC
- Modelos Prophet y estad√≠sticos
- An√°lisis de tendencias y estacionalidad

#### üìã **5. An√°lisis de Contribuci√≥n**
- Contribuci√≥n por categor√≠a ABC a ventas, volumen y popularidad
- Visualizaciones comparativas
- M√©tricas de impacto por categor√≠a

#### üì• **6. Exportaci√≥n Completa**
- Excel con m√∫ltiples hojas organizadas
- Gr√°ficas integradas en Excel
- Perfiles de actividad detallados
- Reportes PDF profesionales

### üöÄ **Gu√≠a de uso:**
1. **Carga de datos** ‚Üí Sube tu Excel con datos de ventas
2. **Configuraci√≥n** ‚Üí Define criterios y cortes ABC
3. **An√°lisis S√∫per ABC** ‚Üí Clasificaci√≥n autom√°tica multi-criterio
4. **Perfiles de Actividad** ‚Üí An√°lisis detallado de patrones
5. **Distribuci√≥n de Bodega** ‚Üí Optimizaci√≥n de espacio y racks
6. **Pron√≥sticos** ‚Üí Forecasting avanzado por SKU y categor√≠a
7. **Exportaci√≥n** ‚Üí Descarga resultados completos

‚ÑπÔ∏è Esta aplicaci√≥n est√° pensada como apoyo para decisiones de **gesti√≥n de inventario y almacenamiento**, facilitando el an√°lisis ABC tradicional y extendido.
""")

# -------------------------------
# Advertencia sobre formato del Excel
# -------------------------------
st.info("""
üìÇ **Configuraci√≥n del archivo Excel requerida:**

El archivo debe contener **exactamente** las siguientes columnas (respetando los nombres, aunque la aplicaci√≥n es tolerante a espacios y may√∫sculas/min√∫sculas):

- `Art√≠culo` ‚Üí Identificador √∫nico del producto  
- `Unid. Vend` ‚Üí Cantidad de unidades vendidas  
- `Monto venta` ‚Üí Monto total de venta  
- `Volumen total (p3) o Volumen total (m3)` ‚Üí Volumen total del producto. Puede estar en **pies¬≥** o **metros¬≥**. La unidad se selecciona en el panel lateral y se convertir√° autom√°ticamente para los c√°lculos internos.  
- `Num. Doc` ‚Üí N√∫mero de documento / pedido  
- `Fecha Doc` ‚Üí Fecha del documento/pedido en formato DD/MM/AAAA. 

‚ö†Ô∏è **Importante:** Si alguna columna no existe o tiene un nombre diferente, la aplicaci√≥n no podr√° procesar los datos correctamente.  
Aseg√∫rate de seleccionar la unidad correcta en la barra lateral para que los c√°lculos de volumen sean consistentes.

üìã **Ejemplo de estructura del archivo Excel:**
```
| Art√≠culo | Unid. Vend | Monto venta | Volumen total (p3) | Num. Doc | Fecha Doc |
|----------|------------|-------------|-------------------|----------|-----------|
| PROD001  | 100        | 1500.00     | 2.5               | DOC001   | 15/01/2024|
| PROD002  | 50         | 750.00      | 1.2               | DOC002   | 16/01/2024|
```
""")

with st.sidebar:
    st.header('1) Cargar datos')
    uploaded_file = st.file_uploader('Excel de ventas/ordenes', type=['xlsx','xls'])
    sheet_name = st.text_input('Hoja (opcional)', help='Si tu Excel tiene m√∫ltiples hojas, especifica cu√°l usar. Si no especificas, se usar√° la primera.')
    unit_vol = st.selectbox('Unidad de volumen', ['pies3 (p3)','metros3 (m3)'])
    vol_factor = 35.3147 if unit_vol == 'metros3 (m3)' else 1.0

    # Permitir al usuario definir el volumen de una tarima
    default_tarima = 42.38 if unit_vol == 'pies3 (p3)' else 1.2
    vol_tarima = st.number_input(
        'Volumen de una tarima completa',
        min_value=0.01,
        value=default_tarima,
        help='Define el volumen de una tarima en la unidad seleccionada'
    )
    # Guardar en session_state para usarlo en PDF y an√°lisis
    st.session_state['vol_tarima'] = vol_tarima

    st.header('2) Criterios ABC (elige m√∫ltiples)')
    criterios = {
        'Popularidad': 'popularidad',
        'Rotacion': 'rotacion_sem',
        'Ventas': 'ventas',
        'Volumen': 'volumen'
    }
    
    # Permitir selecci√≥n m√∫ltiple de criterios
    criterios_seleccionados = st.multiselect(
        'Selecciona los criterios a aplicar (m√≠nimo 2):',
        list(criterios.keys()),
        default=['Popularidad', 'Ventas'],
        help='Puedes seleccionar 2 o m√°s criterios. Se generar√°n todas las combinaciones posibles.'
    )
    
    # Validar que se seleccionen al menos 2 criterios
    if len(criterios_seleccionados) < 2:
        st.warning('‚ö†Ô∏è Debes seleccionar al menos 2 criterios para continuar.')
        st.stop()
    
    # Mostrar informaci√≥n sobre las combinaciones que se generar√°n
    num_combinaciones = 3 ** len(criterios_seleccionados)  # A, B, C para cada criterio
    st.info(f"üìä Se generar√°n {num_combinaciones} combinaciones posibles (A, B, C para cada criterio)")
    
    # Para compatibilidad con el c√≥digo existente, mantener crit1 y crit2
    crit1 = criterios_seleccionados[0]
    crit2 = criterios_seleccionados[1] if len(criterios_seleccionados) > 1 else criterios_seleccionados[0]

    st.header('3) Cortes ABC por contribucion (A, B)')
    
    # Crear sliders din√°micos para cada criterio seleccionado
    cortes_abc = {}
    for i, criterio in enumerate(criterios_seleccionados):
        st.subheader(f'Criterio: {criterio}')
        A_cut = st.slider(f'A ({criterio})', 50, 95, 80, key=f'A_cut_{criterio}_{i}') / 100.0
        B_cut = st.slider(f'B ({criterio})', int(A_cut*100)+1, 99, 95, key=f'B_cut_{criterio}_{i}') / 100.0
        cortes_abc[criterio] = {'A': A_cut, 'B': B_cut}
    
    # Guardar en session_state usando claves √∫nicas
    st.session_state['criterios_seleccionados'] = criterios_seleccionados
    st.session_state['cortes_abc'] = cortes_abc

    # Configuraci√≥n de exportaci√≥n (se mover√° al final)
    st.session_state['want_csv'] = st.checkbox('Permitir descarga Excel', True)
    st.session_state['gen_pdf'] = st.checkbox('Generar informe PDF', False)

if uploaded_file is None:
    st.info('Sube un Excel para comenzar')
    st.stop()

# -------------------------------
# Leer datos
# -------------------------------
try:
    df = read_excel_bytes(uploaded_file.read(), sheet_name=sheet_name or None)
    
    # Verificar si df es un diccionario (m√∫ltiples hojas)
    if isinstance(df, dict):
        st.warning("‚ö†Ô∏è El archivo Excel contiene m√∫ltiples hojas.")
        st.write("**Hojas disponibles:**", list(df.keys()))
        
        if sheet_name and sheet_name in df:
            df = df[sheet_name]
            st.info(f"‚úÖ Usando la hoja especificada: '{sheet_name}'")
        else:
            # Si no se especific√≥ hoja, usar la primera
            primera_hoja = list(df.keys())[0]
            df = df[primera_hoja]
            st.info(f"‚úÖ Usando la primera hoja: '{primera_hoja}'")
            st.write("üí° **Tip:** Puedes especificar una hoja espec√≠fica en el campo 'Hoja (opcional)' en la barra lateral")
    
    # Verificar que df es un DataFrame
    if not isinstance(df, pd.DataFrame):
        st.error("‚ùå Error: No se pudo cargar el archivo como DataFrame")
        st.stop()
    
    # Mostrar informaci√≥n del archivo cargado
    st.success(f"‚úÖ Archivo cargado exitosamente: {uploaded_file.name}")
    st.info(f"üìä Dimensiones del archivo: {df.shape[0]} filas x {df.shape[1]} columnas")
    
    # Mostrar las columnas disponibles
    st.subheader("üìã Columnas disponibles en el archivo:")
    columnas_disponibles = list(df.columns)
    st.write(columnas_disponibles)
    
    # Verificar si existe la columna 'Art√≠culo'
    if 'Art√≠culo' not in df.columns:
        st.error("‚ùå No se encontr√≥ la columna 'Art√≠culo' en el archivo.")
        st.write("**Columnas disponibles:**", columnas_disponibles)
        st.write("**Por favor verifica que tu archivo Excel contenga una columna llamada 'Art√≠culo'**")
        st.stop()
    
    # Limpiar espacios y may√∫sculas/min√∫sculas
    df['Art√≠culo_LIMPIO'] = df['Art√≠culo'].astype(str).str.strip().str.upper()
    
except Exception as e:
    st.error(f'Error leyendo Excel: {e}')
    st.write("**Posibles causas:**")
    st.write("- El archivo no es un Excel v√°lido")
    st.write("- El archivo est√° corrupto")
    st.write("- No tienes permisos para leer el archivo")
    st.write("- El archivo est√° siendo usado por otra aplicaci√≥n")
    st.write("- El archivo tiene m√∫ltiples hojas y no se especific√≥ cu√°l usar")
    st.stop()

# map columns tolerant
try:
    st.subheader("üîç Verificando columnas requeridas...")
    
    # Verificar cada columna requerida
    columnas_requeridas = {
        'Unid. Vend': ['Unid. Vend', 'Unidades Vendidas', 'Cantidad', 'Qty'],
        'Monto venta': ['Monto venta', 'Monto Venta', 'Valor', 'Total'],
        'Volumen total (p3)': ['Volumen total (p3)', 'Volumen total (m3)', 'Volumen total', 'Volumen'],
        'Num. Doc': ['Num. Doc', 'Num Doc', 'Documento', 'Pedido', 'Order'],
        'Fecha Doc': ['Fecha Doc', 'Fecha Doc', 'Fecha', 'Date']
    }
    
    columnas_faltantes = []
    for col_principal, alternativas in columnas_requeridas.items():
        encontrada = False
        for alt in alternativas:
            if alt in df.columns:
                encontrada = True
                break
        if not encontrada:
            columnas_faltantes.append(f"{col_principal} (alternativas: {', '.join(alternativas)})")
    
    if columnas_faltantes:
        st.error("‚ùå Faltan las siguientes columnas requeridas:")
        for col in columnas_faltantes:
            st.write(f"- {col}")
        st.write("**Por favor verifica que tu archivo Excel contenga todas las columnas requeridas.**")
        st.stop()
    
    # Mapear columnas
    art = df['Art√≠culo_LIMPIO']
    unid = pd.to_numeric(safe_col(df, 'Unid. Vend'), errors='coerce').fillna(0)
    monto = pd.to_numeric(safe_col(df, 'Monto venta'), errors='coerce').fillna(0)
    vol = pd.to_numeric(safe_col(df, 'Volumen total (p3)', alt_names=['Volumen total (m3)', 'Volumen total']), errors='coerce').fillna(0) * vol_factor
    numdoc = safe_col(df, 'Num. Doc').astype(str)
    fecha = pd.to_datetime(safe_col(df, 'Fecha Doc'), errors='coerce')
    # Opcional: Unidades por caja (si existe en el Excel)
    unidades_por_caja_src = pd.to_numeric(
        safe_col(df, 'Cant x Caja', alt_names=['Cant x Caja','Cant. x Caja','Unid x Caja','Unid. x Caja','Unidades por caja','Unid por caja']),
        errors='coerce'
    )
    
    st.success("‚úÖ Todas las columnas requeridas fueron encontradas y mapeadas correctamente")
    
except Exception as e:
    st.error(f'Error mapeando columnas: {e}')
    st.write("**Posibles causas:**")
    st.write("- Los nombres de las columnas no coinciden exactamente")
    st.write("- Hay caracteres especiales o espacios extra en los nombres")
    st.write("- El formato de los datos no es el esperado")
    st.stop()

base = pd.DataFrame({
    'Articulo': art,
    'Unidades': unid,
    'Monto': monto,
    'Volumen_p3': vol,
    'NumDoc': numdoc,
    'Fecha': fecha,
    'Cajas_vendidas': pd.to_numeric(safe_col(df, 'Cajas vend.'), errors='coerce').fillna(0),
    'Unidades_por_caja': unidades_por_caja_src
}).dropna(subset=['Fecha'])

# Guardar base en session_state para usarlo en PDF y perfiles
st.session_state['base'] = base

if len(base) == 0:
    st.error('No hay registros con fecha valida')
    st.stop()

st.write("Primeras filas de base:")
st.dataframe(base.head())
st.write("Suma Unidades:", base['Unidades'].sum())
st.write("Suma Cajas_vendidas:", base['Cajas_vendidas'].sum())

# -------------------------------
# Calcular Super ABC
# -------------------------------
st.subheader('‚ñ∂Ô∏è Control de secciones')

if st.button('1) Calcular S√∫per ABC'):
    by_item = base.groupby('Articulo').agg(
        popularidad=('NumDoc','nunique'),
        unidades=('Unidades','sum'),
        ventas=('Monto','sum'),
        volumen=('Volumen_p3','sum'),
        lineas=('NumDoc','count')
    )
    # rotacion semanal (optimizado)
    with st.spinner("Calculando rotaci√≥n semanal..."):
        days_range = (base['Fecha'].max() - base['Fecha'].min()).days + 1
        weeks_range = max(1, days_range/7)
        by_item['rotacion_sem'] = by_item['unidades'] / weeks_range

    # Usar la nueva funci√≥n para generar combinaciones m√∫ltiples
    by_item = generate_super_abc_combinations(
        by_item, 
        criterios_seleccionados, 
        cortes_abc, 
        criterios
    )

    # Mostrar art√≠culos con problemas de clasificaci√≥n
    # Verificar si hay valores NaN en las clasificaciones ABC
    abc_columns = [f'ABC_{criterio}' for criterio in criterios_seleccionados]
    problemas_mask = by_item[abc_columns].isna().any(axis=1) | by_item['Clase_SuperABC'].str.contains('nan')
    problemas = by_item[problemas_mask]
    
    if not problemas.empty:
        st.warning(f"Hay {len(problemas)} art√≠culos sin clase v√°lida. Mira la tabla abajo para revisar:")
        st.dataframe(problemas)
    else:
        st.info("Todos los art√≠culos tienen clase v√°lida.")

    # stats semanales
    base['WeekStart'] = week_floor(base['Fecha'])
    weekly = base.groupby(['Articulo','WeekStart']).agg(units=('Unidades','sum')).reset_index()
    with st.spinner("Calculando estad√≠sticas semanales..."):
        stats = weekly.pivot_table(index='Articulo', values='units', aggfunc=[np.mean, np.std, lambda x: (x==0).mean()])
        stats.columns = ['mean_week','std_week','intermittency']
        by_item = by_item.join(stats, how='left')
        by_item['cv'] = by_item['std_week'] / by_item['mean_week'].replace(0, np.nan)
        by_item['cv'] = by_item['cv'].fillna(np.inf)
        by_item['intermittency'] = by_item['intermittency'].fillna(1.0)

    by_item['Zona_Bodega'] = by_item['Clase_SuperABC'].apply(map_zone)
    by_item['Pol√≠tica_Inv'] = [policy_by_demand(cv, ii) for cv, ii in zip(by_item['cv'], by_item['intermittency'])]
    by_item['FillRate_obj'] = by_item['Zona_Bodega'].apply(target_fill_rate)
    by_item['Frecuencia_Recuento'] = by_item['Zona_Bodega'].apply(cycle_count_freq)

    st.session_state['by_item'] = by_item
    st.session_state['criterios_seleccionados'] = criterios_seleccionados
    st.session_state['crit1_name'] = crit1
    st.session_state['crit2_name'] = crit2
    st.success(f'S√∫per ABC calculado correctamente con {len(criterios_seleccionados)} criterios üéØ')

    # -------------------------------
    # Guardar by_item limpio como perfil
    # -------------------------------
    export_df = by_item.reset_index().copy()
    export_df.columns = [unicodedata.normalize('NFKD', str(c)).encode('ascii','ignore').decode('ascii') for c in export_df.columns]

    if 'FillRate_obj' in export_df.columns:
        export_df['FillRate_obj'] = export_df['FillRate_obj'].astype(str).str.replace('‚Äì','-', regex=False).str.replace('‚Äî','-', regex=False)

    export_df = sanitize_colnames(export_df)
    st.session_state['perfil_by_item_sanitizado'] = export_df


    # --- Comparaci√≥n de art√≠culos √∫nicos para detectar p√©rdidas ---
    articulos_excel = set(df['Art√≠culo'].astype(str).unique())
    articulos_base = set(base['Articulo'].unique())
    articulos_by_item = set(by_item.index)

    faltan_en_base = articulos_excel - articulos_base
    faltan_en_by_item = articulos_base - articulos_by_item

    st.write(f"Total art√≠culos en Excel: {len(articulos_excel)}")
    st.write(f"Total art√≠culos en base (con fecha v√°lida): {len(articulos_base)}")
    st.write(f"Total art√≠culos en by_item (agrupados): {len(articulos_by_item)}")

    if faltan_en_base:
        st.warning(f"Art√≠culos en Excel pero no en base (probablemente por fecha vac√≠a o inv√°lida): {faltan_en_base}")
    if faltan_en_by_item:
        st.warning(f"Art√≠culos en base pero no en by_item (posible error de agrupaci√≥n): {faltan_en_by_item}")
    if not faltan_en_base and not faltan_en_by_item:
        st.info("No se pierden art√≠culos en ninguna etapa del procesamiento.")
# -------------------------------
# Mostrar resumen y perfiles
# -------------------------------
def ira_by_class(clase: str) -> str:
    """
    Determina el IRA (Inventory Record Accuracy) basado en la clase de S√∫per ABC.
    Para m√∫ltiples criterios, se basa en la prioridad de las letras A, B, C.
    """
    # Contar la cantidad de cada letra
    count_a = clase.count('A')
    count_b = clase.count('B')
    count_c = clase.count('C')
    
    # Determinar IRA basado en la prioridad
    if count_a >= 2:  # M√∫ltiples A
        return '> 95%'
    elif count_a == 1 and count_b >= 1:  # Una A y al menos una B
        return '94% - 95%'
    elif count_a == 1:  # Solo una A
        return '92% - 94%'
    elif count_b >= 2:  # M√∫ltiples B
        return '90% - 92%'
    elif count_b == 1:  # Solo una B
        return '88% - 90%'
    elif count_c >= 2:  # M√∫ltiples C
        return '86% - 88%'
    elif count_c == 1:  # Solo una C
        return '84% - 86%'
    else:
        return '< 80%'

if 'by_item' in st.session_state:
    by_item = st.session_state['by_item']

    # -------------------------------
    # Secci√≥n 2: Perfiles de Actividad
    # -------------------------------
    with st.expander("üìà Perfiles de Actividad", expanded=False):
        # Mostrar informaci√≥n sobre los criterios utilizados
        criterios_usados = st.session_state.get('criterios_seleccionados', [crit1, crit2])
        st.subheader(f'üìã Resumen por categor√≠a - Criterios: {", ".join(criterios_usados)}')
        
        # Mostrar estad√≠sticas de las combinaciones generadas
        combinaciones_unicas = by_item['Clase_SuperABC'].nunique()
        st.info(f"Se generaron {combinaciones_unicas} combinaciones √∫nicas de clasificaci√≥n ABC")
        
        summary = by_item.groupby('Clase_SuperABC').agg(
            Cantidad=('Clase_SuperABC','count'),
            Zona_Bodega=('Zona_Bodega','first'),
            Politica=('Pol√≠tica_Inv','first'),
            FillRate=('FillRate_obj','first'),
            Ventas=('ventas','sum'),
            Frecuencia_Recuento=('Frecuencia_Recuento','first')
        ).reset_index()

        # Insertar columna IRA despu√©s de FillRate
        summary['IRA'] = summary['Clase_SuperABC'].apply(ira_by_class)

        summary['Porcentaje'] = (summary['Cantidad']/summary['Cantidad'].sum()*100).round(2)
        total_sales = summary['Ventas'].sum()
        summary['% Ventas'] = (100 * summary['Ventas'] / (total_sales if total_sales>0 else 1)).round(2)

        # Ordenar categor√≠as - para m√∫ltiples criterios, ordenar alfab√©ticamente
        summary = summary.sort_values('Clase_SuperABC')

        # Reordenar columnas para que IRA quede despu√©s de FillRate
        cols = ['Clase_SuperABC','Cantidad','Zona_Bodega','Politica','FillRate','IRA',
                'Frecuencia_Recuento','Ventas','Porcentaje','% Ventas']
        summary = summary[cols]

        st.dataframe(summary)
        st.session_state['perfil_resumen'] = summary

        # Perfil: lineas por orden (distribucion %)
        st.subheader('% de √≥rdenes por # l√≠neas')
        lines_per_order = base.groupby('NumDoc').agg(lineas=('Articulo','nunique')).reset_index()
        dist_lines = lines_per_order.groupby('lineas').size().rename('conteo').reset_index()
        total_orders = dist_lines['conteo'].sum()
        dist_lines['%_ordenes'] = 100 * dist_lines['conteo']/ (total_orders if total_orders>0 else 1)
        st.dataframe(dist_lines.sort_values('lineas'))
        fig_lines = px.bar(dist_lines.sort_values('lineas'), x='lineas', y='%_ordenes', labels={'lineas':'L√≠neas por orden','%_ordenes':'% de √≥rdenes'})
        st.plotly_chart(fig_lines, use_container_width=True)

        st.session_state['perfil_lineas'] = dist_lines

        # Perfil: cubicaje por orden
        st.subheader('% de √≥rdenes por rango de volumen (pies¬≥)')
        cubic_per_order = base.groupby('NumDoc').agg(volumen_total=('Volumen_p3','sum')).reset_index()
        vol_bins = [-1,1,2,5,10,20,50,1e9]
        vol_labels = ['‚â§1','1-2','2-5','5-10','10-20','20-50','>50']
        cubic_per_order['vol_bin'] = pd.cut(cubic_per_order['volumen_total'], bins=vol_bins, labels=vol_labels)
        dist_cubic = cubic_per_order.groupby('vol_bin').size().rename('conteo').reset_index()
        total_orders2 = dist_cubic['conteo'].sum()
        dist_cubic['%_ordenes'] = 100 * dist_cubic['conteo']/ (total_orders2 if total_orders2>0 else 1)
        st.dataframe(dist_cubic)
        fig_cubic = px.bar(dist_cubic, x='vol_bin', y='%_ordenes', labels={'vol_bin':'Rango volumen (pies¬≥)','%_ordenes':'% de √≥rdenes'})
        st.plotly_chart(fig_cubic, use_container_width=True)

        st.session_state['perfil_cubicaje'] = dist_cubic

        # Distribucion por dia de la semana
        st.subheader('Distribuci√≥n de √≥rdenes por d√≠a de la semana')
        orders_dates = base.groupby('NumDoc').agg(fecha=('Fecha','max')).reset_index()
        orders_dates['dia'] = orders_dates['fecha'].dt.day_name()
        mapping_days = {'Monday':'Lunes','Tuesday':'Martes','Wednesday':'Mi√©rcoles','Thursday':'Jueves','Friday':'Viernes','Saturday':'S√°bado','Sunday':'Domingo'}
        orders_dates['dia'] = orders_dates['dia'].replace(mapping_days)
        day_order = ['Lunes','Martes','Mi√©rcoles','Jueves','Viernes','S√°bado','Domingo']
        dist_days = orders_dates.groupby('dia').size().reindex(day_order).fillna(0).astype(int).rename('conteo').reset_index()
        dist_days['%_ordenes'] = 100 * dist_days['conteo'] / (dist_days['conteo'].sum() if dist_days['conteo'].sum()>0 else 1)
        st.dataframe(dist_days)
        fig_days = px.bar(dist_days, x='dia', y='%_ordenes', labels={'dia':'D√≠a','%_ordenes':'% de √≥rdenes'})
        st.plotly_chart(fig_days, use_container_width=True)

        st.session_state['perfil_dias'] = dist_days

        # Preparar datos
        lv = base.groupby('NumDoc').agg(
            lineas=('Articulo','nunique'),
            volumen_total=('Volumen_p3','sum')
        ).reset_index()

        # Par√°metro: volumen de una tarima completa (ajusta seg√∫n tu operaci√≥n)
        VOLUMEN_TARIMA = st.session_state.get('vol_tarima', 42.38)

        # % de carga unitaria respecto a una tarima
        lv['%_carga_unidad'] = 100 * lv['volumen_total'] / VOLUMEN_TARIMA
        lv['%_carga_unidad'] = lv['%_carga_unidad'].clip(upper=100)  # m√°ximo 100%

        # Bins para % de carga unitaria
        carga_bins = list(range(0, 105, 5))
        carga_labels = [f'{i}-{i+5}%' for i in range(0, 100, 5)]
        lv['r_carga'] = pd.cut(lv['%_carga_unidad'], bins=carga_bins, labels=carga_labels, right=True, include_lowest=True)
        
        # Distribuci√≥n cruzada: % l√≠neas de pedido vs % carga unitaria
        dist_incremento = lv.groupby(['r_carga']).agg(
            pedidos=('NumDoc', 'count'),
            lineas_prom=('lineas', 'mean')
        ).reset_index()
        dist_incremento['%_lineas_pedido'] = 100 * dist_incremento['pedidos'] / dist_incremento['pedidos'].sum()

        st.subheader('Distribuci√≥n por incremento de pedidos (% carga unitaria vs % de l√≠neas de pedido)')
        st.dataframe(dist_incremento.rename(columns={'%_lineas_pedido': '% de l√≠neas de pedido'}))
        fig_incremento = px.bar(
            dist_incremento,
            x='r_carga',
            y='%_lineas_pedido',
            labels={'r_carga': '% de carga unitaria (tarima)', '%_lineas_pedido': '% de l√≠neas de pedido'},
            title='% de l√≠neas de pedido por % de carga unitaria'
        )
        st.plotly_chart(fig_incremento, use_container_width=True)

        st.session_state['perfil_carga'] = dist_incremento

        # -------------------------------
        # Tabla cruzada l√≠neas x volumen por pedido
        # -------------------------------
        st.subheader('Tabla cruzada: L√≠neas por pedido vs pies¬≥ por pedido')

        # Categor√≠as
        line_labels = ['1','2-5','6-9','10+']
        lv['r_lineas'] = pd.cut(lv['lineas'], bins=[0,1,6,10,1e9], labels=line_labels, right=True, include_lowest=True)

        vol_labels = ['0-1','1-2','2-5','5-10','10-20','20+']
        lv['r_vol'] = pd.cut(lv['volumen_total'], bins=[0,1,2,5,10,20,1e9], labels=vol_labels, right=True, include_lowest=True)

        # Desglose de pedidos por rango de l√≠neas (incluyendo volumen)
        st.subheader('Desglose de pedidos por rango de l√≠neas')
        for rango in line_labels:
            pedidos_rango = lv[lv['r_lineas'] == rango][['NumDoc', 'lineas', 'volumen_total', 'r_vol']]
            st.markdown(f"**Rango {rango}: {len(pedidos_rango)} pedidos**")
            st.dataframe(pedidos_rango.reset_index(drop=True))

        # Conteo de pedidos por l√≠nea y volumen
        ct_counts = pd.crosstab(lv['r_lineas'], lv['r_vol'], dropna=False)

        # Totales de l√≠nea y % pedidos por l√≠nea
        ct_counts['Totales'] = ct_counts.sum(axis=1)
        ct_counts['% pedidos'] = (ct_counts['Totales'] / ct_counts['Totales'].sum() * 100).round(2)

        # üîπ Total de l√≠neas (sumando l√≠neas, no volumen)
        pivot_lines = pd.pivot_table(
            lv,
            index='r_lineas',
            values='lineas',
            aggfunc='sum',
            fill_value=0
        )
        total_lines_global = pivot_lines['lineas'].sum()
        pivot_lines['% linea'] = (pivot_lines['lineas'] / (total_lines_global if total_lines_global>0 else 1) * 100).round(2)

        # Crear tabla final con columnas en orden deseado
        table_final = pd.DataFrame(index=line_labels, columns=vol_labels + ['Totales','% pedidos','Total_Linea','% linea'])
        table_final[vol_labels] = ct_counts[vol_labels]
        table_final['Totales'] = ct_counts['Totales']
        table_final['% pedidos'] = ct_counts['% pedidos']
        table_final['Total_Linea'] = pivot_lines['lineas']
        table_final['% linea'] = pivot_lines['% linea']

        # Fila Totales
        totales_row = table_final[vol_labels].sum()
        totales_row['Totales'] = table_final['Totales'].sum()
        totales_row['% pedidos'] = 100
        totales_row['Total_Linea'] = table_final['Total_Linea'].sum()
        totales_row['% linea'] = 100
        table_final.loc['Totales'] = totales_row

        # Fila % pedidos (por columna)
        pct_pedidos_row = (table_final.loc[line_labels, vol_labels].sum() / table_final['Totales'].sum() * 100).round(2)
        pct_pedidos_row['Totales'] = 100
        pct_pedidos_row['% pedidos'] = np.nan
        pct_pedidos_row['Total_Linea'] = np.nan
        pct_pedidos_row['% linea'] = np.nan
        table_final.loc['% pedidos'] = pct_pedidos_row

        # Fila Espacio total (volumen)
        espacio_total_row = lv.groupby('r_vol')['volumen_total'].sum()
        espacio_total_row = espacio_total_row.reindex(vol_labels, fill_value=0)
        espacio_total_row['Totales'] = espacio_total_row.sum()
        espacio_total_row['% pedidos'] = np.nan
        espacio_total_row['Total_Linea'] = np.nan       # No calcular para espacio total
        espacio_total_row['% linea'] = np.nan           # No calcular para espacio total
        table_final.loc['Espacio total'] = espacio_total_row

        # Renombrar √≠ndice
        table_final.index.name = 'L√≠neas por orden / Volumen por orden'

        # Mostrar tabla
        st.dataframe(table_final.round(2))

        st.session_state['perfil_cruzado'] = table_final

        # Pareto popularidad
        st.subheader('Pareto de popularidad de √≠tems (picks acumulados)')
        pareto = by_item.sort_values('popularidad', ascending=False)[['popularidad']].copy()
        pareto['cum_picks'] = pareto['popularidad'].cumsum()
        total_picks = pareto['popularidad'].sum()
        pareto['cum_pct_picks'] = 100 * pareto['cum_picks'] / (total_picks if total_picks>0 else 1)
        pareto['sku_rank'] = np.arange(1, len(pareto)+1)
        pareto['pct_sku'] = 100 * pareto['sku_rank'] / len(pareto)
        st.dataframe(pareto.head(20))
        fig_pareto = px.line(pareto, x='pct_sku', y='cum_pct_picks', labels={'pct_sku':'% de SKU (acumulado)','cum_pct_picks':'% de picks (acumulado)'}, title='Curva de Pareto ‚Äì Popularidad')
        st.plotly_chart(fig_pareto, use_container_width=True)

        st.session_state['perfil_pareto'] = pareto


    # -------------------------------
    # Datos generales
    # -------------------------------
    file_name = st.session_state.get('file_name', uploaded_file.name if uploaded_file else 'Archivo no registrado')
    sheet_used = st.session_state.get('sheet_name', sheet_name or 'Hoja no registrada')
    vol_units = st.session_state.get('vol_units', unit_vol)
    criterios_usados = st.session_state.get('criterios_seleccionados', [crit1, crit2])
    cortes_abc = st.session_state.get('cortes_abc', {})
    
    # Para compatibilidad con c√≥digo existente
    crit1 = criterios_usados[0] if criterios_usados else 'Popularidad'
    crit2 = criterios_usados[1] if len(criterios_usados) > 1 else criterios_usados[0] if criterios_usados else 'Ventas'
    
    # Obtener cortes de la nueva estructura
    A_cut_1 = cortes_abc.get(crit1, {}).get('A', 0.8) if cortes_abc else 0.8
    B_cut_1 = cortes_abc.get(crit1, {}).get('B', 0.95) if cortes_abc else 0.95
    A_cut_2 = cortes_abc.get(crit2, {}).get('A', 0.8) if cortes_abc else 0.8
    B_cut_2 = cortes_abc.get(crit2, {}).get('B', 0.95) if cortes_abc else 0.95

    # -------------------------------
    # Crear hoja Portada
    # -------------------------------
    # Crear datos de portada din√°micamente
    portada_campos = ['Documento le√≠do', 'Hoja utilizada', 'Unidades de volumen', 'Criterios utilizados']
    portada_valores = [file_name, sheet_used, vol_units, ', '.join(criterios_usados)]
    
    # Agregar cortes para cada criterio
    for criterio in criterios_usados:
        if criterio in cortes_abc:
            portada_campos.extend([f'Corte A ({criterio})', f'Corte B ({criterio})'])
            portada_valores.extend([cortes_abc[criterio]['A'], cortes_abc[criterio]['B']])
    
    portada_data = {
        'Campo': portada_campos,
        'Valor': portada_valores
    }

    df_portada = pd.DataFrame(portada_data)
        
if 'by_item' in st.session_state:
    by_item = st.session_state['by_item']
    base = st.session_state['base']

    with st.expander("üîÆ Forecasting de Demanda por Art√≠culo", expanded=False):
        st.header('üîÆ Forecasting de Demanda por Art√≠culo')

        # Selecci√≥n de art√≠culo
        articulos = sorted(base['Articulo'].unique())
        articulo_sel = st.selectbox('Selecciona Art√≠culo para pron√≥stico', articulos, key='forecast_articulo')

        # Per√≠odo y cantidad de forecast
        periodo_forecast = st.selectbox('Periodo de forecast', ['Mensual', 'Semanal'], index=0)
        n_periods = st.number_input(f'Per√≠odos a pronosticar ({periodo_forecast.lower()})', min_value=1, max_value=52, value=4, step=1)

        # Unidad a pronosticar
        unidad_forecast = st.selectbox('Unidad a pronosticar', ['Unidades vendidas', 'Cajas vendidas'], index=0)
        columna_forecast = 'Unidades' if unidad_forecast=='Unidades vendidas' else 'Cajas_vendidas'

        # Filtrar datos
        base_art = base[base['Articulo']==articulo_sel].copy()
        if base_art.empty:
            st.warning("No hay registros para ese art√≠culo.")
            st.stop()
        for col in ['Unidades','Cajas_vendidas']:
            base_art[col] = pd.to_numeric(base_art.get(col,0), errors='coerce').fillna(0)

        # Serie hist√≥rica
        orders_df = base_art.groupby('NumDoc').agg(Fecha=('Fecha','max'),
                                                Unidades=('Unidades','sum'),
                                                Cajas_vendidas=('Cajas_vendidas','sum')).reset_index()
        resample_freq = 'MS' if periodo_forecast=='Mensual' else 'W-MON'
        date_offset = pd.DateOffset(months=1) if periodo_forecast=='Mensual' else pd.DateOffset(weeks=1)
        ts_art = orders_df.set_index('Fecha')[columna_forecast].resample(resample_freq).sum().fillna(0)
        st.subheader("Serie hist√≥rica")
        st.line_chart(ts_art)

        import numpy as np
        import pandas as pd
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.metrics import mean_absolute_error, mean_squared_error
        import plotly.graph_objects as go

        # Modelos
        modelos = ['Media m√≥vil (4 periodos)','Holt-Winters','Prophet','Random Forest']
        forecasts_dict = {}
        resultados = []

        for modelo in modelos:
            try:
                last_index = ts_art.index[-1]
                future_index = pd.date_range(start=last_index + date_offset, periods=n_periods, freq=resample_freq)
                forecast_future = None
                forecast_hist = None

                # ---------------- Media M√≥vil ----------------
                if modelo=='Media m√≥vil (4 periodos)':
                    ma = ts_art.rolling(window=4, min_periods=1).mean().shift(1)
                    ma = ma.fillna(ts_art)  # reemplazar NaN iniciales
                    forecast_future = pd.Series([ma.iloc[-1]]*n_periods, index=future_index)
                    forecast_hist = ma

                # ---------------- Holt-Winters ----------------
                elif modelo=='Holt-Winters':
                    if len(ts_art) >= 2:
                        # Detectar estacionalidad autom√°ticamente si hay suficientes ciclos
                        period = None
                        if periodo_forecast=='Mensual' and len(ts_art) >= 24:
                            period = 12
                        elif periodo_forecast=='Semanal' and len(ts_art) >= 104:
                            period = 52

                        hw = sm.tsa.ExponentialSmoothing(
                            ts_art,
                            trend='add',
                            seasonal='add' if period else None,
                            seasonal_periods=period,
                            initialization_method="estimated"
                        ).fit()
                        forecast_future = pd.Series(hw.forecast(n_periods).values, index=future_index)
                        forecast_hist = hw.fittedvalues
                    else:
                        st.info("Holt-Winters omitido por pocos datos.")

                # ---------------- Prophet ----------------
                elif modelo=='Prophet':
                    from prophet import Prophet
                    df_prophet = ts_art.reset_index().rename(columns={'Fecha':'ds', columna_forecast:'y'})
                    
                    if len(df_prophet) >= 3:
                        # Decidir autom√°ticamente la estacionalidad
                        yearly = False
                        weekly = False
                        daily = False  # normalmente no se usa para datos semanales/mensuales

                        if periodo_forecast=='Mensual' and len(ts_art) >= 24:
                            yearly = True
                        if periodo_forecast=='Semanal':
                            if len(ts_art) >= 104:
                                yearly = True
                            if len(ts_art) >= 8:
                                weekly = True

                        m = Prophet(yearly_seasonality=yearly,
                                    weekly_seasonality=weekly,
                                    daily_seasonality=daily)
                        m.fit(df_prophet)
                        future_all = m.make_future_dataframe(periods=n_periods, freq=resample_freq)
                        forecast = m.predict(future_all)
                        # Forzar valores positivos para forecast futuro
                        forecast_future = pd.Series(np.maximum(forecast['yhat'].tail(n_periods).values, 0),
                                                    index=forecast['ds'].tail(n_periods))
                        forecast_hist = pd.Series(forecast['yhat'].iloc[:len(ts_art)].values, index=ts_art.index)


                # ---------------- Random Forest ----------------
                elif modelo=='Random Forest':
                    df_ml = ts_art.copy().reset_index()
                    df_ml.rename(columns={'Fecha':'Periodo', columna_forecast:'y'}, inplace=True)
                    # Reindexar a frecuencia continua y rellenar vac√≠os
                    df_ml = df_ml.set_index('Periodo').asfreq(resample_freq, fill_value=0).reset_index()
                    max_lag = 4
                    for lag in range(1, max_lag+1):
                        df_ml[f'lag_{lag}'] = df_ml['y'].shift(lag)
                        df_ml[f'lag_{lag}'].fillna(df_ml['y'].iloc[0], inplace=True)  # Rellenar NaN iniciales

                    X = df_ml[[f'lag_{i}' for i in range(1, max_lag+1)]].to_numpy()
                    y = df_ml['y'].to_numpy()
                    rf = RandomForestRegressor(n_estimators=200, random_state=42)
                    rf.fit(X, y)

                    # Forecast futuro
                    last_values = list(df_ml.iloc[-1][[f'lag_{i}' for i in range(1, max_lag+1)]])
                    preds_future = []
                    for _ in range(n_periods):
                        pred = rf.predict([last_values])[0]
                        pred = max(pred, 0)
                        preds_future.append(pred)
                        last_values = [pred] + last_values[:-1]
                    forecast_future = pd.Series(preds_future, index=future_index)

                    # Forecast hist√≥rico
                    forecast_hist = pd.Series(rf.predict(X), index=df_ml['Periodo'])
                    forecast_hist = forecast_hist.reindex(ts_art.index, method='ffill')

                # Guardar resultados y m√©tricas
                if forecast_future is not None:
                    forecasts_dict[modelo] = {'future':forecast_future, 'hist':forecast_hist}
                    if forecast_hist is not None and len(forecast_hist)==len(ts_art):
                        y_true = ts_art.values
                        y_pred = forecast_hist.values
                        mae = mean_absolute_error(y_true, y_pred)
                        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
                        mape = np.mean(np.abs((y_true-y_pred)/(y_true+1e-9)))*100
                        # Detectar posibles valores absurdos
                        mape_warning = mape > 1000  # umbral arbitrario para advertencia
                        if mape_warning:
                            st.warning(f"‚ö†Ô∏è El MAPE del modelo '{modelo}' es extremadamente alto ({mape:.2f}%). Esto puede ocurrir por valores cercanos a cero en la serie hist√≥rica y puede no reflejar un error realista. Use el MAPE sim√©trico (SMAPE) como referencia.")
                        smape = 100 * np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred) + 1e-9))
                        resultados.append({'Modelo':modelo,'MAE':mae,'RMSE':rmse,'MAPE (%)':mape,'SMAPE (%)':smape})

            except Exception as e:
                st.warning(f"{modelo} omitido: {e}")
                
        # ----------- Tabla de m√©tricas -----------
        df_resultados = pd.DataFrame(resultados)
        if not df_resultados.empty:
            st.subheader("üìä Comparaci√≥n de m√©tricas")
            st.dataframe(df_resultados.round(2).sort_values('RMSE'))

        # ----------- Selecci√≥n de modelos a mostrar -----------
        modelos_disp = st.multiselect("Selecciona modelos a mostrar en la gr√°fica", list(forecasts_dict.keys()), default=list(forecasts_dict.keys()))

        # ----------- Gr√°fico interactivo con Plotly -----------
        st.subheader("üìà Comparativa interactiva de forecasts")
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=ts_art.index, y=ts_art.values, mode='lines+markers', name='Observado', line=dict(color='black', width=3)))
        for modelo in modelos_disp:
            data = forecasts_dict[modelo]
            if data['hist'] is not None:
                fig.add_trace(go.Scatter(x=data['hist'].index, y=data['hist'].values, mode='lines', name=f"{modelo} (hist)", line=dict(dash='dot')))
            fig.add_trace(go.Scatter(x=data['future'].index, y=data['future'].values, mode='lines+markers', name=f"{modelo} (futuro)"))
        fig.update_layout(hovermode='x unified', xaxis_title='Fecha', yaxis_title=columna_forecast)
        st.plotly_chart(fig, use_container_width=True)

        # ----------- Descarga ZIP -----------
        import io, zipfile
        buffer = io.BytesIO()
        with zipfile.ZipFile(buffer, 'w') as zf:
            if not df_resultados.empty:
                zf.writestr("comparacion_metricas.csv", df_resultados.round(2).to_csv(index=False))
            all_forecasts = pd.DataFrame({m:data['future'] for m,data in forecasts_dict.items()})
            all_forecasts.index.name='Periodo'
            all_forecasts.reset_index(inplace=True)
            zf.writestr("forecasts_modelos.csv", all_forecasts.round(2).to_csv(index=False))
        st.download_button("üì• Descargar resultados completos (ZIP)", data=buffer.getvalue(),
                        file_name=f"forecast_completo_{articulo_sel}.zip", mime="application/zip")
        
    with st.expander("üéØ Forecasting de Demanda por Categor√≠as S√∫per ABC", expanded=False):
        st.header('üéØ Forecasting de Demanda por Categor√≠as S√∫per ABC')
        
        st.markdown("""
        Esta secci√≥n permite hacer pron√≥sticos de demanda agregada por categor√≠as del S√∫per ABC, 
        lo cual es √∫til para planificaci√≥n estrat√©gica y gesti√≥n de inventarios a nivel de categor√≠a.
        
        **Modelos disponibles:** Media m√≥vil, Holt-Winters, Prophet y Random Forest (mismo conjunto que para SKU individual).
        """)
        
        # Verificar que tenemos datos de S√∫per ABC
        if 'Clase_SuperABC' not in by_item.columns:
            st.warning("‚ö†Ô∏è Primero debes calcular el S√∫per ABC para usar esta funcionalidad.")
        else:
            # Obtener categor√≠as disponibles
            categorias_disponibles = sorted(by_item['Clase_SuperABC'].unique())
            
            # Selecci√≥n de categor√≠as
            col1, col2 = st.columns(2)
            
            with col1:
                # Permitir selecci√≥n m√∫ltiple de categor√≠as
                categorias_seleccionadas = st.multiselect(
                    'Selecciona las categor√≠as ABC a pronosticar:',
                    categorias_disponibles,
                    default=categorias_disponibles[:3] if len(categorias_disponibles) >= 3 else categorias_disponibles,
                    help='Puedes seleccionar una o m√°s categor√≠as para comparar sus pron√≥sticos'
                )
            
            with col2:
                # Par√°metros de forecast
                periodo_forecast_cat = st.selectbox('Periodo de forecast', ['Mensual', 'Semanal'], index=0, key='forecast_cat_periodo')
                n_periods_cat = st.number_input(f'Per√≠odos a pronosticar ({periodo_forecast_cat.lower()})', 
                                            min_value=1, max_value=52, value=6, step=1, key='forecast_cat_periods')
                unidad_forecast_cat = st.selectbox('Unidad a pronosticar', ['Unidades vendidas', 'Cajas vendidas'], 
                                                index=0, key='forecast_cat_unidad')
            
            if categorias_seleccionadas:
                columna_forecast_cat = 'Unidades' if unidad_forecast_cat=='Unidades vendidas' else 'Cajas_vendidas'
                
                # Agregar datos por categor√≠a
                base_con_categoria = base.merge(
                    by_item[['Clase_SuperABC']].reset_index(), 
                    left_on='Articulo', 
                    right_on='Articulo', 
                    how='left'
                )
                
                # Filtrar solo las categor√≠as seleccionadas
                base_categorias = base_con_categoria[base_con_categoria['Clase_SuperABC'].isin(categorias_seleccionadas)]
                
                if base_categorias.empty:
                    st.warning("No hay datos para las categor√≠as seleccionadas.")
                else:
                    # Agregar por categor√≠a y fecha
                    resample_freq_cat = 'MS' if periodo_forecast_cat=='Mensual' else 'W-MON'
                    date_offset_cat = pd.DateOffset(months=1) if periodo_forecast_cat=='Mensual' else pd.DateOffset(weeks=1)
                    
                    # Agregar datos por categor√≠a y per√≠odo
                    ts_categorias = base_categorias.groupby(['Clase_SuperABC', 'Fecha'])[columna_forecast_cat].sum().reset_index()
                    ts_categorias = ts_categorias.set_index('Fecha').groupby('Clase_SuperABC')[columna_forecast_cat].resample(resample_freq_cat).sum().fillna(0)
                    
                    # Mostrar series hist√≥ricas
                    st.subheader("üìä Series hist√≥ricas por categor√≠a")
                    ts_categorias_pivot = ts_categorias.unstack(level=0).fillna(0)
                    st.line_chart(ts_categorias_pivot)
                    
                    # Estad√≠sticas por categor√≠a
                    st.subheader("üìà Estad√≠sticas por categor√≠a")
                    stats_categorias = ts_categorias.groupby('Clase_SuperABC').agg([
                        'count', 'mean', 'std', 'min', 'max', 'sum'
                    ]).round(2)
                    stats_categorias.columns = ['Per√≠odos', 'Promedio', 'Desv. Est.', 'M√≠nimo', 'M√°ximo', 'Total']
                    st.dataframe(stats_categorias)
                    
                    # Forecasting por categor√≠a
                    st.subheader("üîÆ Pron√≥sticos por categor√≠a")
                    
                    # Modelos para categor√≠as (incluir Random Forest como en SKU individual)
                    modelos_cat = ['Media m√≥vil (4 periodos)', 'Holt-Winters', 'Prophet', 'Random Forest']
                    forecasts_cat_dict = {}
                    resultados_cat = []
                    
                    for categoria in categorias_seleccionadas:
                        if categoria in ts_categorias.index.get_level_values(0):
                            ts_cat = ts_categorias.loc[categoria]
                            
                            if len(ts_cat) < 2:
                                st.warning(f"Categor√≠a {categoria}: Insuficientes datos para pron√≥stico")
                                continue
                            
                            st.write(f"**Pronosticando categor√≠a: {categoria}**")
                            
                            # Crear √≠ndice futuro
                            last_index_cat = ts_cat.index[-1]
                            future_index_cat = pd.date_range(start=last_index_cat + date_offset_cat, 
                                                        periods=n_periods_cat, freq=resample_freq_cat)
                            
                            categoria_forecasts = {}
                            
                            for modelo in modelos_cat:
                                try:
                                    forecast_future_cat = None
                                    forecast_hist_cat = None
                                    
                                    # Media M√≥vil
                                    if modelo == 'Media m√≥vil (4 periodos)':
                                        ma_cat = ts_cat.rolling(window=4, min_periods=1).mean().shift(1)
                                        ma_cat = ma_cat.fillna(ts_cat)
                                        forecast_future_cat = pd.Series([ma_cat.iloc[-1]]*n_periods_cat, index=future_index_cat)
                                        forecast_hist_cat = ma_cat
                                    
                                    # Holt-Winters
                                    elif modelo == 'Holt-Winters':
                                        if len(ts_cat) >= 2:
                                            period_cat = None
                                            if periodo_forecast_cat=='Mensual' and len(ts_cat) >= 24:
                                                period_cat = 12
                                            elif periodo_forecast_cat=='Semanal' and len(ts_cat) >= 104:
                                                period_cat = 52
                                            
                                            hw_cat = sm.tsa.ExponentialSmoothing(
                                                ts_cat,
                                                trend='add',
                                                seasonal='add' if period_cat else None,
                                                seasonal_periods=period_cat,
                                                initialization_method="estimated"
                                            ).fit()
                                            forecast_future_cat = pd.Series(hw_cat.forecast(n_periods_cat).values, index=future_index_cat)
                                            forecast_hist_cat = hw_cat.fittedvalues
                                    
                                    # Prophet
                                    elif modelo == 'Prophet':
                                        df_prophet_cat = ts_cat.reset_index().rename(columns={'Fecha':'ds', columna_forecast_cat:'y'})
                                        
                                        if len(df_prophet_cat) >= 3:
                                            yearly_cat = False
                                            weekly_cat = False
                                            
                                            if periodo_forecast_cat=='Mensual' and len(ts_cat) >= 24:
                                                yearly_cat = True
                                            if periodo_forecast_cat=='Semanal':
                                                if len(ts_cat) >= 104:
                                                    yearly_cat = True
                                                if len(ts_cat) >= 8:
                                                    weekly_cat = True
                                            
                                            m_cat = Prophet(yearly_seasonality=yearly_cat,
                                                        weekly_seasonality=weekly_cat,
                                                        daily_seasonality=False)
                                            m_cat.fit(df_prophet_cat)
                                            future_all_cat = m_cat.make_future_dataframe(periods=n_periods_cat, freq=resample_freq_cat)
                                            forecast_cat = m_cat.predict(future_all_cat)
                                            forecast_future_cat = pd.Series(np.maximum(forecast_cat['yhat'].tail(n_periods_cat).values, 0),
                                                                        index=forecast_cat['ds'].tail(n_periods_cat))
                                            forecast_hist_cat = pd.Series(forecast_cat['yhat'].iloc[:len(ts_cat)].values, index=ts_cat.index)
                                    
                                    # Random Forest
                                    elif modelo == 'Random Forest':
                                        df_ml_cat = ts_cat.copy().reset_index()
                                        df_ml_cat.rename(columns={'Fecha':'Periodo', columna_forecast_cat:'y'}, inplace=True)
                                        # Reindexar a frecuencia continua y rellenar vac√≠os
                                        df_ml_cat = df_ml_cat.set_index('Periodo').asfreq(resample_freq_cat, fill_value=0).reset_index()
                                        
                                        max_lag_cat = 4
                                        for lag in range(1, max_lag_cat+1):
                                            df_ml_cat[f'lag_{lag}'] = df_ml_cat['y'].shift(lag)
                                            df_ml_cat[f'lag_{lag}'].fillna(df_ml_cat['y'].iloc[0], inplace=True)  # Rellenar NaN iniciales
                                        
                                        X_cat = df_ml_cat[[f'lag_{i}' for i in range(1, max_lag_cat+1)]].to_numpy()
                                        y_cat = df_ml_cat['y'].to_numpy()
                                        
                                        rf_cat = RandomForestRegressor(n_estimators=200, random_state=42)
                                        rf_cat.fit(X_cat, y_cat)
                                        
                                        # Forecast futuro
                                        last_values_cat = list(df_ml_cat.iloc[-1][[f'lag_{i}' for i in range(1, max_lag_cat+1)]])
                                        preds_future_cat = []
                                        for _ in range(n_periods_cat):
                                            pred_cat = rf_cat.predict([last_values_cat])[0]
                                            pred_cat = max(pred_cat, 0)
                                            preds_future_cat.append(pred_cat)
                                            last_values_cat = [pred_cat] + last_values_cat[:-1]
                                        
                                        forecast_future_cat = pd.Series(preds_future_cat, index=future_index_cat)
                                        
                                        # Forecast hist√≥rico
                                        forecast_hist_cat = pd.Series(rf_cat.predict(X_cat), index=df_ml_cat['Periodo'])
                                        forecast_hist_cat = forecast_hist_cat.reindex(ts_cat.index, method='ffill')
                                    
                                    if forecast_future_cat is not None:
                                        categoria_forecasts[modelo] = {'future': forecast_future_cat, 'hist': forecast_hist_cat}
                                        
                                        # Calcular m√©tricas
                                        if forecast_hist_cat is not None and len(forecast_hist_cat) == len(ts_cat):
                                            y_true_cat = ts_cat.values
                                            y_pred_cat = forecast_hist_cat.values
                                            mae_cat = mean_absolute_error(y_true_cat, y_pred_cat)
                                            rmse_cat = np.sqrt(mean_squared_error(y_true_cat, y_pred_cat))
                                            mape_cat = np.mean(np.abs((y_true_cat-y_pred_cat)/(y_true_cat+1e-9)))*100
                                            smape_cat = 100 * np.mean(2 * np.abs(y_true_cat - y_pred_cat) / (np.abs(y_true_cat) + np.abs(y_pred_cat) + 1e-9))
                                            
                                            resultados_cat.append({
                                                'Categor√≠a': categoria,
                                                'Modelo': modelo,
                                                'MAE': mae_cat,
                                                'RMSE': rmse_cat,
                                                'MAPE (%)': mape_cat,
                                                'SMAPE (%)': smape_cat
                                            })
                                    
                                except Exception as e:
                                    st.warning(f"Categor√≠a {categoria}, {modelo} omitido: {e}")
                            
                            forecasts_cat_dict[categoria] = categoria_forecasts
                    
                    # Mostrar resultados
                    if resultados_cat:
                        st.subheader("üìä Comparaci√≥n de m√©tricas por categor√≠a")
                        df_resultados_cat = pd.DataFrame(resultados_cat)
                        st.dataframe(df_resultados_cat.round(2).sort_values(['Categor√≠a', 'RMSE']))
                        
                        # Gr√°fico comparativo
                        st.subheader("üìà Comparativa de pron√≥sticos por categor√≠a")
                        
                        # Seleccionar modelo para comparar
                        modelos_disponibles_cat = list(set([r['Modelo'] for r in resultados_cat]))
                        modelo_comparar = st.selectbox("Selecciona modelo para comparar categor√≠as:", 
                                                    modelos_disponibles_cat, key='modelo_comparar_cat')
                        
                        fig_cat = go.Figure()
                        
                        # Colores para categor√≠as
                        colors = px.colors.qualitative.Set3
                        
                        for i, categoria in enumerate(categorias_seleccionadas):
                            if categoria in forecasts_cat_dict and modelo_comparar in forecasts_cat_dict[categoria]:
                                data_cat = forecasts_cat_dict[categoria][modelo_comparar]
                                color = colors[i % len(colors)]
                                
                                # Serie hist√≥rica
                                ts_cat_plot = ts_categorias.loc[categoria]
                                fig_cat.add_trace(go.Scatter(
                                    x=ts_cat_plot.index, 
                                    y=ts_cat_plot.values, 
                                    mode='lines+markers', 
                                    name=f'{categoria} (hist)',
                                    line=dict(color=color, width=2)
                                ))
                                
                                # Pron√≥stico hist√≥rico
                                if data_cat['hist'] is not None:
                                    fig_cat.add_trace(go.Scatter(
                                        x=data_cat['hist'].index, 
                                        y=data_cat['hist'].values, 
                                        mode='lines', 
                                        name=f'{categoria} ({modelo_comparar} hist)',
                                        line=dict(color=color, dash='dot')
                                    ))
                                
                                # Pron√≥stico futuro
                                fig_cat.add_trace(go.Scatter(
                                    x=data_cat['future'].index, 
                                    y=data_cat['future'].values, 
                                    mode='lines+markers', 
                                    name=f'{categoria} ({modelo_comparar} futuro)',
                                    line=dict(color=color, width=3)
                                ))
                        
                        fig_cat.update_layout(
                            hovermode='x unified', 
                            xaxis_title='Fecha', 
                            yaxis_title=columna_forecast_cat,
                            title=f'Pron√≥sticos por categor√≠a - {modelo_comparar}'
                        )
                        st.plotly_chart(fig_cat, use_container_width=True)
                        
                        # Descarga de resultados por categor√≠as
                        st.subheader("üì• Descargar resultados por categor√≠as")
                        buffer_cat = io.BytesIO()
                        with zipfile.ZipFile(buffer_cat, 'w') as zf:
                            # M√©tricas por categor√≠a
                            zf.writestr("metricas_por_categoria.csv", df_resultados_cat.round(2).to_csv(index=False))
                            
                            # Pron√≥sticos por categor√≠a
                            for categoria in categorias_seleccionadas:
                                if categoria in forecasts_cat_dict:
                                    for modelo in forecasts_cat_dict[categoria]:
                                        data_cat = forecasts_cat_dict[categoria][modelo]
                                        forecast_df = pd.DataFrame({
                                            'Periodo': data_cat['future'].index,
                                            'Pronostico': data_cat['future'].values
                                        })
                                        zf.writestr(f"forecast_{categoria}_{modelo}.csv", forecast_df.to_csv(index=False))
                        
                        st.download_button(
                            "üìä Descargar pron√≥sticos por categor√≠as (ZIP)", 
                            data=buffer_cat.getvalue(),
                            file_name="forecasts_por_categorias.zip", 
                            mime="application/zip"
                        )
            else:
                st.info("Selecciona al menos una categor√≠a para hacer pron√≥sticos.")
        
    with st.expander("üìä An√°lisis de Contribuci√≥n por Categor√≠as ABC", expanded=False):
        # -------------------------------
        # An√°lisis de Contribuci√≥n por Categor√≠as
        # -------------------------------
        st.header('üìä An√°lisis de Contribuci√≥n por Categor√≠as ABC')
        
        st.markdown("""
        Esta secci√≥n proporciona un an√°lisis detallado de la contribuci√≥n de cada categor√≠a ABC 
        al total de ventas, volumen y popularidad, √∫til para entender el impacto de cada categor√≠a.
        """)
        
        # An√°lisis de contribuci√≥n
        contribucion_categorias = by_item.groupby('Clase_SuperABC').agg({
            'ventas': 'sum',
            'volumen': 'sum', 
            'popularidad': 'sum',
            'unidades': 'sum'
        }).round(2)
        
        # Agregar conteo de art√≠culos (usando el √≠ndice)
        contribucion_categorias['Cantidad_Articulos'] = by_item.groupby('Clase_SuperABC').size()
        
        # Calcular porcentajes
        total_ventas = contribucion_categorias['ventas'].sum()
        total_volumen = contribucion_categorias['volumen'].sum()
        total_popularidad = contribucion_categorias['popularidad'].sum()
        total_unidades = contribucion_categorias['unidades'].sum()
        total_articulos = contribucion_categorias['Cantidad_Articulos'].sum()
        
        contribucion_categorias['% Ventas'] = (contribucion_categorias['ventas'] / total_ventas * 100).round(2)
        contribucion_categorias['% Volumen'] = (contribucion_categorias['volumen'] / total_volumen * 100).round(2)
        contribucion_categorias['% Popularidad'] = (contribucion_categorias['popularidad'] / total_popularidad * 100).round(2)
        contribucion_categorias['% Unidades'] = (contribucion_categorias['unidades'] / total_unidades * 100).round(2)
        contribucion_categorias['% Art√≠culos'] = (contribucion_categorias['Cantidad_Articulos'] / total_articulos * 100).round(2)
        
        # Renombrar columnas
        contribucion_categorias.columns = ['Ventas', 'Volumen', 'Popularidad', 'Unidades', 'Cantidad Art√≠culos', 
                                         '% Ventas', '% Volumen', '% Popularidad', '% Unidades', '% Art√≠culos']
        
        st.subheader("üìà Tabla de Contribuci√≥n por Categor√≠as")
        st.dataframe(contribucion_categorias)
        
        # Gr√°ficos de contribuci√≥n
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ü•ß Contribuci√≥n de Ventas por Categor√≠a")
            fig_ventas = px.pie(
                values=contribucion_categorias['% Ventas'], 
                names=contribucion_categorias.index,
                title="Distribuci√≥n de Ventas por Categor√≠a ABC"
            )
            st.plotly_chart(fig_ventas, use_container_width=True)
        
        with col2:
            st.subheader("ü•ß Contribuci√≥n de Volumen por Categor√≠a")
            fig_volumen = px.pie(
                values=contribucion_categorias['% Volumen'], 
                names=contribucion_categorias.index,
                title="Distribuci√≥n de Volumen por Categor√≠a ABC"
            )
            st.plotly_chart(fig_volumen, use_container_width=True)
        
        # Gr√°fico de barras comparativo
        st.subheader("üìä Comparaci√≥n de Contribuciones")
        
        # Preparar datos para gr√°fico de barras
        contrib_data = contribucion_categorias[['% Ventas', '% Volumen', '% Popularidad', '% Unidades']].reset_index()
        contrib_data_melted = contrib_data.melt(
            id_vars=['Clase_SuperABC'], 
            value_vars=['% Ventas', '% Volumen', '% Popularidad', '% Unidades'],
            var_name='M√©trica', 
            value_name='Porcentaje'
        )
        
        fig_barras = px.bar(
            contrib_data_melted, 
            x='Clase_SuperABC', 
            y='Porcentaje', 
            color='M√©trica',
            title="Comparaci√≥n de Contribuciones por Categor√≠a ABC",
            barmode='group'
        )
        fig_barras.update_layout(xaxis_title="Categor√≠a ABC", yaxis_title="Porcentaje (%)")
        st.plotly_chart(fig_barras, use_container_width=True)
        
        # An√°lisis de concentraci√≥n (Pareto por categor√≠as)
        st.subheader("üìà An√°lisis de Concentraci√≥n (Pareto)")
        
        # Ordenar por ventas
        pareto_categorias = contribucion_categorias.sort_values('% Ventas', ascending=False)
        pareto_categorias['Ventas_Acumuladas'] = pareto_categorias['% Ventas'].cumsum()
        pareto_categorias['Categorias_Acumuladas'] = range(1, len(pareto_categorias) + 1)
        pareto_categorias['% Categorias'] = (pareto_categorias['Categorias_Acumuladas'] / len(pareto_categorias) * 100).round(2)
        
        # Gr√°fico de Pareto
        fig_pareto_cat = go.Figure()
        
        # Barras de ventas
        fig_pareto_cat.add_trace(go.Bar(
            x=pareto_categorias.index,
            y=pareto_categorias['% Ventas'],
            name='% Ventas',
            marker_color='lightblue'
        ))
        
        # L√≠nea de acumulado
        fig_pareto_cat.add_trace(go.Scatter(
            x=pareto_categorias.index,
            y=pareto_categorias['Ventas_Acumuladas'],
            mode='lines+markers',
            name='% Ventas Acumulado',
            yaxis='y2',
            line=dict(color='red', width=3)
        ))
        
        fig_pareto_cat.update_layout(
            title="An√°lisis de Pareto - Concentraci√≥n de Ventas por Categor√≠as ABC",
            xaxis_title="Categor√≠as ABC (ordenadas por ventas)",
            yaxis=dict(title="% Ventas", side="left"),
            yaxis2=dict(title="% Ventas Acumulado", side="right", overlaying="y"),
            hovermode='x unified'
        )
        
        st.plotly_chart(fig_pareto_cat, use_container_width=True)
        
        # Mostrar tabla de Pareto
        st.subheader("üìã Tabla de An√°lisis de Pareto")
        pareto_display = pareto_categorias[['% Ventas', 'Ventas_Acumuladas', '% Categorias']].copy()
        pareto_display.columns = ['% Ventas', '% Ventas Acumulado', '% Categor√≠as']
        st.dataframe(pareto_display)
        
        # Insights autom√°ticos
        st.subheader("üí° Insights Autom√°ticos")
        
        # Categor√≠a con mayor contribuci√≥n
        top_categoria = pareto_categorias.index[0]
        top_ventas = pareto_categorias.iloc[0]['% Ventas']
        
        # Categor√≠as que representan el 80% de las ventas
        categorias_80 = pareto_categorias[pareto_categorias['Ventas_Acumuladas'] <= 80]
        num_categorias_80 = len(categorias_80)
        
        # Categor√≠as con baja contribuci√≥n
        categorias_bajas = pareto_categorias[pareto_categorias['% Ventas'] < 5]
        
        insights = []
        insights.append(f"üéØ **Categor√≠a l√≠der**: {top_categoria} representa el {top_ventas}% de las ventas")
        insights.append(f"üìä **Concentraci√≥n**: {num_categorias_80} categor√≠as representan el 80% de las ventas")
        insights.append(f"üìâ **Categor√≠as de baja contribuci√≥n**: {len(categorias_bajas)} categor√≠as contribuyen menos del 5% cada una")
        
        if len(categorias_bajas) > 0:
            insights.append(f"üîç **Categor√≠as a revisar**: {', '.join(categorias_bajas.index)}")
        
        for insight in insights:
            st.info(insight)

    with st.expander("üè≠ Sugerencias de Distribuci√≥n de Bodega", expanded=False):
        # -------------------------------
        # Sugerencias de Distribuci√≥n de Bodega
        # -------------------------------
        st.header('üè≠ Sugerencias de Distribuci√≥n de Bodega')
        
        st.markdown("""
        Esta secci√≥n permite calcular la distribuci√≥n √≥ptima de racks en la bodega bas√°ndose en el an√°lisis ABC 
        y las dimensiones f√≠sicas de pallets, bays, racks y la bodega. El sistema calcula autom√°ticamente 
        la capacidad de almacenamiento y sugiere la distribuci√≥n de racks por categor√≠a ABC.
        
        **üí° Nota importante:** El porcentaje de almacenamiento representa qu√© parte del √°rea total de la bodega 
        se destinar√° espec√≠ficamente para almacenamiento (el resto se usa para pasillos, oficinas, √°reas de 
        recepci√≥n/despacho, etc.). Un valor t√≠pico es entre 60-80%.
        """)
        
        # Verificar que tenemos datos de S√∫per ABC
        if 'Clase_SuperABC' not in by_item.columns:
            st.warning("‚ö†Ô∏è Primero debes calcular el S√∫per ABC para usar esta funcionalidad.")
        else:
            # Crear columnas para organizar los par√°metros
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("üì¶ Dimensiones de Pallets")
                largo_pallet = st.number_input("Largo del pallet (pies)", min_value=0.1, value=4.0, step=0.1)
                ancho_pallet = st.number_input("Ancho del pallet (pies)", min_value=0.1, value=4.0, step=0.1)
                alto_pallet = st.number_input("Alto del pallet (pies)", min_value=0.1, value=5.0, step=0.1)
                factor_llenado = st.number_input("Factor de llenado (%)", min_value=0.1, max_value=100.0, value=85.0, step=1.0) / 100.0
                
                st.subheader("üèóÔ∏è Dimensiones de Bay")
                largo_bay = st.number_input("Largo de Bay (pies)", min_value=0.1, value=8.0, step=0.1)
                profundidad_bay = st.number_input("Profundidad del Bay (pies)", min_value=0.1, value=4.0, step=0.1)
                niveles = st.number_input("Niveles", min_value=1, value=5, step=1)
                
            with col2:
                st.subheader("üè¢ Informaci√≥n de Rack")
                bays_por_rack = st.number_input("Bays por rack", min_value=1, value=10, step=1)
                
                st.subheader("üè≠ Dimensiones de Bodega")
                ancho_bodega = st.number_input("Ancho de bodega (pies)", min_value=0.1, value=100.0, step=1.0)
                largo_bodega = st.number_input("Largo de bodega (pies)", min_value=0.1, value=200.0, step=1.0)
                porcentaje_almacenamiento = st.number_input("Porcentaje para almacenamiento (%)", min_value=1.0, max_value=100.0, value=70.0, step=1.0) / 100.0
                ancho_pasillo = st.number_input("Ancho de pasillo (pies)", min_value=0.1, value=12.0, step=0.1)
            
            # Bot√≥n para calcular distribuci√≥n
            if st.button("üßÆ Calcular Distribuci√≥n de Bodega"):
                # -------------------------------
                # C√°lculos de Capacidad
                # -------------------------------
                st.subheader("üìä C√°lculos de Capacidad")
                
                # Volumen de pallet
                volumen_pallet = largo_pallet * ancho_pallet * alto_pallet * factor_llenado
                
                # Pallets por nivel
                pallets_por_nivel = int((largo_bay // largo_pallet) * (profundidad_bay // ancho_pallet))
                
                # √Årea de bay
                area_bay = largo_bay * profundidad_bay
                
                # √Årea de rack
                area_rack = area_bay * bays_por_rack
                
                # √Årea de bodega
                area_bodega_total = ancho_bodega * largo_bodega
                
                # √Årea efectiva de almacenamiento (basada en porcentaje)
                area_efectiva_almacenamiento = area_bodega_total * porcentaje_almacenamiento
                
                # √Årea de pasillo
                area_pasillo = largo_bay * ancho_pasillo * bays_por_rack
                
                # √Årea de rack + pasillo
                area_rack_pasillo = area_rack + area_pasillo
                
                # Pallets por rack
                pallets_por_rack = pallets_por_nivel * niveles * bays_por_rack
                
                # Mostrar c√°lculos
                calculos_df = pd.DataFrame({
                    'M√©trica': [
                        'Volumen de pallet (pies¬≥)',
                        'Pallets por nivel',
                        '√Årea de bay (pies¬≤)',
                        '√Årea de rack (pies¬≤)',
                        '√Årea de bodega (pies¬≤)',
                        f'√Årea efectiva de almacenamiento (pies¬≤) - {porcentaje_almacenamiento*100:.0f}%',
                        '√Årea de pasillo (pies¬≤)',
                        '√Årea de rack + pasillo (pies¬≤)',
                        'Pallets por rack'
                    ],
                    'Valor': [
                        round(volumen_pallet, 2),
                        pallets_por_nivel,
                        round(area_bay, 2),
                        round(area_rack, 2),
                        round(area_bodega_total, 2),
                        round(area_efectiva_almacenamiento, 2),
                        round(area_pasillo, 2),
                        round(area_rack_pasillo, 2),
                        pallets_por_rack
                    ]
                })
                
                st.dataframe(calculos_df, use_container_width=True)
                
                # -------------------------------
                # Tabla previa de preparaci√≥n (solicitada)
                # -------------------------------
                st.subheader("üìã Tabla base previa (detalle limpio)")
                base_pre = base.copy()
                base_pre['MesyA√±o'] = base_pre['Fecha'].dt.to_period('M').astype(str)
                # Volumen por unidad: cuidar divisiones por 0
                base_pre['Volumen por unidad'] = (base_pre['Volumen_p3'] / base_pre['Unidades'].replace(0, np.nan)).fillna(0)
                tabla_previa = base_pre[['NumDoc','Articulo','Unidades','Cajas_vendidas','Unidades_por_caja','Fecha','Volumen_p3','MesyA√±o','Volumen por unidad']].copy()
                tabla_previa.columns = ['Num. Doc','Art√≠culo','Unid. Vend','Cajas vend.','Cant x caja','Fecha Doc','Volumen total (p3)','MesyA√±o','Volumen por unidad']
                st.dataframe(tabla_previa, use_container_width=True)

                # -------------------------------
                # An√°lisis de Inventario por SKU (Art√≠culo)
                # -------------------------------
                st.subheader("üìã An√°lisis por SKU (Art√≠culo)")

                # Utilidades
                SCORES = {
                "A": 0.99,
                "B": 0.90,
                "C": 0.75
                }

                def calcular_csl(categoria):
                    if not isinstance(categoria, str):
                        return 0.70
                    valores = [SCORES.get(letra, 0.70) for letra in categoria] # Define un score por cada letra, y el CSL de la combinaci√≥n es el promedio
                    return round(sum(valores) / len(valores), 2)


                def calcular_z_score(csl):
                    from scipy.stats import norm
                    return float(norm.ppf(csl))
                
                def calcular_safety_stock(demanda_promedio, desviacion, z_score, lead_time=1):
                    return z_score * desviacion * np.sqrt(lead_time)
                
                # 1) Tabla mensual de Unidades por SKU
                base_mes = base.copy()
                base_mes['YearMonth'] = base_mes['Fecha'].dt.to_period('M').astype(str)
                pivot_mes = pd.pivot_table(
                    base_mes,
                    index='Articulo',
                    columns='YearMonth',
                    values='Unidades',
                    aggfunc='sum',
                    fill_value=0
                )
                # ordenar columnas cronol√≥gicamente
                pivot_mes = pivot_mes.reindex(sorted(pivot_mes.columns), axis=1)

                # 2) C√°lculos por SKU: totales y estad√≠sticas de demanda
                totales = base.groupby('Articulo').agg(
                    unidades_totales=('Unidades','sum'),
                    volumen_total=('Volumen_p3','sum')
                )
                vol_por_unidad = (totales['volumen_total'] / totales['unidades_totales'].replace(0, np.nan)).fillna(0)

                # Unidades por caja por SKU: usar la moda (valor m√°s frecuente) de 'Cant x Caja'
                upc_series = pd.to_numeric(base['Unidades_por_caja'], errors='coerce')
                upc_por_sku = base.assign(Unidades_por_caja=upc_series).groupby('Articulo')['Unidades_por_caja'].agg(
                    lambda s: s.mode().iloc[0] if not s.mode().empty else s.dropna().iloc[0] if not s.dropna().empty else 1
                )
                upc_por_sku = upc_por_sku.fillna(1).replace(0, 1)

                # Mapear categor√≠a S√∫per ABC por SKU EXACTAMENTE como fue calculada (sin reordenar letras)
                # Usar by_item del session_state que contiene las categor√≠as ABC originales
                by_item_original = st.session_state['by_item']
                mapa_abc = by_item_original['Clase_SuperABC'].reindex(pivot_mes.index)
                # Filtrar solo SKUs que tienen clasificaci√≥n ABC v√°lida
                skus_con_abc = mapa_abc.dropna()
                pivot_mes_filtrado = pivot_mes.reindex(skus_con_abc.index)
                
                # Demanda promedio y desviaci√≥n: usar promedio mensual directo del pivote filtrado
                demanda_prom = pivot_mes_filtrado.mean(axis=1)
                # Desviaci√≥n muestral (como DESVEST.M en Excel)
                desviacion = pivot_mes_filtrado.std(axis=1, ddof=1).fillna(0)
                
                csl = skus_con_abc.apply(calcular_csl)
                z_vals = csl.apply(calcular_z_score)
                ss_vals = calcular_safety_stock(demanda_prom, desviacion, z_vals)
                inv_max = demanda_prom + ss_vals

                # Vol√∫menes y cajas (usar solo SKUs con ABC v√°lido)
                vol_por_caja = vol_por_unidad.reindex(skus_con_abc.index).fillna(0) * upc_por_sku.reindex(skus_con_abc.index).fillna(1)
                vol_total_unidades = inv_max * vol_por_unidad.reindex(skus_con_abc.index).fillna(0)
                cant_cajas = np.ceil(inv_max / upc_por_sku.reindex(skus_con_abc.index).replace(0, 1))
                vol_total_cajas = cant_cajas * vol_por_caja

                # Construir tabla final por SKU (solo con SKUs que tienen ABC)
                sku_df = pivot_mes_filtrado.copy()
                sku_df['Total general'] = pivot_mes_filtrado.sum(axis=1)
                sku_df['Demanda promedio'] = demanda_prom.round(2)
                sku_df['Desviaci√≥n'] = desviacion.round(2)
                sku_df['ABC'] = skus_con_abc
                sku_df['CSL'] = csl
                sku_df['Z'] = z_vals.round(2)
                sku_df['ss'] = ss_vals.round(2)
                sku_df['Inventario m√°ximo'] = inv_max.round(2)
                sku_df['Volumen por unidad'] = vol_por_unidad.reindex(skus_con_abc.index).fillna(0).round(4)
                sku_df['Volumen Total (unidades)'] = vol_total_unidades.round(2)
                sku_df['Unidades por caja'] = upc_por_sku.reindex(skus_con_abc.index).fillna(1).astype(int)
                sku_df['Cantidad de cajas'] = cant_cajas.astype(int)
                sku_df['Volumen por caja'] = vol_por_caja.round(4)
                sku_df['Volumen Total (cajas)'] = vol_total_cajas.round(2)

                st.dataframe(sku_df.reset_index(), use_container_width=True)

                # Totales generales previos a demanda: sumar meses, Total general y Volumen Total (cajas)
                totales_previos = {
                    'Total general (unidades)': float(sku_df['Total general'].sum()),
                    'Volumen Total (cajas)': float(sku_df['Volumen Total (cajas)'].sum())
                }
                st.write('Totales generales:', {k: round(v, 2) for k, v in totales_previos.items()})
                
                # -------------------------------
                # Tabla de Vol√∫menes por Categor√≠a (antes de racks)
                # -------------------------------
                st.subheader("üìä Vol√∫menes por Categor√≠a ABC")
                
                # Agregar vol√∫menes por categor√≠a (sku_df ya est√° filtrado por ABC v√°lido)
                vol_por_categoria = sku_df.groupby('ABC')['Volumen Total (cajas)'].sum().sort_index()
                vol_total_general = vol_por_categoria.sum()
                
                tabla_volumenes = pd.DataFrame({
                    'Suma de Volumen Total': vol_por_categoria,
                    'Porcentaje del Total': (vol_por_categoria / vol_total_general * 100)
                }).round(4)

                # % agrupado por primera letra
                tabla_volumenes['Primera_Letra'] = tabla_volumenes.index.astype(str).str[0]
                pct_grouped = (tabla_volumenes.groupby('Primera_Letra')['Porcentaje del Total'].sum()).round(4)
                tabla_volumenes['Porcentaje agrupado'] = tabla_volumenes['Primera_Letra'].map(pct_grouped)

                # A√±adir Total General
                total_row = pd.DataFrame({
                    'Suma de Volumen Total': [vol_total_general],
                    'Porcentaje del Total': [100.0],
                    'Porcentaje agrupado': [pct_grouped.sum()]
                }, index=['Total General'])
                tabla_mostrar = pd.concat([tabla_volumenes[['Suma de Volumen Total', 'Porcentaje del Total', 'Porcentaje agrupado']].round(2), total_row], axis=0)
                tabla_mostrar.index.name = 'Etiquetas de fila'
                st.dataframe(tabla_mostrar, use_container_width=True)

                st.dataframe(vol_por_categoria.to_frame('Volumen Total (cajas)').round(2), use_container_width=True)
                
                # -------------------------------
                # C√°lculo de Racks Necesarios
                # -------------------------------
                st.subheader("üèóÔ∏è C√°lculo de Racks Necesarios")
                
                # Crear tabla de racks por categor√≠a usando los vol√∫menes ya calculados
                racks_categorias = pd.DataFrame({'VolumenTotal_ft3': vol_por_categoria})
                racks_categorias.index.name = 'Clase_SuperABC'
                
                # C√°lculos paso a paso 
                racks_categorias['Pallets_Necesarios'] = np.ceil(racks_categorias['VolumenTotal_ft3'] / volumen_pallet)
                racks_categorias['Equivalente_en_Niveles'] = racks_categorias['Pallets_Necesarios'] / pallets_por_nivel
                racks_categorias['Equivalente_en_Bays'] = racks_categorias['Equivalente_en_Niveles'] / niveles
                racks_categorias['Equivalente_en_Racks'] = racks_categorias['Equivalente_en_Bays'] / bays_por_rack
                
                # Calcular distribuci√≥n de racks en porcentaje respecto a racks redondeados (espacio no usado)
                total_racks = racks_categorias['Equivalente_en_Racks'].sum()
                if total_racks == 0:
                    racks_categorias['Distribucion_de_Racks_%'] = 0.0
                else:
                    racks_disponibles = np.ceil(total_racks)
                    racks_categorias['Distribucion_de_Racks_%'] = (racks_categorias['Equivalente_en_Racks'] / racks_disponibles * 100).round(2)

                    # Calcular sobrante
                    sobrante_pct = 100 - racks_categorias['Distribucion_de_Racks_%'].sum()
                    if sobrante_pct > 0:
                        sobrante_row = pd.DataFrame({
                            'VolumenTotal_ft3': [0],
                            'Pallets_Necesarios': [0],
                            'Equivalente_en_Niveles': [0],
                            'Equivalente_en_Bays': [0],
                            'Equivalente_en_Racks': [racks_disponibles - total_racks],
                            'Distribucion_de_Racks_%': [sobrante_pct]
                        }, index=['Sobrante'])
                        racks_categorias = pd.concat([racks_categorias, sobrante_row])

                # Mostrar tabla de racks
                st.dataframe(racks_categorias, use_container_width=True)
                
                # -------------------------------
                # Resumen de Distribuci√≥n
                # -------------------------------
                st.subheader("üìä Resumen de Distribuci√≥n")
                
                # Calcular m√©tricas de utilizaci√≥n
                racks_necesarios = np.ceil(racks_categorias['Pallets_Necesarios'].sum() / pallets_por_rack)
                area_en_uso = area_rack_pasillo * racks_necesarios
                utilizacion_espacio = (area_en_uso / area_efectiva_almacenamiento * 100).round(2)
                
                resumen_df = pd.DataFrame({
                    'M√©trica': [
                        'Racks necesarios total',
                        '√Årea en uso (pies¬≤)',
                        'Utilizaci√≥n de espacio (%)'
                    ],
                    'Valor': [
                        int(racks_necesarios),
                        round(area_en_uso, 2),
                        utilizacion_espacio
                    ]
                })
                
                st.dataframe(resumen_df, use_container_width=True)
                
                # -------------------------------
                # Gr√°fico de Distribuci√≥n
                # -------------------------------
                st.subheader("üìä Gr√°fico de Distribuci√≥n de Racks por Categor√≠a")
                
                fig_distribucion = px.pie(
                    values=racks_categorias['Distribucion_de_Racks_%'],
                    names=racks_categorias.index,
                    title="Distribuci√≥n de Racks por Categor√≠a ABC"
                )
                st.plotly_chart(fig_distribucion, use_container_width=True)
                
                # -------------------------------
                # Guardar resultados en session_state
                # -------------------------------
                st.session_state['calculos_capacidad'] = calculos_df
                st.session_state['analisis_categorias'] = sku_df
                st.session_state['racks_categorias'] = racks_categorias
                st.session_state['resumen_distribucion'] = resumen_df               
                st.success("‚úÖ Distribuci√≥n de bodega calculada exitosamente!")


# =============================================================================
# SECCI√ìN DE DESCARGAS
# =============================================================================

from openpyxl import load_workbook
from openpyxl.chart import BarChart, Reference, PieChart, LineChart
from openpyxl.chart.axis import DateAxis, NumericAxis

st.markdown("---")
st.header("üì• Descargas y Exportaci√≥n")

with st.expander("üìä Descargar Resultados Completos", expanded=False):
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìà Perfiles de Actividad")
        if st.session_state.get('want_csv', True):
            if st.button("üì• Exportar perfiles a Excel"):
                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
                    # Hoja Portada primero
                    df_portada.to_excel(writer, sheet_name='Portada', index=False)

                    # Guardamos nombres de hojas para generar gr√°ficos luego
                    hoja_nombres = []

                    for key, df in st.session_state.items():
                        if key.startswith("perfil_") and isinstance(df, pd.DataFrame):
                            hoja = key.replace("perfil_", "")[:30]  # hoja ‚â§ 31 chars
                            df.to_excel(writer, sheet_name=hoja, index=False)
                            hoja_nombres.append((hoja, df))

                # Abrir libro para a√±adir gr√°ficos
                buffer.seek(0)
                wb = load_workbook(buffer)

                for hoja, df in hoja_nombres:
                    ws = wb[hoja]
                    chart = BarChart()  # default, lo cambiaremos seg√∫n hoja

                    # Selecci√≥n de datos seg√∫n tipo de hoja
                    if hoja.lower() in ["dias", "lineas", "carga", "cubicaje"]:
                        # Columna 1 = etiquetas, columna 2 = valores
                        data = Reference(ws, min_col=2, min_row=1, max_row=ws.max_row)
                        cats = Reference(ws, min_col=1, min_row=2, max_row=ws.max_row)
                        chart.add_data(data, titles_from_data=True)
                        chart.set_categories(cats)
                        chart.title = f"Gr√°fico {hoja}"
                        chart.y_axis.title = "Cantidad"
                        chart.x_axis.title = "Categor√≠a"
                        ws.add_chart(chart, "H5")  # colocar gr√°fico a la derecha
                    elif hoja.lower() == "pareto":
                        chart = LineChart()
                        chart.title = "Pareto de Picks"
                        chart.style = 10  # estilo opcional
                        chart.legend = None  # sin leyenda
                        
                        # Datos Y = cum_pct_picks (columna C)
                        data = Reference(ws, min_col=3, min_row=2, max_row=ws.max_row)
                        chart.add_data(data, titles_from_data=False)
                        
                        # Eje X = pct_sku (columna E)
                        cats = Reference(ws, min_col=5, min_row=2, max_row=ws.max_row)
                        chart.set_categories(cats)
                        
                        # Etiquetas de ejes
                        chart.x_axis.title = "% acumulado de SKU"
                        chart.y_axis.title = "% acumulado de Picks"
                        
                        # Configurar l√≠neas de graduaci√≥n cada 10%
                        chart.x_axis.majorUnit = 10
                        chart.x_axis.minorUnit = 5
                        chart.y_axis.majorUnit = 10
                        chart.y_axis.minorUnit = 5
                        
                        # Posici√≥n del gr√°fico en la hoja
                        ws.add_chart(chart, "H5")
                    else:
                        continue  # saltar hojas no reconocidas
                    
                # Guardar cambios
                buffer = io.BytesIO()
                wb.save(buffer)
                buffer.seek(0)

                st.download_button(
                    "üìä Descargar Excel con perfiles",
                    data=buffer.getvalue(),
                    file_name="perfiles_distribuciones.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
    with col2:
        st.subheader("üèóÔ∏è Distribuci√≥n de Bodega")
        if st.button("üì• Exportar an√°lisis de bodega", key="download_warehouse"):
            if 'analisis_categorias' in st.session_state:
                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
                    # Hoja An√°lisis por SKU
                    st.session_state['analisis_categorias'].to_excel(writer, sheet_name='Analisis_SKU', index=True)
                    
                    # Hoja C√°lculos de Capacidad
                    if 'calculos_capacidad' in st.session_state:
                        st.session_state['calculos_capacidad'].to_excel(writer, sheet_name='Calculos_Capacidad', index=True)
                
                    # Hoja Racks por Categor√≠a
                    if 'racks_categorias' in st.session_state:
                        st.session_state['racks_categorias'].to_excel(writer, sheet_name='Distribucion_Racks', index=True)
                    
                    # Hoja Resumen de Distribuci√≥n
                    if 'resumen_distribucion' in st.session_state:
                        st.session_state['resumen_distribucion'].to_excel(writer, sheet_name='Resumen_Distribucion', index=False)


                from openpyxl import load_workbook
                # üîπ Cargar el libro desde el mismo buffer
                buffer.seek(0)
                wb = load_workbook(buffer)

                from openpyxl.chart import PieChart, Reference
                from openpyxl.chart.label import DataLabelList


                # üîπ Insertar gr√°fico en hoja Distribucion_Racks
                if 'Distribucion_Racks' in wb.sheetnames:
                    ws2 = wb['Distribucion_Racks']
                    chart2 = PieChart()
                    labels2 = Reference(ws2, min_col=1, min_row=2, max_row=ws2.max_row)  # categor√≠as
                    data2 = Reference(ws2, min_col=7, min_row=1, max_row=ws2.max_row)    # columna con % racks
                    chart2.add_data(data2, titles_from_data=True)
                    chart2.set_categories(labels2)
                    chart2.title = "Distribuci√≥n de Racks por Categor√≠a"
                    chart2.dataLabels = DataLabelList()
                    chart2.dataLabels.showVal = True      # Muestra valores
                    chart2.dataLabels.showPercent = True  # (opcional) muestra % en vez de valores
                    chart2.dataLabels.showCatName = True  # (opcional) muestra nombre de categor√≠a
                    ws2.add_chart(chart2, "H5")  # posici√≥n del gr√°fico

                # üîπ Guardar de nuevo en buffer
                new_buffer = io.BytesIO()
                wb.save(new_buffer)
                new_buffer.seek(0)

                st.download_button(
                    "üì• Descargar Excel de Bodega",
                    data=new_buffer.getvalue(),
                    file_name='distribucion_bodega.xlsx',
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

            else:
                st.warning("Primero debes calcular la distribuci√≥n de bodega")

with st.expander("üìÑ Reportes PDF", expanded=False):
    # -------------------------------
    # Generar PDF completo robusto y profesional (mejorado)
    # -------------------------------
    if st.session_state.get('gen_pdf', False):
        if not PDF_LIBS_AVAILABLE:
            st.error('Para generar PDFs instala: pip install reportlab matplotlib')
        else:
            if st.button('4) Generar informe PDF'):
                from reportlab.lib import colors
                from reportlab.platypus import TableStyle, Image, PageBreak
                from reportlab.pdfgen import canvas
                from reportlab.lib.units import cm, mm
                from reportlab.platypus import BaseDocTemplate, Frame, PageTemplate
                import io, matplotlib.pyplot as plt

                # --- Pie de p√°gina con numeraci√≥n
                def add_page_number(canvas, doc):
                    page_num = canvas.getPageNumber()
                    text = f"P√°gina {page_num}"
                    canvas.setFont('Helvetica', 8)
                    canvas.drawRightString(200*mm, 10*mm, text)

                buffer = io.BytesIO()
                doc = BaseDocTemplate(
                    buffer,
                    pagesize=letter,
                    rightMargin=25, leftMargin=25,
                    topMargin=25, bottomMargin=18
                )
                frame = Frame(doc.leftMargin, doc.bottomMargin,
                            doc.width, doc.height, id='normal')
                template = PageTemplate(id='with-number',
                                        frames=frame,
                                        onPage=add_page_number)
                doc.addPageTemplates([template])

                styles = getSampleStyleSheet()
                elems = []

                # -------------------------------
                # Encabezado
                # -------------------------------
                elems.append(Paragraph('üìä Informe de An√°lisis - S√∫per ABC & Perfiles', styles['Title']))
                elems.append(Spacer(1, 14))

                # -------------------------------
                # Texto explicativo inicial
                # -------------------------------
                intro_text = """
                <b>Clasificaci√≥n de zonas de bodega:</b><br/>
                - <b>Zona Oro (Close to door, close to floor):</b> √Årea de mayor valor, ubicada estrat√©gicamente cerca de las puertas de entrada y salida de la bodega. Se destina a los productos de <b>alta rotaci√≥n</b>, minimizando tiempo de viaje y esfuerzo de los operarios.<br/>
                - <b>Zona Plata (Close to floor):</b> Ubicada a una distancia media de las puertas. Se utiliza para productos de <b>rotaci√≥n media</b>. El tiempo de acceso es moderado.<br/>
                - <b>Zona Bronce (Far from door, far from floor):</b> √Årea m√°s alejada de las puertas. Reservada para productos de <b>baja rotaci√≥n</b>. Aunque implica mayor tiempo de acceso, la baja frecuencia de movimiento lo justifica.<br/><br/>

                <b>Pol√≠ticas de inventario:</b><br/>
                - <b>ROP-OUL:</b> Reordenar al alcanzar el punto de pedido (ROP), con un l√≠mite superior (OUL) para evitar exceso de inventario.<br/>
                - <b>RTP-EOQ:</b> Pol√≠tica de revisi√≥n peri√≥dica (RTP), aplicando el tama√±o de lote econ√≥mico (EOQ) como cantidad √≥ptima de pedido.<br/>
                - <b>ROP-EOQ:</b> Pol√≠tica de reorden continuo (ROP), usando el EOQ como lote de reposici√≥n.<br/><br/>

                <b>Fill rate:</b> M√©trica de nivel de servicio que mide el porcentaje de demanda atendida en el primer intento con el inventario disponible. Un fill rate alto indica capacidad de satisfacer pedidos sin generar faltantes.<br/><br/>

                <b>IRA (Inventory Record Accuracy):</b> KPI que mide la exactitud del inventario, comparando los registros te√≥ricos del sistema con la realidad f√≠sica del stock disponible en un almac√©n. Un IRA alto indica que la informaci√≥n del sistema es confiable, lo que permite una gesti√≥n de inventarios m√°s eficiente, reduciendo p√©rdidas, excedentes y retrasos en los pedidos.  <br/><br/>

                <b>Recuento c√≠clico:</b> Estrategia de control de inventarios que consiste en revisar y contar de forma peri√≥dica subgrupos de productos a lo largo del a√±o. Se enfoca m√°s en art√≠culos cr√≠ticos o de mayor rotaci√≥n (categor√≠a A o AA), garantizando precisi√≥n de inventario sin necesidad de inventarios generales completos.
                """

                elems.append(Paragraph(intro_text, styles['Normal']))
                elems.append(Spacer(1, 14))

                # -------------------------------
                # Datos generales
                # -------------------------------
                file_name = st.session_state.get('file_name', uploaded_file.name if uploaded_file else 'Archivo no registrado')
                sheet_used = st.session_state.get('sheet_name', sheet_name or 'Hoja no registrada')
                vol_units = st.session_state.get('vol_units', unit_vol)
                criterios_usados = st.session_state.get('criterios_seleccionados', [crit1, crit2])
                cortes_abc = st.session_state.get('cortes_abc', {})
                
                # Para compatibilidad con c√≥digo existente
                crit1 = criterios_usados[0] if criterios_usados else 'Popularidad'
                crit2 = criterios_usados[1] if len(criterios_usados) > 1 else criterios_usados[0] if criterios_usados else 'Ventas'
                
                # Obtener cortes de la nueva estructura
                A_cut_1 = cortes_abc.get(crit1, {}).get('A', 0.8) if cortes_abc else 0.8
                B_cut_1 = cortes_abc.get(crit1, {}).get('B', 0.95) if cortes_abc else 0.95
                A_cut_2 = cortes_abc.get(crit2, {}).get('A', 0.8) if cortes_abc else 0.8
                B_cut_2 = cortes_abc.get(crit2, {}).get('B', 0.95) if cortes_abc else 0.95

                general_info = f"""
                <b>Documento le√≠do:</b> {file_name}<br/>
                <b>Hoja utilizada:</b> {sheet_used}<br/>
                <b>Unidades de volumen:</b> {vol_units}<br/>
                <b>Criterios utilizados:</b> {', '.join(criterios_usados)}<br/>
                """
                
                # Agregar cortes para cada criterio
                for criterio in criterios_usados:
                    if criterio in cortes_abc:
                        general_info += f"<b>Corte A ({criterio}):</b> {cortes_abc[criterio]['A']*100:.1f}%<br/>"
                        general_info += f"<b>Corte B ({criterio}):</b> {cortes_abc[criterio]['B']*100:.1f}%<br/>"
                elems.append(Paragraph(general_info, styles['Normal']))
                elems.append(Spacer(1, 12))

                by_item = st.session_state['by_item']
                base = st.session_state['base']

                # -------------------------------
                # Tabla resumen Super ABC (columnas compactas)
                # -------------------------------
                summary_table = by_item.groupby('Clase_SuperABC').agg(
                    Cantidad=('Clase_SuperABC','count'),
                    Zona_Bodega=('Zona_Bodega','first'),
                    Politica=('Pol√≠tica_Inv','first'),
                    FillRate=('FillRate_obj','first'),
                    Frecuencia_Recuento=('Frecuencia_Recuento','first'),
                    Ventas=('ventas','sum')
                ).reset_index()

                summary_table['Porcentaje'] = (summary_table['Cantidad']/summary_table['Cantidad'].sum()*100).round(2)
                total_sales = summary_table['Ventas'].sum()
                summary_table['% Ventas'] = (100 * summary_table['Ventas'] / (total_sales if total_sales>0 else 1)).round(2)
                summary_table['Ventas'] = summary_table['Ventas'].round(2)

                # üëâ Definir IRA seg√∫n categor√≠a usando la nueva funci√≥n
                summary_table['IRA'] = summary_table['Clase_SuperABC'].apply(ira_by_class)

                # Reordenar columnas para poner IRA despu√©s de FillRate
                cols = list(summary_table.columns)
                insert_pos = cols.index('FillRate') + 1
                cols = cols[:insert_pos] + ['IRA'] + cols[insert_pos:-1]  # dejamos % Ventas al final
                summary_table = summary_table[cols]

                # preparar datos y anchos
                data = [list(summary_table.columns)] + summary_table.round(2).astype(str).values.tolist()
                col_widths = []
                for col in summary_table.columns:
                    if col in ['Cantidad','Zona_Bodega','FillRate','IRA']:
                        col_widths.append(45)
                    elif col in ['Ventas','Porcentaje','% Ventas']:
                        col_widths.append(50)
                    elif col in ['Clase_SuperABC','Frecuencia_Recuento']:
                        col_widths.append(70)
                    else:
                        col_widths.append(97)

                t = Table(data, colWidths=col_widths, hAlign='CENTER')
                t.setStyle(TableStyle([
                    ('GRID', (0,0), (-1,-1), 0.5, colors.black),
                    ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),
                    ('FONTSIZE', (0,0), (-1,-1), 7),
                    ('ALIGN',(0,0),(-1,-1),'CENTER')
                ]))
                elems.append(Paragraph('üìë Resumen por categor√≠a (AA..CC)', styles['Heading2']))
                elems.append(t)
                elems.append(PageBreak())

                # -------------------------------
                # Funci√≥n auxiliar para a√±adir figuras
                # -------------------------------
                def add_fig(fig, title='', width=450, height=240):
                    img_buf = io.BytesIO()
                    fig.tight_layout()
                    fig.savefig(img_buf, format='png', dpi=130)
                    plt.close(fig)
                    img_buf.seek(0)
                    elems.append(Paragraph(title, styles['Heading3']))
                    elems.append(Image(img_buf, width=width, height=height))
                    elems.append(Spacer(1, 12))
                # -------------------------------
                # Gr√°fica Pareto
                # -------------------------------

                pareto = by_item.sort_values('popularidad', ascending=False).copy()
                pareto['cum_picks'] = pareto['popularidad'].cumsum()
                total_picks = pareto['popularidad'].sum()
                pareto['cum_pct_picks'] = 100*pareto['cum_picks']/(total_picks if total_picks>0 else 1)
                pareto['pct_sku'] = 100 * np.arange(1,len(pareto)+1)/len(pareto)
                fig1, ax1 = plt.subplots(figsize=(6,3))
                ax1.plot(pareto['pct_sku'], pareto['cum_pct_picks'], marker='o')
                ax1.set_xlabel('% SKU (acumulado)')
                ax1.set_ylabel('% picks (acumulado)')
                ax1.set_title('Distribuci√≥n de popularidad')
                add_fig(fig1, 'Pareto de popularidad')
                            
                pareto_intro = """
                Este perfil muestra qu√© porcentaje acumulado de los movimientos de picking corresponde a qu√© porcentaje acumulado de SKUs seg√∫n el principio de Pareto (muchos triviales, pocos vitales). 
                Permite identificar los productos que concentran la mayor parte de la actividad y que deben recibir prioridad en la bodega.
                """
                elems.append(Paragraph(pareto_intro, styles['Normal']))
                elems.append(Spacer(1, 6))

                elems.append(PageBreak())

                # -------------------------------
                # L√≠neas por orden
                # -------------------------------
                lines_per_order = base.groupby('NumDoc').agg(lineas=('Articulo','nunique')).reset_index()
                dist_lines = lines_per_order.groupby('lineas').size().rename('conteo').reset_index()
                total_orders = dist_lines['conteo'].sum()
                dist_lines['%_ordenes'] = 100*dist_lines['conteo']/(total_orders if total_orders>0 else 1)
                fig2, ax2 = plt.subplots(figsize=(6,3))
                ax2.bar(dist_lines['lineas'].astype(str), dist_lines['%_ordenes'])
                ax2.set_xlabel('L√≠neas por orden')
                ax2.set_ylabel('% de √≥rdenes')
                ax2.set_title('Distribuci√≥n de l√≠neas por orden')
                add_fig(fig2, 'L√≠neas por orden')
                
                lines_intro = """
                Este perfil muestra cu√°ntas l√≠neas (SKUs distintos) tiene cada pedido y qu√© porcentaje de √≥rdenes corresponde a cada cantidad de l√≠neas. 
                Permite evaluar la complejidad de los pedidos y planificar recursos de picking y personal.
                """
                elems.append(Paragraph(lines_intro, styles['Normal']))
                elems.append(Spacer(1, 6))
                elems.append(PageBreak())

                # -------------------------------
                # Cubicaje por orden
                # -------------------------------

                cubic_per_order = base.groupby('NumDoc').agg(volumen_total=('Volumen_p3','sum')).reset_index()
                vol_bins = [-1,1,2,5,10,20,50,1e9]
                vol_labels = ['‚â§1','1-2','2-5','5-10','10-20','20-50','>50']
                cubic_per_order['vol_bin'] = pd.cut(cubic_per_order['volumen_total'], bins=vol_bins, labels=vol_labels)
                dist_cubic = cubic_per_order.groupby('vol_bin').size().rename('conteo').reset_index()
                total_orders2 = dist_cubic['conteo'].sum()
                dist_cubic['%_ordenes'] = 100*dist_cubic['conteo']/(total_orders2 if total_orders2>0 else 1)
                fig3, ax3 = plt.subplots(figsize=(6,3))
                ax3.bar(dist_cubic['vol_bin'].astype(str), dist_cubic['%_ordenes'])
                ax3.set_xlabel('Rango volumen (pies¬≥)')
                ax3.set_ylabel('% de √≥rdenes')
                ax3.set_title('Distribuci√≥n de volumen por orden')
                add_fig(fig3, 'Volumen por orden')

                cubic_intro = """
                El presente perfil ilustra mediante una gr√°fica el rango de volumen total de los pedidos y su porcentaje sobre el total de √≥rdenes. 
                Es √∫til para dimensionar espacio de almacenamiento, cajas, pallets y veh√≠culos de transporte, seg√∫n requerimientos de espacio y rotaci√≥n.
                """
                elems.append(Paragraph(cubic_intro, styles['Normal']))
                elems.append(Spacer(1, 6))
                elems.append(PageBreak())

                # Recalcular lv y dist_incremento para el PDF
                lv = base.groupby('NumDoc').agg(
                    lineas=('Articulo','nunique'),
                    volumen_total=('Volumen_p3','sum')
                ).reset_index()

                VOLUMEN_TARIMA = st.session_state.get('vol_tarima', 42.38)
                lv['%_carga_unidad'] = 100 * lv['volumen_total'] / VOLUMEN_TARIMA
                lv['%_carga_unidad'] = lv['%_carga_unidad'].clip(upper=100)
                carga_bins = list(range(0, 105, 5))
                carga_labels = [f'{i}-{i+5}%' for i in range(0, 100, 5)]
                lv['r_carga'] = pd.cut(lv['%_carga_unidad'], bins=carga_bins, labels=carga_labels, right=True, include_lowest=True)
                dist_incremento = lv.groupby(['r_carga']).agg(
                    pedidos=('NumDoc', 'count'),
                    lineas_prom=('lineas', 'mean')
                ).reset_index()
                dist_incremento['%_lineas_pedido'] = 100 * dist_incremento['pedidos'] / dist_incremento['pedidos'].sum()

                # Gr√°fica de incremento de pedidos (carga unitaria vs % l√≠neas de pedido)
                fig_inc, ax_inc = plt.subplots(figsize=(6,3))
                ax_inc.bar(dist_incremento['r_carga'].astype(str), dist_incremento['%_lineas_pedido'])
                ax_inc.set_xlabel('% de carga unitaria (tarima)')
                ax_inc.set_ylabel('% de l√≠neas de pedido')
                ax_inc.set_title('Distribuci√≥n por incremento de pedidos')
                plt.setp(ax_inc.get_xticklabels(), rotation=60, ha='right', fontsize=7)  # Rota y reduce fuente
                add_fig(fig_inc, 'Distribuci√≥n por incremento de pedidos')

                inc_intro = """
                Esta gr√°fica muestra la proporci√≥n de l√≠neas de pedido seg√∫n el porcentaje de carga unitaria (por ejemplo, respecto a una tarima completa).
                Permite visualizar cu√°ntos pedidos representan cargas parciales o completas, facilitando la planificaci√≥n log√≠stica y el uso eficiente de espacio.
                """
                elems.append(Paragraph(inc_intro, styles['Normal']))
                elems.append(Spacer(1, 6))
                elems.append(PageBreak())

                # -------------------------------
                # Distribuci√≥n por d√≠a de la semana
                # -------------------------------

                orders_dates = base.groupby('NumDoc').agg(fecha=('Fecha','max')).reset_index()
                orders_dates['dia'] = orders_dates['fecha'].dt.day_name()
                mapping_days = {'Monday':'Lunes','Tuesday':'Martes','Wednesday':'Mi√©rcoles','Thursday':'Jueves',
                                'Friday':'Viernes','Saturday':'S√°bado','Sunday':'Domingo'}
                orders_dates['dia'] = orders_dates['dia'].replace(mapping_days)
                day_order = ['Lunes','Martes','Mi√©rcoles','Jueves','Viernes','S√°bado','Domingo']
                dist_days = orders_dates.groupby('dia').size().reindex(day_order).fillna(0).astype(int).rename('conteo').reset_index()
                dist_days['%_ordenes'] = 100*dist_days['conteo']/dist_days['conteo'].sum()
                fig4, ax4 = plt.subplots(figsize=(6,3))
                ax4.bar(dist_days['dia'], dist_days['%_ordenes'])
                ax4.set_xlabel('D√≠a')
                ax4.set_ylabel('% de √≥rdenes')
                ax4.set_title('Distribuci√≥n de √≥rdenes por d√≠a de la semana')
                add_fig(fig4, '√ìrdenes por d√≠a de la semana')

                days_intro = """
                Este muestra c√≥mo se distribuyen los pedidos a lo largo de la semana y su porcentaje sobre el total. 
                Permite planificar personal, turnos y recursos log√≠sticos en funci√≥n de los picos y valles de demanda, identificando qu√© d√≠as presentan mayor ingreso de √≥rdenes.
                """
                elems.append(Paragraph(days_intro, styles['Normal']))
                elems.append(PageBreak())

                # -------------------------------
                # Tabla cruzada l√≠neas x volumen con % pedidos, Totales y Total L√≠nea
                # -------------------------------

                lv = base.groupby('NumDoc').agg(
                    lineas=('Articulo','nunique'),
                    volumen_total=('Volumen_p3','sum')
                ).reset_index()

                # Definir rangos (misma l√≥gica que en Streamlit)
                line_labels = ['1','2-5','6-9','10+']
                vol_labels2 = ['0-1','1-2','2-5','5-10','10-20','20+']

                # Categorizar (igual que en la app)
                lv['r_lineas'] = pd.cut(lv['lineas'], bins=[0,1,5,9,1e9], labels=line_labels, right=True, include_lowest=True)
                lv['r_vol'] = pd.cut(lv['volumen_total'], bins=[0,1,2,5,10,20,1e9], labels=vol_labels2, right=True, include_lowest=True)

                # Conteos y totales
                ct_counts = pd.crosstab(lv['r_lineas'], lv['r_vol'], dropna=False)
                ct_counts = ct_counts.reindex(index=line_labels, columns=vol_labels2, fill_value=0)
                ct_counts['Totales'] = ct_counts.sum(axis=1)

                # üîπ Total de l√≠neas (sumando l√≠neas, no volumen)
                pivot_lines = pd.pivot_table(
                    lv, index='r_lineas',
                    values='lineas', aggfunc='sum', fill_value=0
                ).reindex(index=line_labels, fill_value=0)
                pivot_lines['% linea'] = (pivot_lines['lineas'] / pivot_lines['lineas'].sum() * 100).round(2)

                # Volumen total (solo para fila de "Espacio total")
                pivot_vol = pd.pivot_table(
                    lv, index='r_lineas', columns='r_vol',
                    values='volumen_total', aggfunc='sum', fill_value=0
                ).reindex(index=line_labels, columns=vol_labels2, fill_value=0).round(2)

                # Construir tabla combinada
                data_cross = []

                # Encabezado combinado
                data_cross.append(
                    ['L√≠neas por orden'] 
                    + ['Volumen por pedido (pies¬≥)']*len(vol_labels2) 
                    + ['Totales','% pedidos','Total L√≠nea','% l√≠nea']
                )
                data_cross.append(
                    [''] + vol_labels2 + ['Totales','% pedidos','Total L√≠nea','% l√≠nea']
                )

                # Filas por r_lineas
                for idx in line_labels:
                    row_counts = ct_counts.loc[idx, vol_labels2].tolist()
                    row_total = ct_counts.loc[idx, 'Totales']
                    row_pct_pedidos = (row_total / ct_counts['Totales'].sum() * 100).round(2)
                    row_total_linea = int(pivot_lines.loc[idx, 'lineas'])  # üîπ ahora es la suma de l√≠neas
                    row_pct_linea = float(pivot_lines.loc[idx, '% linea'])
                    data_cross.append([idx] + row_counts + [row_total, row_pct_pedidos, row_total_linea, row_pct_linea])

                # üëâ Fila de Totales
                tot_row_counts = ct_counts[vol_labels2].sum().tolist()
                tot_total = ct_counts['Totales'].sum()
                tot_pct_pedidos = 100.0
                tot_total_linea = int(pivot_lines['lineas'].sum())  # üîπ total l√≠neas global
                tot_pct_linea = 100.0
                data_cross.append(['Totales'] + tot_row_counts + [tot_total, tot_pct_pedidos, tot_total_linea, tot_pct_linea])

                # Fila de % pedidos (por columna de volumen + total)
                pct_pedidos_cols = (ct_counts[vol_labels2].sum() / ct_counts['Totales'].sum() * 100).round(2).tolist()
                pct_pedidos_total = round(sum(pct_pedidos_cols), 2)
                row_pct_pedidos = ['% pedidos'] + pct_pedidos_cols + [pct_pedidos_total, '', '', '']
                data_cross.append(row_pct_pedidos)

                # Fila de volumen total por columna
                vol_values = pivot_vol[vol_labels2].sum().round(2).tolist()
                row_vol_total = ['Espacio total'] + vol_values + [pivot_vol.values.sum().round(2), '', '', '']
                data_cross.append(row_vol_total)

                # Configurar tabla PDF
                col_widths_cross = [50] + [50]*len(vol_labels2) + [50,50,50,50]
                t_cross = Table(data_cross, colWidths=col_widths_cross, hAlign='CENTER')
                t_cross.setStyle(TableStyle([
                    ('SPAN',(1,0),(len(vol_labels2),0)),  # unir fila 0 columnas de volumen
                    ('SPAN',(len(vol_labels2)+1,0),(len(vol_labels2)+1,1)),  # Totales
                    ('SPAN',(len(vol_labels2)+2,0),(len(vol_labels2)+2,1)),  # % pedidos
                    ('SPAN',(len(vol_labels2)+3,0),(len(vol_labels2)+3,1)),  # Total L√≠nea
                    ('SPAN',(len(vol_labels2)+4,0),(len(vol_labels2)+4,1)),  # % l√≠nea
                    ('GRID',(0,0),(-1,-1),0.5,colors.black),
                    ('BACKGROUND',(0,0),(-1,1),colors.lightgrey),
                    ('BACKGROUND',(0,-3),(-1,-3),colors.lightgrey),  # Totales fila
                    ('BACKGROUND',(0,-2),(-1,-2),colors.whitesmoke),  # % pedidos
                    ('BACKGROUND',(0,-1),(-1,-1),colors.whitesmoke),  # espacio total
                    ('FONTSIZE',(0,0),(-1,-1),6),
                    ('ALIGN',(0,0),(-1,-1),'CENTER'),
                    ('VALIGN',(0,0),(-1,-1),'MIDDLE')
                ]))
                elems.append(Paragraph('Tabla cruzada: l√≠neas por orden vs volumen', styles['Heading2']))
                cross_intro = """
                Permite ver cu√°ntos pedidos combinan cierta cantidad de l√≠neas con un rango de volumen determinado, 
                junto con totales, porcentaje de pedidos y porcentaje de l√≠neas. 
                Esto ayuda a identificar combinaciones de pedidos frecuentes o cr√≠ticas y optimizar la disposici√≥n de la bodega y flujos de picking.
                """
                elems.append(Paragraph(cross_intro, styles['Normal']))
                elems.append(Spacer(1, 6))
                elems.append(t_cross)
                elems.append(Spacer(1, 10))


                # -------------------------------
                # Construir PDF
                # -------------------------------
                doc.build(elems)
                buffer.seek(0)
                st.download_button(
                    'üìÑ Descargar Informe PDF',
                    data=buffer.getvalue(),
                    file_name='informe_super_abc_completo.pdf',
                    mime='application/pdf'
                )
            else:
                st.info("Haz clic en el bot√≥n para generar el informe PDF.")
    else:
        st.warning("Habilita 'Generar informe PDF' en la configuraci√≥n del sidebar para usar esta funci√≥n.")

st.success('C√°lculos finalizados. Ajusta cortes y vuelve a calcular seg√∫n necesites.')
