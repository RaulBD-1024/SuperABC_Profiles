"""
Inventory Insight App Interactiva - by Ra√∫l Bola√±os D√≠az - 2025
=====================================
"""

import io
import unicodedata
import numpy as np
import pandas as pd
import seaborn as sns
import plotly.express as px
import streamlit as st

import statsmodels.api as sm
from prophet import Prophet
from prophet.plot import plot_plotly, plot_components_plotly


# Para generar PDF/plots
try:
    import matplotlib.pyplot as plt
    from reportlab.lib.pagesizes import letter
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table
    from reportlab.lib.styles import getSampleStyleSheet
    PDF_LIBS_AVAILABLE = True
except Exception:
    PDF_LIBS_AVAILABLE = False

# -------------------------------
# Utilidades
# -------------------------------

def sanitize_filename(s: str) -> str:
    # elimina acentos y caracteres especiales, deja ascii y guiones bajos
    s = str(s)
    s = unicodedata.normalize('NFKD', s)
    s = s.encode('ascii', 'ignore').decode('ascii')
    s = s.replace(' ', '_')
    allowed = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_-"
    return ''.join(c for c in s if c in allowed)

def sanitize_colnames(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [unicodedata.normalize('NFKD', str(c)).encode('ascii','ignore').decode('ascii') for c in df.columns]
    df.columns = [c.replace(' ', '_') for c in df.columns]
    return df

def minmax_normalize(s: pd.Series) -> pd.Series:
    s = s.fillna(0)
    rng = s.max() - s.min()
    if rng == 0:
        return pd.Series(np.zeros(len(s)), index=s.index)
    return (s - s.min()) / rng

@st.cache_data(show_spinner=False, ttl=3600)  # Cache por 1 hora
def read_excel_bytes(file_bytes: bytes, sheet_name=None):
    """
    Lee un archivo Excel desde bytes.
    
    Args:
        file_bytes: Bytes del archivo Excel
        sheet_name: Nombre de la hoja a leer (None para todas las hojas)
    
    Returns:
        DataFrame si sheet_name est√° especificado, dict si no
    """
    try:
        if sheet_name:
            # Leer hoja espec√≠fica
            return pd.read_excel(io.BytesIO(file_bytes), sheet_name=sheet_name, engine='openpyxl')
        else:
            # Leer todas las hojas
            return pd.read_excel(io.BytesIO(file_bytes), sheet_name=None, engine='openpyxl')
    except Exception as e:
        # Si falla con openpyxl, intentar con xlrd para archivos .xls
        try:
            return pd.read_excel(io.BytesIO(file_bytes), sheet_name=sheet_name, engine='xlrd')
        except:
            raise e

# ABC por contribuci√≥n acumulada

def safe_col(df: pd.DataFrame, name: str, alt_names=None):
    """Busca una columna tolerando espacios, may√∫sculas/min√∫sculas o nombres alternativos."""
    if alt_names is None:
        alt_names = []
    # Diccionario para b√∫squeda insensible a may√∫sculas/min√∫sculas y espacios
    alt = {c.strip().lower(): c for c in df.columns}
    key = name.strip().lower()
    # Revisar nombre principal
    if key in alt:
        return df[alt[key]]
    # Revisar nombres alternativos
    for alt_name in alt_names:
        k = alt_name.strip().lower()
        if k in alt:
            return df[alt[k]]
    raise KeyError(f"No se encontr√≥ la columna requerida: {name}")


def cycle_count_freq(zone: str) -> str:
    return {'Oro':'Semanal/Mensual','Plata':'Mensual/Trimestral','Bronce':'Trimestral/Semestral'}.get(zone, 'Trimestral')


def abc_by_contribution(series: pd.Series, A_cut: float, B_cut: float) -> pd.Series:
    df_tmp = series.rename('metric').to_frame()
    df_tmp = df_tmp.sort_values('metric', ascending=False)
    total = df_tmp['metric'].sum()
    if total <= 0:
        return pd.Series('C', index=series.index)
    df_tmp['cum_contrib'] = df_tmp['metric'].cumsum() / total
    df_tmp['cls'] = np.where(df_tmp['cum_contrib'] <= A_cut, 'A', np.where(df_tmp['cum_contrib'] <= B_cut, 'B', 'C'))
    return df_tmp['cls'].reindex(series.index)

@st.cache_data(show_spinner=False, ttl=1800)  # Cache por 30 minutos
def generate_super_abc_combinations(by_item: pd.DataFrame, criterios_seleccionados: list, cortes_abc: dict, criterios_map: dict) -> pd.DataFrame:
    """
    Genera todas las combinaciones posibles de clasificaciones ABC para m√∫ltiples criterios.
    
    Args:
        by_item: DataFrame con m√©tricas por art√≠culo
        criterios_seleccionados: Lista de criterios seleccionados
        cortes_abc: Diccionario con los cortes A y B para cada criterio
        criterios_map: Mapeo de nombres de criterios a columnas del DataFrame
    
    Returns:
        DataFrame con las clasificaciones ABC para cada criterio y la combinaci√≥n final
    """
    import itertools
    
    # Calcular clasificaci√≥n ABC para cada criterio
    for criterio in criterios_seleccionados:
        col_name = criterios_map[criterio]
        A_cut = cortes_abc[criterio]['A']
        B_cut = cortes_abc[criterio]['B']
        by_item[f'ABC_{criterio}'] = abc_by_contribution(by_item[col_name], A_cut, B_cut)
    
    # Generar todas las combinaciones posibles
    abc_values = ['A', 'B', 'C']
    combinaciones = list(itertools.product(abc_values, repeat=len(criterios_seleccionados)))
    
    # Crear la clasificaci√≥n combinada
    def create_combination_class(row):
        combination = ''.join([row[f'ABC_{criterio}'] for criterio in criterios_seleccionados])
        return combination
    
    by_item['Clase_SuperABC'] = by_item.apply(create_combination_class, axis=1)
    
    return by_item

# Map zone from combined class

def map_zone(clase: str) -> str:
    """
    Asigna una zona (Oro, Plata, Bronce) considerando:
    - La letra m√°s importante est√° al inicio.
    - Las letras A, B, C tienen pesos 3, 2 y 1 respectivamente.
    - Se aplica un promedio ponderado seg√∫n posici√≥n.
    Compatible con clases de 2, 3 o m√°s letras.
    """
    if not isinstance(clase, str) or clase.strip() == "":
        return "Bronce"

    clase = clase.strip().upper()
    pesos_letras = {'A': 3, 'B': 2, 'C': 1}

    # Ponderar m√°s las letras de la izquierda
    n = len(clase)
    pesos_posicionales = list(range(n, 0, -1))  # Ej: [3,2,1] para 3 letras

    total = 0
    total_peso = 0
    for letra, peso_pos in zip(clase, pesos_posicionales):
        valor = pesos_letras.get(letra, 1)
        total += valor * peso_pos
        total_peso += peso_pos

    promedio_ponderado = total / total_peso

    # Umbrales calibrados con tus datos reales
    if promedio_ponderado >= 2.45:
        return "Oro"
    elif promedio_ponderado >= 2:
        return "Plata"
    else:
        return "Bronce"

def policy_by_demand(cv: float, intermittency: float) -> str:
    if intermittency >= 0.5:
        return 'RTP-EOQ (items intermitentes)'
    if cv < 0.5:
        return 'ROP-OUL (alta estabilidad)'
    if cv < 1.0:
        return 'ROP-EOQ (variabilidad media)'
    return 'RTP-EOQ (alta variabilidad)'

# Fill rates nuevos (usar guion ASCII)

def target_fill_rate(zone: str) -> str:
    if zone == 'Oro':
        return '99-90%'
    if zone == 'Plata':
        return '89-80%'
    if zone == 'Bronce':
        return '70-80%'
    return '80-90%'

# Week floor
from datetime import datetime

def week_floor(dt: pd.Series) -> pd.Series:
    return dt.dt.to_period('W-MON').dt.start_time

# -------------------------------
# UI
# -------------------------------
st.set_page_config(page_title='Inventory Insight App', layout='wide')
st.title('üì¶ Inventory Insight App')

st.markdown("""
Bienvenido a **Inventory Insight App** üöÄ  

Desarrollado por Ra√∫l Bola√±os D√≠az - 2025
            
Esta herramienta integral permite analizar y optimizar la gesti√≥n de inventarios mediante una clasificaci√≥n **S√∫per ABC** multi-criterio, an√°lisis de distribuci√≥n de bodega y estudio de demandas.  

### üéØ **Funcionalidades Principales:**

#### üìä **1. An√°lisis S√∫per ABC Multi-Criterio**
- Clasificaci√≥n combinada de productos seg√∫n el principio de Pareto
- M√∫ltiples criterios simult√°neos (ventas, popularidad, rotaci√≥n, volumen)
- Pol√≠ticas de inventario personalizadas por categor√≠a
- Zonificaci√≥n autom√°tica de bodega (Oro, Plata, Bronce)

#### üèóÔ∏è **2. Distribuci√≥n Inteligente de Bodega**
- An√°lisis detallado por SKU con c√°lculos de inventario √≥ptimo
- C√°lculo de racks, pallets y espacio necesario por categor√≠a
- Tablas de vol√∫menes y distribuci√≥n porcentual
- Optimizaci√≥n de utilizaci√≥n de espacio

#### üìà **3. Perfiles de Actividad Avanzados**
- An√°lisis de Pareto de popularidad
- Distribuci√≥n de l√≠neas por pedido
- Perfiles de cubicaje y carga unitaria
- An√°lisis cruzado l√≠neas vs volumen

#### üîÆ **4. An√°lisis de Demanda**
- Series hist√≥ricas individuales por SKU o Familia
- Estudios de tendencia y estacionalidad
- Alternativas para series muy cortas o irregulares (tendencia suavizada y ACF [Autocorrelaci√≥n])

#### üìã **5. An√°lisis de Contribuci√≥n**
- Contribuci√≥n por categor√≠a ABC a ventas, volumen y popularidad
- Visualizaciones comparativas
- M√©tricas de impacto por categor√≠a
            
### üì¶ **Registros y optimizaci√≥n de almac√©n:**
- An√°lisis de ubicaciones actuales vs sugeridas
- Sugerencias de reubicaci√≥n basadas en actividad
- Sistema de registros de movimientos de producto y actualizaci√≥n de ocupaci√≥n
- Optimizaci√≥n de espacio y racks

#### üì• **6. Exportaci√≥n Completa**
- Excel con m√∫ltiples hojas organizadas
- Gr√°ficas integradas en Excel
- Perfiles de actividad detallados
- Reportes PDF profesionales

### üöÄ **Gu√≠a de uso:**
1. **Carga de datos** ‚Üí Sube tu Excel con datos de ventas
2. **Configuraci√≥n** ‚Üí Define criterios y cortes ABC
3. **An√°lisis S√∫per ABC** ‚Üí Clasificaci√≥n autom√°tica multi-criterio
4. **Perfiles de Actividad** ‚Üí An√°lisis detallado de patrones
5. **Distribuci√≥n de Bodega** ‚Üí Optimizaci√≥n de espacio y racks
6. **Demanda** ‚Üí An√°lisis de demanda y estacionalidad avanzado por SKU o Familia
7. **Exportaci√≥n** ‚Üí Descarga resultados completos

‚ÑπÔ∏è Esta aplicaci√≥n est√° pensada como apoyo para decisiones de **gesti√≥n de inventario y almacenamiento**, facilitando el an√°lisis ABC tradicional y extendido.
""")

# -------------------------------
# Advertencia sobre formato del Excel
# -------------------------------
st.info("""
üìÇ **Configuraci√≥n del archivo Excel requerida:**

El archivo debe contener **exactamente** las siguientes columnas (respetando los nombres, aunque la aplicaci√≥n es tolerante a espacios y may√∫sculas/min√∫sculas):

- `Num. Doc` ‚Üí N√∫mero de documento / pedido (factura)
- `Art√≠culo` ‚Üí Identificador √∫nico del producto 
- `Familia` ‚Üí Categor√≠a principal del producto 
- `Unid. Vend` ‚Üí Cantidad de unidades vendidas  
- `Monto venta` ‚Üí Monto total de venta  
- `Cajas vend.` ‚Üí Cantidad de cajas vendidas (requerido para forecasting y sugerencias de distribuci√≥n de bodega)
- `Cant x caja.` ‚Üí Cantidad de unidades por caja (opcional, pero recomendado para an√°lisis de carga unitaria)
- `Volumen total (p3) o Volumen total (m3)` ‚Üí Volumen total del producto. Puede estar en **pies¬≥** o **metros¬≥**. La unidad se selecciona en el panel lateral y se convertir√° autom√°ticamente para los c√°lculos internos.   
- `Fecha Doc` ‚Üí Fecha del documento/pedido en formato DD/MM/AAAA. 
- `Num Cliente` ‚Üí Identificador del cliente (opcional, pero recomendado para an√°lisis de popularidad)
- `Num Pa√≠s` ‚Üí Identificador del pa√≠s (opcional, pero recomendado para an√°lisis de popularidad)

‚ö†Ô∏è **Importante:** Si alguna columna no existe o tiene un nombre diferente, la aplicaci√≥n no podr√° procesar los datos correctamente.  
Aseg√∫rate de seleccionar la unidad correcta en la barra lateral para que los c√°lculos de volumen sean consistentes.
""")

with st.sidebar:
    st.header('1) Cargar datos')
    uploaded_file = st.file_uploader('Excel de ventas/ordenes', type=['xlsx','xls'])
    sheet_name = st.text_input('Hoja (opcional)', help='Si tu Excel tiene m√∫ltiples hojas, especifica cu√°l usar. Si no especificas, se usar√° la primera.')
    unit_vol = st.selectbox('Unidad de volumen', ['pies3 (p3)','metros3 (m3)'])
    vol_factor = 35.3147 if unit_vol == 'metros3 (m3)' else 1.0

    # Permitir al usuario definir el volumen de una tarima
    default_tarima = 42.38 if unit_vol == 'pies3 (p3)' else 1.2
    vol_tarima = st.number_input(
        'Volumen de una tarima completa',
        min_value=0.01,
        value=default_tarima,
        help='Define el volumen de una tarima en la unidad seleccionada'
    )
    # Guardar en session_state para usarlo en PDF y an√°lisis
    st.session_state['vol_tarima'] = vol_tarima

    st.header('2) Criterios ABC (elige m√∫ltiples)')
    criterios = {
        'Popularidad': 'popularidad',
        'Rotacion': 'rotacion_sem',
        'Ventas': 'ventas',
        'Volumen': 'volumen'
    }
    
    # Permitir selecci√≥n m√∫ltiple de criterios
    criterios_seleccionados = st.multiselect(
        'Selecciona los criterios a aplicar (m√≠nimo 2):',
        list(criterios.keys()),
        default=['Rotacion', 'Ventas'],
        help='Puedes seleccionar 2 o m√°s criterios. Se generar√°n todas las combinaciones posibles.'
    )
    
    # Validar que se seleccionen al menos 2 criterios
    if len(criterios_seleccionados) < 2:
        st.warning('‚ö†Ô∏è Debes seleccionar al menos 2 criterios para continuar.')
        st.stop()
    
    # Mostrar informaci√≥n sobre las combinaciones que se generar√°n
    num_combinaciones = 3 ** len(criterios_seleccionados)  # A, B, C para cada criterio
    st.info(f"üìä Se generar√°n {num_combinaciones} combinaciones posibles (A, B, C para cada criterio)")
    
    # Para compatibilidad con el c√≥digo existente, mantener crit1 y crit2
    crit1 = criterios_seleccionados[0]
    crit2 = criterios_seleccionados[1] if len(criterios_seleccionados) > 1 else criterios_seleccionados[0]

    st.header('3) Cortes ABC por contribucion (A, B)')
    
    # Crear sliders din√°micos para cada criterio seleccionado
    cortes_abc = {}
    for i, criterio in enumerate(criterios_seleccionados):
        st.subheader(f'Criterio: {criterio}')
        A_cut = st.slider(f'A ({criterio})', 50, 95, 80, key=f'A_cut_{criterio}_{i}') / 100.0
        B_cut = st.slider(f'B ({criterio})', int(A_cut*100)+1, 99, 95, key=f'B_cut_{criterio}_{i}') / 100.0
        cortes_abc[criterio] = {'A': A_cut, 'B': B_cut}
    
    # Guardar en session_state usando claves √∫nicas
    st.session_state['criterios_seleccionados'] = criterios_seleccionados
    st.session_state['cortes_abc'] = cortes_abc

    # Configuraci√≥n de exportaci√≥n (se mover√° al final)
    st.session_state['want_csv'] = st.checkbox('Permitir descarga Excel', True)
    st.session_state['gen_pdf'] = st.checkbox('Generar informe PDF', False)

if uploaded_file is None:
    st.info('Sube un Excel para comenzar')
    st.stop()

# -------------------------------
# Leer datos
# -------------------------------
try:
    df = read_excel_bytes(uploaded_file.read(), sheet_name=sheet_name or None)
    
    # Verificar si df es un diccionario (m√∫ltiples hojas)
    if isinstance(df, dict):
        st.warning("‚ö†Ô∏è El archivo Excel contiene m√∫ltiples hojas.")
        st.write("**Hojas disponibles:**", list(df.keys()))
        
        if sheet_name and sheet_name in df:
            df = df[sheet_name]
            st.info(f"‚úÖ Usando la hoja especificada: '{sheet_name}'")
        else:
            # Si no se especific√≥ hoja, usar la primera
            primera_hoja = list(df.keys())[0]
            df = df[primera_hoja]
            st.info(f"‚úÖ Usando la primera hoja: '{primera_hoja}'")
            st.write("üí° **Tip:** Puedes especificar una hoja espec√≠fica en el campo 'Hoja (opcional)' en la barra lateral")
    
    # Verificar que df es un DataFrame
    if not isinstance(df, pd.DataFrame):
        st.error("‚ùå Error: No se pudo cargar el archivo como DataFrame")
        st.stop()
    
    # Mostrar informaci√≥n del archivo cargado
    st.success(f"‚úÖ Archivo cargado exitosamente: {uploaded_file.name}")
    st.info(f"üìä Dimensiones del archivo: {df.shape[0]} filas x {df.shape[1]} columnas")
    
    # Mostrar las columnas disponibles
    st.subheader("üìã Columnas disponibles en el archivo:")
    columnas_disponibles = list(df.columns)
    st.write(columnas_disponibles)
    
    # Verificar si existe la columna 'Art√≠culo'
    if 'Art√≠culo' not in df.columns:
        st.error("‚ùå No se encontr√≥ la columna 'Art√≠culo' en el archivo.")
        st.write("**Columnas disponibles:**", columnas_disponibles)
        st.write("**Por favor verifica que tu archivo Excel contenga una columna llamada 'Art√≠culo'**")
        st.stop()
    
    # Limpiar espacios y may√∫sculas/min√∫sculas
    df['Art√≠culo_LIMPIO'] = df['Art√≠culo'].astype(str).str.strip().str.upper()
    
except Exception as e:
    st.error(f'Error leyendo Excel: {e}')
    st.write("**Posibles causas:**")
    st.write("- El archivo no es un Excel v√°lido")
    st.write("- El archivo est√° corrupto")
    st.write("- No tienes permisos para leer el archivo")
    st.write("- El archivo est√° siendo usado por otra aplicaci√≥n")
    st.write("- El archivo tiene m√∫ltiples hojas y no se especific√≥ cu√°l usar")
    st.stop()

# map columns tolerant
try:
    st.subheader("üîç Verificando columnas requeridas...")
    
    # Verificar cada columna requerida
    columnas_requeridas = {
        'Unid. Vend': ['Unid. Vend', 'Unidades Vendidas', 'Cantidad', 'Qty'],
        'Monto venta': ['Monto venta', 'Monto Venta', 'Valor', 'Total'],
        'Volumen total (p3)': ['Volumen total (p3)', 'Volumen total (m3)', 'Volumen total', 'Volumen'],
        'Num. Doc': ['Num. Doc', 'Num Doc', 'Documento', 'Pedido', 'Order'],
        'Fecha Doc': ['Fecha Doc', 'Fecha Doc', 'Fecha', 'Date']
    }
    
    columnas_faltantes = []
    for col_principal, alternativas in columnas_requeridas.items():
        encontrada = False
        for alt in alternativas:
            if alt in df.columns:
                encontrada = True
                break
        if not encontrada:
            columnas_faltantes.append(f"{col_principal} (alternativas: {', '.join(alternativas)})")
    
    if columnas_faltantes:
        st.error("‚ùå Faltan las siguientes columnas requeridas:")
        for col in columnas_faltantes:
            st.write(f"- {col}")
        st.write("**Por favor verifica que tu archivo Excel contenga todas las columnas requeridas.**")
        st.stop()
    
    # Mapear columnas
    art = df['Art√≠culo_LIMPIO']
    unid = pd.to_numeric(safe_col(df, 'Unid. Vend'), errors='coerce').fillna(0)
    monto = pd.to_numeric(safe_col(df, 'Monto venta'), errors='coerce').fillna(0)
    vol = pd.to_numeric(safe_col(df, 'Volumen total (m3)', alt_names=['Volumen total (p3)', 'Volumen total']), errors='coerce').fillna(0) # revisar si ocupa vol_factor
    numdoc = safe_col(df, 'Num. Doc').astype(str)
    fecha = pd.to_datetime(safe_col(df, 'Fecha Doc'), errors='coerce')
    familia = safe_col(df, 'Familia').astype(str).str.strip()
    num_cliente = safe_col(df, 'Num. Cliente').astype(str)
    num_pais = safe_col(df, 'Num. Pa√≠s').astype(str)
    # Opcional: Unidades por caja (si existe en el Excel)
    unidades_por_caja_src = pd.to_numeric(
        safe_col(df, 'Cant x Caja', alt_names=['Cant x Caja','Cant. x Caja','Unid x Caja','Unid. x Caja','Unidades por caja','Unid por caja']),
        errors='coerce'
    )
    
    st.success("‚úÖ Todas las columnas requeridas fueron encontradas y mapeadas correctamente")
    
except Exception as e:
    st.error(f'Error mapeando columnas: {e}')
    st.write("**Posibles causas:**")
    st.write("- Los nombres de las columnas no coinciden exactamente")
    st.write("- Hay caracteres especiales o espacios extra en los nombres")
    st.write("- El formato de los datos no es el esperado")
    st.stop()

base = pd.DataFrame({
    'Articulo': art,
    'Unidades': unid,
    'Monto': monto,
    'Volumen_m3': vol,
    'NumDoc': numdoc,
    'Fecha': fecha,
    'Familia': familia,
    'NumCliente': num_cliente,
    'NumPais': num_pais,
    'Cajas_vendidas': pd.to_numeric(safe_col(df, 'Cajas vend'), errors='coerce').fillna(0),
    'Unidades_por_caja': pd.to_numeric(safe_col(df, 'Cant x caja'), errors='coerce').fillna(0)
}).dropna(subset=['Fecha'])

# Guardar base en session_state para usarlo en PDF y perfiles
st.session_state['base'] = base

if len(base) == 0:
    st.error('No hay registros con fecha valida')
    st.stop()

st.write("Primeras filas de base:")
st.dataframe(base.head())
st.write("Suma Unidades:", base['Unidades'].sum())
st.write("Suma Cajas_vendidas:", base['Cajas_vendidas'].sum())

# -------------------------------
# Calcular Super ABC
# -------------------------------
st.subheader('‚ñ∂Ô∏è Control de secciones')

if st.button('1) Calcular S√∫per ABC'):
    by_item = base.groupby('Articulo').agg(
        popularidad=('NumDoc', 'nunique'),
        cajas=('Cajas_vendidas', 'sum'),
        ventas=('Monto', 'sum'),
        volumen=('Volumen_m3', 'sum'),
        lineas=('NumDoc', 'count'),
        Unidades=('Unidades', 'sum')
    )

    # Rotaci√≥n basada en cajas
    with st.spinner("Calculando rotaci√≥n semanal..."):
        days_range = (base['Fecha'].max() - base['Fecha'].min()).days + 1
        weeks_range = max(1, days_range / 7)
        months_range = max(1, days_range / 30.44)
        years_range = max(1, days_range / 365.25)

        by_item['rotacion_sem'] = by_item['cajas'] / weeks_range
        by_item['rotacion_mes'] = by_item['cajas'] / months_range
        by_item['rotacion_anual'] = by_item['cajas'] / years_range

    # Usar la nueva funci√≥n para generar combinaciones m√∫ltiples
    by_item = generate_super_abc_combinations(
        by_item,
        criterios_seleccionados,
        cortes_abc,
        criterios
    )

    # Mostrar art√≠culos con problemas de clasificaci√≥n
    # Verificar si hay valores NaN en las clasificaciones ABC
    abc_columns = [f'ABC_{criterio}' for criterio in criterios_seleccionados]
    problemas_mask = by_item[abc_columns].isna().any(axis=1) | by_item['Clase_SuperABC'].str.contains('nan')
    problemas = by_item[problemas_mask]
    
    if not problemas.empty:
        st.warning(f"Hay {len(problemas)} art√≠culos sin clase v√°lida. Mira la tabla abajo para revisar:")
        st.dataframe(problemas)
    else:
        st.info("Todos los art√≠culos tienen clase v√°lida.")

    # stats semanales
    base['WeekStart'] = week_floor(base['Fecha'])
    weekly = base.groupby(['Articulo','WeekStart']).agg(units=('Unidades','sum')).reset_index()
    with st.spinner("Calculando estad√≠sticas semanales..."):
        stats = weekly.pivot_table(index='Articulo', values='units', aggfunc=[np.mean, np.std, lambda x: (x==0).mean()])
        stats.columns = ['mean_week','std_week','intermittency']
        by_item = by_item.join(stats, how='left')
        by_item['cv'] = by_item['std_week'] / by_item['mean_week'].replace(0, np.nan)
        by_item['cv'] = by_item['cv'].fillna(np.inf)
        by_item['intermittency'] = by_item['intermittency'].fillna(1.0)

    by_item['Zona_Bodega'] = by_item['Clase_SuperABC'].apply(map_zone)
    by_item['Pol√≠tica_Inv'] = [policy_by_demand(cv, ii) for cv, ii in zip(by_item['cv'], by_item['intermittency'])]
    by_item['FillRate_obj'] = by_item['Zona_Bodega'].apply(target_fill_rate)
    by_item['Frecuencia_Recuento'] = by_item['Zona_Bodega'].apply(cycle_count_freq)

    st.session_state['by_item'] = by_item
    st.session_state['criterios_seleccionados'] = criterios_seleccionados
    st.session_state['crit1_name'] = crit1
    st.session_state['crit2_name'] = crit2
    st.success(f'S√∫per ABC calculado correctamente con {len(criterios_seleccionados)} criterios üéØ')

    # -------------------------------
    # Guardar by_item limpio como perfil
    # -------------------------------
    export_df = by_item.reset_index().copy()
    export_df.columns = [unicodedata.normalize('NFKD', str(c)).encode('ascii','ignore').decode('ascii') for c in export_df.columns]

    if 'FillRate_obj' in export_df.columns:
        export_df['FillRate_obj'] = export_df['FillRate_obj'].astype(str).str.replace('‚Äì','-', regex=False).str.replace('‚Äî','-', regex=False)

    export_df = sanitize_colnames(export_df)
    st.session_state['perfil_by_item_sanitizado'] = export_df

    # --- Comparaci√≥n de art√≠culos √∫nicos para detectar p√©rdidas ---
    articulos_excel = set(df['Art√≠culo'].astype(str).unique())
    articulos_base = set(base['Articulo'].unique())
    articulos_by_item = set(by_item.index)

    faltan_en_base = articulos_excel - articulos_base
    faltan_en_by_item = articulos_base - articulos_by_item

    st.write(f"Total art√≠culos en Excel: {len(articulos_excel)}")
    st.write(f"Total art√≠culos en base (con fecha v√°lida): {len(articulos_base)}")
    st.write(f"Total art√≠culos en by_item (agrupados): {len(articulos_by_item)}")

    if faltan_en_base:
        st.warning(f"Art√≠culos en Excel pero no en base (probablemente por fecha vac√≠a o inv√°lida): {faltan_en_base}")
    if faltan_en_by_item:
        st.warning(f"Art√≠culos en base pero no en by_item (posible error de agrupaci√≥n): {faltan_en_by_item}")
    if not faltan_en_base and not faltan_en_by_item:
        st.info("No se pierden art√≠culos en ninguna etapa del procesamiento.")
# -------------------------------
# Mostrar resumen y perfiles
# -------------------------------
def ira_by_class(clase: str) -> str:
    """
    Determina el IRA (Inventory Record Accuracy) basado en la clase de S√∫per ABC.
    Para m√∫ltiples criterios, se basa en la prioridad de las letras A, B, C.
    """
    # Contar la cantidad de cada letra
    count_a = clase.count('A')
    count_b = clase.count('B')
    count_c = clase.count('C')
    
    # Determinar IRA basado en la prioridad
    if count_a >= 2:  # M√∫ltiples A
        return '> 95%'
    elif count_a == 1 and count_b >= 1:  # Una A y al menos una B
        return '94% - 95%'
    elif count_a == 1:  # Solo una A
        return '92% - 94%'
    elif count_b >= 2:  # M√∫ltiples B
        return '90% - 92%'
    elif count_b == 1:  # Solo una B
        return '88% - 90%'
    elif count_c >= 2:  # M√∫ltiples C
        return '86% - 88%'
    elif count_c == 1:  # Solo una C
        return '84% - 86%'
    else:
        return '< 80%'

if 'by_item' in st.session_state:
    by_item = st.session_state['by_item']

    # -------------------------------
    # Secci√≥n 2: Perfiles de Actividad
    # -------------------------------
    with st.expander("üìà Perfiles de Actividad", expanded=False):
        # -------------------------------
        # Informaci√≥n de criterios
        # -------------------------------
        criterios_usados = st.session_state.get('criterios_seleccionados', [crit1, crit2])
        st.subheader(f'üìã Resumen por categor√≠a - Criterios: {", ".join(criterios_usados)}')

        combinaciones_unicas = by_item['Clase_SuperABC'].nunique()
        st.info(f"Se generaron {combinaciones_unicas} combinaciones √∫nicas de clasificaci√≥n ABC")

        # -------------------------------
        # Rotaciones por unidades y cajas
        # -------------------------------
        days_range = (base['Fecha'].max() - base['Fecha'].min()).days + 1
        weeks_range = max(1, days_range/7)
        months_range = max(1, days_range/30)
        years_range = max(1, days_range/365)

        # Rotaci√≥n unidades
        by_item['Rot_Unidades_Sem'] = by_item['Unidades'] / weeks_range
        by_item['Rot_Unidades_Mes'] = by_item['Unidades'] / months_range
        by_item['Rot_Unidades_A√±o'] = by_item['Unidades'] / years_range

        # Rotaci√≥n cajas
        if 'Cajas_vendidas' in base.columns:
            # Sumar cajas vendidas por art√≠culo
            by_item_cajas = base.groupby('Articulo')['Cajas_vendidas'].sum()
            # Alinear con el √≠ndice de by_item
            by_item['Cajas'] = by_item_cajas.reindex(by_item.index)
            
            # Calcular rotaciones en cajas
            by_item['Rot_Cajas_Sem'] = by_item['Cajas'] / weeks_range
            by_item['Rot_Cajas_Mes'] = by_item['Cajas'] / months_range
            by_item['Rot_Cajas_A√±o'] = by_item['Cajas'] / years_range
        else:
            by_item['Rot_Cajas_Sem'] = np.nan
            by_item['Rot_Cajas_Mes'] = np.nan
            by_item['Rot_Cajas_A√±o'] = np.nan

        # -------------------------------
        # Tabla resumen por Clase_SuperABC
        # -------------------------------
        summary = by_item.groupby('Clase_SuperABC').agg(
            Cantidad=('Clase_SuperABC','count'),
            Zona_Bodega=('Zona_Bodega','first'),
            Politica=('Pol√≠tica_Inv','first'),
            FillRate=('FillRate_obj','first'),
            Ventas=('ventas','sum'),
            Volumen=('volumen','sum'),
            Rot_Unidades_Sem=('Rot_Unidades_Sem','mean'),
            Rot_Unidades_Mes=('Rot_Unidades_Mes','mean'),
            Rot_Unidades_A√±o=('Rot_Unidades_A√±o','mean'),
            Rot_Cajas_Sem=('Rot_Cajas_Sem','mean'),
            Rot_Cajas_Mes=('Rot_Cajas_Mes','mean'),
            Rot_Cajas_A√±o=('Rot_Cajas_A√±o','mean'),
            Popularidad=('popularidad','mean'),
            Frecuencia_Recuento=('Frecuencia_Recuento','first')
        ).reset_index()

        # IRA
        summary['IRA'] = summary['Clase_SuperABC'].apply(ira_by_class)

        # Porcentajes de suma
        summary['% Art√≠culos'] = (100 * summary['Cantidad'] / summary['Cantidad'].sum()).round(2)
        summary['% Ventas'] = (100 * summary['Ventas'] / summary['Ventas'].sum()).round(2)
        summary['% Volumen'] = (100 * summary['Volumen'] / summary['Volumen'].sum()).round(2)

        # Porcentajes de promedio (rotaciones y popularidad)
        for col in ['Rot_Unidades_Sem','Rot_Unidades_Mes','Rot_Unidades_A√±o',
                    'Rot_Cajas_Sem','Rot_Cajas_Mes','Rot_Cajas_A√±o','Popularidad']:
            summary[f'% {col}'] = (100 * summary[col] / summary[col].sum()).round(2)

        # -------------------------------
        # Ordenar y mostrar
        # -------------------------------
        summary = summary.sort_values('Clase_SuperABC')

        cols_display = [
            'Clase_SuperABC','Cantidad','% Art√≠culos','Zona_Bodega','Politica','FillRate','IRA',
            'Frecuencia_Recuento','Ventas','% Ventas',
            'Volumen','% Volumen',
            'Rot_Unidades_Sem','% Rot_Unidades_Sem',
            'Rot_Unidades_Mes','% Rot_Unidades_Mes',
            'Rot_Unidades_A√±o','% Rot_Unidades_A√±o',
            'Rot_Cajas_Sem','% Rot_Cajas_Sem',
            'Rot_Cajas_Mes','% Rot_Cajas_Mes',
            'Rot_Cajas_A√±o','% Rot_Cajas_A√±o',
            'Popularidad','% Popularidad'
        ]

        summary = summary[[c for c in cols_display if c in summary.columns]]  # evita KeyError


        st.dataframe(summary)
        st.session_state['perfil_resumen'] = summary

        # Perfil: lineas por orden (distribucion %)
        st.subheader('% de √≥rdenes por # l√≠neas')
        lines_per_order = base.groupby('NumDoc').agg(lineas=('Articulo','nunique')).reset_index()
        dist_lines = lines_per_order.groupby('lineas').size().rename('conteo').reset_index()
        total_orders = dist_lines['conteo'].sum()
        dist_lines['%_ordenes'] = 100 * dist_lines['conteo']/ (total_orders if total_orders>0 else 1)
        st.dataframe(dist_lines.sort_values('lineas'))
        fig_lines = px.bar(dist_lines.sort_values('lineas'), x='lineas', y='%_ordenes', labels={'lineas':'L√≠neas por orden','%_ordenes':'% de √≥rdenes'})
        st.plotly_chart(fig_lines, use_container_width=True)

        st.session_state['perfil_lineas'] = dist_lines

        # Perfil: cubicaje por orden
        st.subheader('% de √≥rdenes por rango de volumen (m¬≥)')
        cubic_per_order = base.groupby('NumDoc').agg(volumen_total=('Volumen_m3','sum')).reset_index()
        vol_bins = [-1, 0.5, 1, 2, 5, 10, 20, 50, 1e9]  # Ajusta los rangos para m¬≥
        vol_labels = ['‚â§0.5', '0.5-1', '1-2', '2-5', '5-10', '10-20', '20-50', '>50']
        cubic_per_order['vol_bin'] = pd.cut(cubic_per_order['volumen_total'], bins=vol_bins, labels=vol_labels)
        dist_cubic = cubic_per_order.groupby('vol_bin').size().rename('conteo').reset_index()
        total_orders2 = dist_cubic['conteo'].sum()
        dist_cubic['%_ordenes'] = 100 * dist_cubic['conteo']/ (total_orders2 if total_orders2>0 else 1)
        st.dataframe(dist_cubic)
        fig_cubic = px.bar(dist_cubic, x='vol_bin', y='%_ordenes', labels={'vol_bin':'Rango volumen (m¬≥)','%_ordenes':'% de √≥rdenes'})
        st.plotly_chart(fig_cubic, use_container_width=True)

        st.session_state['perfil_cubicaje'] = dist_cubic

        # Distribucion por dia de la semana
        st.subheader('Distribuci√≥n de √≥rdenes por d√≠a de la semana')
        orders_dates = base.groupby('NumDoc').agg(fecha=('Fecha','max')).reset_index()
        orders_dates['dia'] = orders_dates['fecha'].dt.day_name()
        mapping_days = {'Monday':'Lunes','Tuesday':'Martes','Wednesday':'Mi√©rcoles','Thursday':'Jueves','Friday':'Viernes','Saturday':'S√°bado','Sunday':'Domingo'}
        orders_dates['dia'] = orders_dates['dia'].replace(mapping_days)
        day_order = ['Lunes','Martes','Mi√©rcoles','Jueves','Viernes','S√°bado','Domingo']
        dist_days = orders_dates.groupby('dia').size().reindex(day_order).fillna(0).astype(int).rename('conteo').reset_index()
        dist_days['%_ordenes'] = 100 * dist_days['conteo'] / (dist_days['conteo'].sum() if dist_days['conteo'].sum()>0 else 1)
        st.dataframe(dist_days)
        fig_days = px.bar(dist_days, x='dia', y='%_ordenes', labels={'dia':'D√≠a','%_ordenes':'% de √≥rdenes'})
        st.plotly_chart(fig_days, use_container_width=True)

        st.session_state['perfil_dias'] = dist_days

        # Preparar datos
        lv = base.groupby('NumDoc').agg(
            lineas=('Articulo','nunique'),
            volumen_total=('Volumen_m3','sum')
        ).reset_index()

        # Par√°metro: volumen de una tarima completa (ajusta seg√∫n tu operaci√≥n)
        VOLUMEN_TARIMA = st.session_state.get('vol_tarima', 42.38)

        # % de carga unitaria respecto a una tarima
        lv['%_carga_unidad'] = 100 * lv['volumen_total'] / VOLUMEN_TARIMA
        lv['%_carga_unidad'] = lv['%_carga_unidad'].clip(upper=100)  # m√°ximo 100%

        # Bins para % de carga unitaria
        carga_bins = list(range(0, 105, 5))
        carga_labels = [f'{i}-{i+5}%' for i in range(0, 100, 5)]
        lv['r_carga'] = pd.cut(lv['%_carga_unidad'], bins=carga_bins, labels=carga_labels, right=True, include_lowest=True)
        
        # Distribuci√≥n cruzada: % l√≠neas de pedido vs % carga unitaria
        dist_incremento = lv.groupby(['r_carga']).agg(
            pedidos=('NumDoc', 'count'),
            lineas_prom=('lineas', 'mean')
        ).reset_index()
        dist_incremento['%_lineas_pedido'] = 100 * dist_incremento['pedidos'] / dist_incremento['pedidos'].sum()

        st.subheader('Distribuci√≥n por incremento de pedidos (% carga unitaria vs % de l√≠neas de pedido)')
        st.dataframe(dist_incremento.rename(columns={'%_lineas_pedido': '% de l√≠neas de pedido'}))
        fig_incremento = px.bar(
            dist_incremento,
            x='r_carga',
            y='%_lineas_pedido',
            labels={'r_carga': '% de carga unitaria (tarima)', '%_lineas_pedido': '% de l√≠neas de pedido'},
            title='% de l√≠neas de pedido por % de carga unitaria'
        )
        st.plotly_chart(fig_incremento, use_container_width=True)

        st.session_state['perfil_carga'] = dist_incremento

        # -------------------------------
        # Tabla cruzada l√≠neas x volumen por pedido
        # -------------------------------
        st.subheader('Tabla cruzada: L√≠neas por pedido vs pies¬≥ por pedido')

        # Categor√≠as
        line_labels = ['1','2-5','6-9','10+']
        lv['r_lineas'] = pd.cut(lv['lineas'], bins=[0,1,6,10,1e9], labels=line_labels, right=True, include_lowest=True)

        vol_labels = ['‚â§0.5', '0.5-1', '1-2', '2-5', '5-10', '10-20', '20-50', '>50']
        lv['r_vol'] = pd.cut(lv['volumen_total'], bins=[-1, 0.5, 1, 2, 5, 10, 20, 50, 1e9], labels=vol_labels, right=True, include_lowest=True)

        # Desglose de pedidos por rango de l√≠neas (incluyendo volumen)
        st.subheader('Desglose de pedidos por rango de l√≠neas')
        for rango in line_labels:
            pedidos_rango = lv[lv['r_lineas'] == rango][['NumDoc', 'lineas', 'volumen_total', 'r_vol']]
            st.markdown(f"**Rango {rango}: {len(pedidos_rango)} pedidos**")
            st.dataframe(pedidos_rango.reset_index(drop=True))

        # Conteo de pedidos por l√≠nea y volumen
        ct_counts = pd.crosstab(lv['r_lineas'], lv['r_vol'], dropna=False)

        # Totales de l√≠nea y % pedidos por l√≠nea
        ct_counts['Totales'] = ct_counts.sum(axis=1)
        ct_counts['% pedidos'] = (ct_counts['Totales'] / ct_counts['Totales'].sum() * 100).round(2)

        # üîπ Total de l√≠neas (sumando l√≠neas, no volumen)
        pivot_lines = pd.pivot_table(
            lv,
            index='r_lineas',
            values='lineas',
            aggfunc='sum',
            fill_value=0
        )
        total_lines_global = pivot_lines['lineas'].sum()
        pivot_lines['% linea'] = (pivot_lines['lineas'] / (total_lines_global if total_lines_global>0 else 1) * 100).round(2)

        # Crear tabla final con columnas en orden deseado
        table_final = pd.DataFrame(index=line_labels, columns=vol_labels + ['Totales','% pedidos','Total_Linea','% linea'])
        table_final[vol_labels] = ct_counts[vol_labels]
        table_final['Totales'] = ct_counts['Totales']
        table_final['% pedidos'] = ct_counts['% pedidos']
        table_final['Total_Linea'] = pivot_lines['lineas']
        table_final['% linea'] = pivot_lines['% linea']

        # Fila Totales
        totales_row = table_final[vol_labels].sum()
        totales_row['Totales'] = table_final['Totales'].sum()
        totales_row['% pedidos'] = 100
        totales_row['Total_Linea'] = table_final['Total_Linea'].sum()
        totales_row['% linea'] = 100
        table_final.loc['Totales'] = totales_row

        # ‚úÖ Fila % pedidos (por columna, ahora bien calculada)
        total_pedidos_global = table_final.loc[line_labels, vol_labels].values.sum()
        pct_pedidos_row = (table_final.loc[line_labels, vol_labels].sum() / total_pedidos_global * 100).round(2)

        pct_pedidos_row['Totales'] = 100
        pct_pedidos_row['% pedidos'] = np.nan
        pct_pedidos_row['Total_Linea'] = np.nan
        pct_pedidos_row['% linea'] = np.nan
        table_final.loc['% pedidos'] = pct_pedidos_row

        # Fila Espacio total (volumen)
        espacio_total_row = lv.groupby('r_vol')['volumen_total'].sum()
        espacio_total_row = espacio_total_row.reindex(vol_labels, fill_value=0)
        espacio_total_row['Totales'] = espacio_total_row.sum()
        espacio_total_row['% pedidos'] = np.nan
        espacio_total_row['Total_Linea'] = np.nan       # No calcular para espacio total
        espacio_total_row['% linea'] = np.nan           # No calcular para espacio total
        table_final.loc['Espacio total'] = espacio_total_row

        # Renombrar √≠ndice
        table_final.index.name = 'L√≠neas por orden / Volumen por orden'

        # Mostrar tabla
        st.dataframe(table_final.round(2))

        import plotly.express as px
        import plotly.graph_objects as go

        # -------------------------------
        # 1Ô∏è‚É£ Barras apiladas interactivas (l√≠neas por volumen)
        # -------------------------------
        table_plot = table_final.loc[line_labels, vol_labels].astype(float)
        table_plot_reset = table_plot.reset_index().rename(columns={'index':'Rango de l√≠neas'})

        fig_barras = px.bar(
            table_plot_reset,
            x='L√≠neas por orden / Volumen por orden',
            y=vol_labels,
            labels={'value':'Cantidad de pedidos','Rango de l√≠neas':'L√≠neas por orden'},
            title='Distribuci√≥n de pedidos por l√≠neas y volumen (interactivo)',
            text_auto=True
        )
        st.plotly_chart(fig_barras, use_container_width=True)

        # -------------------------------
        # 2Ô∏è‚É£ Gr√°fico de pastel interactivo (por volumen total)
        # -------------------------------
        pie_data = table_final.loc['Totales', vol_labels].astype(float)
        fig_pastel = px.pie(
            names=pie_data.index,
            values=pie_data.values,
            title='Distribuci√≥n de pedidos por volumen total',
            hole=0.3  # donut
        )
        st.plotly_chart(fig_pastel, use_container_width=True)

        # -------------------------------
        # 3Ô∏è‚É£ Heatmap interactivo (l√≠neas x volumen)
        # -------------------------------
        heatmap_data = table_final.loc[line_labels, vol_labels].astype(float)

        fig_heatmap = go.Figure(
            data=go.Heatmap(
                z=heatmap_data.values,
                x=heatmap_data.columns,
                y=heatmap_data.index,
                colorscale='YlGnBu',
                text=heatmap_data.values,
                texttemplate="%{text}",
                colorbar=dict(title="Cantidad de pedidos")
            )
        )
        fig_heatmap.update_layout(
            title='Heatmap: Pedidos por l√≠neas y volumen',
            xaxis_title='Volumen por orden (m¬≥)',
            yaxis_title='L√≠neas por orden'
        )
        st.plotly_chart(fig_heatmap, use_container_width=True)


        st.session_state['perfil_cruzado'] = table_final

        # Pareto popularidad
        st.subheader('Pareto de popularidad de √≠tems (picks acumulados)')
        pareto = by_item.sort_values('popularidad', ascending=False)[['popularidad']].copy()
        pareto['cum_picks'] = pareto['popularidad'].cumsum()
        total_picks = pareto['popularidad'].sum()
        pareto['cum_pct_picks'] = 100 * pareto['cum_picks'] / (total_picks if total_picks>0 else 1)
        pareto['sku_rank'] = np.arange(1, len(pareto)+1)
        pareto['pct_sku'] = 100 * pareto['sku_rank'] / len(pareto)
        st.dataframe(pareto.head(20))
        fig_pareto = px.line(pareto, x='pct_sku', y='cum_pct_picks', labels={'pct_sku':'% de SKU (acumulado)','cum_pct_picks':'% de picks (acumulado)'}, title='Curva de Pareto ‚Äì Popularidad')
        st.plotly_chart(fig_pareto, use_container_width=True)

        st.session_state['perfil_pareto'] = pareto


    # -------------------------------
    # Datos generales
    # -------------------------------
    file_name = st.session_state.get('file_name', uploaded_file.name if uploaded_file else 'Archivo no registrado')
    sheet_used = st.session_state.get('sheet_name', sheet_name or 'Hoja no registrada')
    vol_units = st.session_state.get('vol_units', unit_vol)
    criterios_usados = st.session_state.get('criterios_seleccionados', [crit1, crit2])
    cortes_abc = st.session_state.get('cortes_abc', {})
    
    # Para compatibilidad con c√≥digo existente
    crit1 = criterios_usados[0] if criterios_usados else 'Popularidad'
    crit2 = criterios_usados[1] if len(criterios_usados) > 1 else criterios_usados[0] if criterios_usados else 'Ventas'
    
    # Obtener cortes de la nueva estructura
    A_cut_1 = cortes_abc.get(crit1, {}).get('A', 0.8) if cortes_abc else 0.8
    B_cut_1 = cortes_abc.get(crit1, {}).get('B', 0.95) if cortes_abc else 0.95
    A_cut_2 = cortes_abc.get(crit2, {}).get('A', 0.8) if cortes_abc else 0.8
    B_cut_2 = cortes_abc.get(crit2, {}).get('B', 0.95) if cortes_abc else 0.95

    # -------------------------------
    # Crear hoja Portada
    # -------------------------------
    # Crear datos de portada din√°micamente
    portada_campos = ['Documento le√≠do', 'Hoja utilizada', 'Unidades de volumen', 'Criterios utilizados']
    portada_valores = [file_name, sheet_used, vol_units, ', '.join(criterios_usados)]
    
    # Agregar cortes para cada criterio
    for criterio in criterios_usados:
        if criterio in cortes_abc:
            portada_campos.extend([f'Corte A ({criterio})', f'Corte B ({criterio})'])
            portada_valores.extend([cortes_abc[criterio]['A'], cortes_abc[criterio]['B']])
    
    portada_data = {
        'Campo': portada_campos,
        'Valor': portada_valores
    }

    df_portada = pd.DataFrame(portada_data)
        
if 'by_item' in st.session_state:
    by_item = st.session_state['by_item']
    base = st.session_state['base']

    from statsmodels.tsa.seasonal import seasonal_decompose
    import plotly.graph_objects as go

    with st.expander("üîÆ An√°lisis de Demanda por Art√≠culo", expanded=False):
        st.header('üîÆ An√°lisis de Demanda por Art√≠culo')

        with st.expander("‚ÑπÔ∏è ¬øQu√© estudia esta secci√≥n?", expanded=False):
            st.markdown("""
            Esta secci√≥n est√° dise√±ada para **analizar la demanda hist√≥rica de un art√≠culo espec√≠fico**, permitiendo comprender c√≥mo ha evolucionado a lo largo del tiempo y detectar patrones de comportamiento relevantes.  

    **Objetivos principales:**
    1. **Visualizar la serie hist√≥rica de demanda:**  
       - Observar la evoluci√≥n de ventas o unidades despachadas.  
       - Analizar con frecuencia semanal o mensual seg√∫n la granularidad de los datos.

    2. **Identificar la tendencia de la demanda:**  
       - Mediante suavizado (promedio m√≥vil), se destaca la tendencia subyacente.  
       - Permite detectar si la demanda est√° **creciendo, decreciendo o se mantiene estable**.

    3. **Detectar estacionalidad o patrones repetitivos:**  
       - Analiza la autocorrelaci√≥n de la serie para identificar ciclos de demanda.  
       - Los rezagos significativos indican posibles patrones estacionales.

    4. **Interpretaci√≥n simplificada con pocos datos:**  
       - Para series cortas o irregulares, se ofrece un an√°lisis alternativo con suavizado y autocorrelaci√≥n parcial.
            """)

        with st.expander("‚ÑπÔ∏è ¬øQu√© m√©tricas se utilizan y c√≥mo interpretarlas?", expanded=False):
            st.markdown("""
             **M√©tricas y su interpretaci√≥n:**
    
    1. **Serie hist√≥rica:**  
       - Gr√°fico de la demanda a lo largo del tiempo.  
       - Permite observar cambios, picos o ca√≠das en las ventas.

    2. **Tendencia suavizada:**  
       - Promedio m√≥vil de 3 per√≠odos (o ajustable).  
       - Indica la direcci√≥n general de la demanda (creciente, decreciente o estable).

    3. **Autocorrelaci√≥n (ACF):**  
       - Mide la correlaci√≥n de la demanda con sus propios rezagos.  
       - **Interpretaci√≥n de rezagos:**  
         - Un rezago de 1 mes/semana indica c√≥mo la demanda actual se relaciona con la del per√≠odo anterior.  
         - Rezagos significativos m√°s largos (2, 3, ‚Ä¶) muestran patrones repetitivos o estacionales.  
         - Por ejemplo, un rezago significativo de 12 meses sugiere que la demanda se repite anualmente en ese mes.

    4. **Interpretaci√≥n resumida:**  
       - Con base en la tendencia y la ACF, se puede anticipar estacionalidad y direcci√≥n de la demanda.  
       - √ötil para planificaci√≥n de inventarios, producci√≥n y estrategias de abastecimiento.
            """)
        # Selecci√≥n de nivel de an√°lisis
        nivel_analisis = st.selectbox('Nivel de an√°lisis', ['Articulo', 'Familia'], index=0)

        # Selecci√≥n de art√≠culo o familia
        if nivel_analisis == 'Articulo':
            opciones = sorted(base['Articulo'].unique())
            seleccion = st.selectbox('Selecciona Art√≠culo para analizar', opciones, key='analizar_articulo')
            columna_estudio = 'Unidades' if st.selectbox('Unidad a pronosticar', ['Unidades vendidas', 'Cajas vendidas'], index=0) == 'Unidades vendidas' else 'Cajas_vendidas'
        else:
            opciones = sorted(base['Familia'].unique())
            seleccion = st.selectbox('Selecciona Familia para analizar', opciones, key='analizar_familia')
            columna_estudio = 'Unidades' if st.selectbox('Unidad a pronosticar', ['Unidades vendidas', 'Cajas vendidas'], index=0) == 'Unidades vendidas' else 'Cajas_vendidas'

        # Filtrar datos
        if nivel_analisis not in base.columns:
            st.error(f"El nivel de an√°lisis '{nivel_analisis}' no existe en las columnas de base.")
            st.write("Columnas disponibles:", base.columns)
            st.stop()

        base_filtrada = base[base[nivel_analisis] == seleccion].copy()

        if base_filtrada.empty:
            st.warning(f"No hay registros para {nivel_analisis.lower()} seleccionado.")
            st.stop()

        # Serie hist√≥rica
        resample_freq = 'MS' if st.selectbox('Frecuencia de estudio', ['Mensual', 'Semanal'], index=0) == 'Mensual' else 'W-MON'
        ts = base_filtrada.groupby('Fecha')[columna_estudio].sum().resample(resample_freq).sum().fillna(0)
        ts.index.freq = resample_freq
        st.subheader("Serie hist√≥rica")
        st.line_chart(ts)

        # --- Panel interactivo para par√°metros de an√°lisis ---
        st.subheader("‚öôÔ∏è Configuraci√≥n del an√°lisis")

        modelo_descomp = st.radio(
            "Modelo de descomposici√≥n",
            options=["Aditivo", "Multiplicativo"],
            index=0,
            horizontal=True
        )

        periodo_default = 12 if resample_freq == "MS" else 52
        periodo_estacionalidad = st.number_input(
            "Periodo de estacionalidad (ej. 12 meses, 52 semanas)",
            min_value=2, max_value=200, value=periodo_default, step=1
        )

        umbral_estacionalidad = st.slider(
            "Sensibilidad para considerar estacionalidad significativa",
            min_value=0.1, max_value=1.0, value=0.3, step=0.05
        )

        # --- An√°lisis de tendencia y estacionalidad ---
        st.subheader("üìä Tendencia y Estacionalidad")

        # Validar si hay suficientes datos
        if len(ts) >= 2 * periodo_estacionalidad:
            try:
                decomposition = seasonal_decompose(
                    ts,
                    model="additive" if modelo_descomp == "Aditivo" else "multiplicative",
                    period=periodo_estacionalidad
                )

                # Graficar resultados de la descomposici√≥n
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=decomposition.trend.index, y=decomposition.trend,
                                        mode='lines', name='Tendencia'))
                fig.add_trace(go.Scatter(x=decomposition.seasonal.index, y=decomposition.seasonal,
                                        mode='lines', name='Estacionalidad'))
                fig.add_trace(go.Scatter(x=decomposition.resid.index, y=decomposition.resid,
                                        mode='lines', name='Residuales'))

                fig.update_layout(
                    title="Descomposici√≥n de la serie",
                    xaxis_title="Fecha", yaxis_title="Demanda",
                    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
                )
                st.plotly_chart(fig, use_container_width=True)

                # Interpretaci√≥n autom√°tica
                st.markdown("### üîç Interpretaci√≥n autom√°tica")
                if decomposition.trend.notna().sum() > 0:
                    tendencia = decomposition.trend.dropna()
                    if tendencia.iloc[-1] > tendencia.iloc[0]:
                        st.success("üîº La demanda muestra una **tendencia creciente**.")
                    elif tendencia.iloc[-1] < tendencia.iloc[0]:
                        st.error("üîΩ La demanda muestra una **tendencia decreciente**.")
                    else:
                        st.info("‚è∏ La demanda se mantiene relativamente estable.")

                seasonal_strength = decomposition.seasonal.std() / ts.std() if ts.std() > 0 else 0
                if seasonal_strength > umbral_estacionalidad:
                    st.success("üìà Se observa una **estacionalidad significativa** (patrones recurrentes).")
                else:
                    st.info("üìâ No se detecta una estacionalidad marcada en la serie.")

            except Exception as e:
                st.warning("‚ö†Ô∏è Ocurri√≥ un problema en la descomposici√≥n.")
                st.error(e)

        else:
            # --- An√°lisis alternativo si no hay suficientes datos ---
            st.warning(f"""
            ‚ö†Ô∏è La serie solo tiene {len(ts)} observaciones, 
            pero se requieren al menos {2*periodo_estacionalidad} para descomponer.
            Se mostrar√° un an√°lisis simplificado.
            """)

            # Rolling mean (suavizado de tendencia)
            rolling = ts.rolling(window=3, center=True).mean()
            st.line_chart(pd.DataFrame({
                "Demanda": ts, 
                "Tendencia suavizada (3 periodos)": rolling
            }))

            # Autocorrelaci√≥n (ACF)
            from statsmodels.tsa.stattools import acf

            # Definir rango m√°ximo de rezagos seg√∫n frecuencia
            default_lag = 10
            if resample_freq == "MS":
                max_lag_default = min(12, len(ts)-1)  # hasta 12 meses
            else:  # Semanal
                max_lag_default = min(52, len(ts)-1)  # hasta 52 semanas

            # Slider interactivo para seleccionar n√∫mero de rezagos
            max_lag = st.slider(
                "N√∫mero m√°ximo de rezagos para ACF",
                min_value=5,
                max_value=max_lag_default,
                value=default_lag
            )

            lag_acf = acf(ts, nlags=max_lag)

            acf_df = pd.DataFrame({
                "Rezago": list(range(len(lag_acf))),
                "Autocorrelaci√≥n": lag_acf
            })
            st.bar_chart(acf_df.set_index("Rezago"))

            # Interpretaci√≥n simple de la tendencia
            st.markdown("### üîç Interpretaci√≥n simplificada")
            if rolling.dropna().iloc[-1] > rolling.dropna().iloc[0]:
                st.success("üîº La demanda parece **creciente** seg√∫n el suavizado.")
            elif rolling.dropna().iloc[-1] < rolling.dropna().iloc[0]:
                st.error("üîΩ La demanda parece **decreciente** seg√∫n el suavizado.")
            else:
                st.info("‚è∏ La demanda parece **estable** en el tiempo analizado.")

            # Identificar rezagos significativos en ACF
            significativos = [lag for lag, val in enumerate(lag_acf[1:], start=1) if abs(val) > 0.3]

            if significativos:
                if resample_freq == "MS":
                    detalle = ", ".join([f"{lag} mes(es)" for lag in significativos])
                else:  # Semanal
                    detalle = ", ".join([f"{lag} semana(s)" for lag in significativos])

                st.success(f"üìà Se detectan correlaciones en los rezagos: **{detalle}**. "
                        "Esto sugiere una posible **estacionalidad** en esos intervalos.")
            else:
                st.info("üìâ No se observa evidencia fuerte de estacionalidad en los rezagos analizados.")
                
    with st.expander("üìä An√°lisis por Familia", expanded=False):
        st.header("üìä An√°lisis por Familia")
        st.markdown("Analiza la demanda, rotaciones y ventas agrupadas por familia de productos.")

        # Agrupaci√≥n por Familia
        familia_agg = base.groupby('Familia').agg(
            Ventas=('Monto', 'sum'),
            Unidades=('Unidades', 'sum'),
            Cajas=('Cajas_vendidas', 'sum'),
            Volumen=('Volumen_m3', 'sum'),
            Rotacion_Sem=('Cajas_vendidas', lambda x: x.sum() / weeks_range),
            Rotacion_Mes=('Cajas_vendidas', lambda x: x.sum() / months_range),
            Rotacion_Anual=('Cajas_vendidas', lambda x: x.sum() / years_range)
        ).reset_index()

        # Calcular porcentajes
        total_ventas = familia_agg['Ventas'].sum()
        familia_agg['% Ventas'] = (familia_agg['Ventas'] / total_ventas * 100).round(2)

        # Mostrar tabla
        st.dataframe(familia_agg)

        # Gr√°fico de contribuci√≥n por familia
        fig_familia = px.pie(
            familia_agg,
            values='% Ventas',
            names='Familia',
            title="Contribuci√≥n de Ventas por Familia"
        )
        st.plotly_chart(fig_familia, use_container_width=True)
    
    with st.expander("üìä An√°lisis por Pa√≠s", expanded=False):
        st.header("üìä An√°lisis por Pa√≠s")
        st.markdown("Analiza la demanda y ventas agrupadas por pa√≠s (manteniendo anonimato).")

        # Crear columna TipoPais
        
        base['TipoPais'] = base['NumPais'].apply(lambda x: 'Nacional' if x == '01' else 'Exportaci√≥n')

        # Agrupaci√≥n por pa√≠s
        pais_agg = base.groupby('NumPais').agg(
            Ventas=('Monto', 'sum'),
            Unidades=('Unidades', 'sum'),
            Cajas=('Cajas_vendidas', 'sum'),
            Volumen=('Volumen_m3', 'sum')
        ).reset_index()

        # Calcular porcentajes
        total_ventas = pais_agg['Ventas'].sum()
        pais_agg['% Ventas'] = (pais_agg['Ventas'] / total_ventas * 100).round(2)

        # Mostrar tabla
        st.dataframe(pais_agg)

        # Gr√°fico de contribuci√≥n por pa√≠s
        fig_pais = px.pie(
            pais_agg,
            names='NumPais',
            values='% Ventas',
            title="Contribuci√≥n de Ventas por Pa√≠s",
        )
        st.plotly_chart(fig_pais, use_container_width=True)

               
    with st.expander("üìä An√°lisis de Contribuci√≥n por Categor√≠as ABC", expanded=False):
        st.header('üìä An√°lisis de Contribuci√≥n por Categor√≠as ABC')
        st.markdown("""
        Esta secci√≥n proporciona un an√°lisis detallado de la contribuci√≥n de cada categor√≠a ABC 
        al total de ventas, volumen, popularidad, unidades y cajas, √∫til para entender el impacto de cada categor√≠a.
        """)

        # --- Agrupar y calcular m√©tricas ---
        contribucion_categorias = by_item.groupby('Clase_SuperABC').agg({
            'ventas': 'sum',
            'volumen': 'sum',
            'popularidad': 'sum',
            'Unidades': 'sum',
            'Cajas': 'sum',
            'Rot_Unidades_Sem': 'mean',
            'Rot_Unidades_Mes': 'mean',
            'Rot_Unidades_A√±o': 'mean',
            'Rot_Cajas_Sem': 'mean',
            'Rot_Cajas_Mes': 'mean',
            'Rot_Cajas_A√±o': 'mean'
        }).round(2)

        # Conteo de art√≠culos
        contribucion_categorias['Cantidad_Articulos'] = by_item.groupby('Clase_SuperABC').size()

        # Totales para porcentajes
        total_ventas = contribucion_categorias['ventas'].sum()
        total_volumen = contribucion_categorias['volumen'].sum()
        total_popularidad = contribucion_categorias['popularidad'].sum()
        total_unidades = contribucion_categorias['Unidades'].sum()
        total_cajas = contribucion_categorias['Cajas'].sum()
        total_articulos = contribucion_categorias['Cantidad_Articulos'].sum()

        # Calcular porcentajes
        contribucion_categorias['% Ventas'] = (contribucion_categorias['ventas']/total_ventas*100).round(2)
        contribucion_categorias['% Volumen'] = (contribucion_categorias['volumen']/total_volumen*100).round(2)
        contribucion_categorias['% Popularidad'] = (contribucion_categorias['popularidad']/total_popularidad*100).round(2)
        contribucion_categorias['% Unidades'] = (contribucion_categorias['Unidades']/total_unidades*100).round(2)
        contribucion_categorias['% Cajas'] = (contribucion_categorias['Cajas']/total_cajas*100).round(2)
        contribucion_categorias['% Art√≠culos'] = (contribucion_categorias['Cantidad_Articulos']/total_articulos*100).round(2)

        # Renombrar columnas
        contribucion_categorias.rename(columns={
            'ventas':'Ventas',
            'volumen':'Volumen',
            'popularidad':'Popularidad',
            'Unidades':'Unidades',
            'Cajas':'Cajas',
            'Rot_Unidades_Sem':'Rotaci√≥n Semanal (uds)',
            'Rot_Unidades_Mes':'Rotaci√≥n Mensual (uds)',
            'Rot_Unidades_A√±o':'Rotaci√≥n Anual (uds)',
            'Rot_Cajas_Sem':'Rotaci√≥n Semanal (cajas)',
            'Rot_Cajas_Mes':'Rotaci√≥n Mensual (cajas)',
            'Rot_Cajas_A√±o':'Rotaci√≥n Anual (cajas)'
        }, inplace=True)

        st.subheader("üìà Tabla de Contribuci√≥n por Categor√≠as")
        st.dataframe(contribucion_categorias)

        # --- Gr√°ficos de contribuci√≥n (ventas y volumen) ---
        import plotly.express as px
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ü•ß Contribuci√≥n de Ventas por Categor√≠a")
            fig_ventas = px.pie(
                contribucion_categorias,
                values='% Ventas',
                names=contribucion_categorias.index,
                title="Distribuci√≥n de Ventas por Categor√≠a ABC"
            )
            st.plotly_chart(fig_ventas, use_container_width=True)

        with col2:
            st.subheader("ü•ß Contribuci√≥n de Volumen por Categor√≠a")
            fig_volumen = px.pie(
                contribucion_categorias,
                values='% Volumen',
                names=contribucion_categorias.index,
                title="Distribuci√≥n de Volumen por Categor√≠a ABC"
            )
            st.plotly_chart(fig_volumen, use_container_width=True)

        # --- Gr√°ficos de rotaci√≥n ---
        st.subheader("ü•ß Distribuci√≥n de Rotaci√≥n por Categor√≠a")
        periodos = ['Semanal','Mensual','Anual']
        tipos = ['uds','cajas']

        for tipo in tipos:
            for periodo in periodos:
                col_name = f'Rotaci√≥n {periodo} ({tipo})'
                if col_name in contribucion_categorias.columns:
                    fig = px.pie(
                        contribucion_categorias,
                        values=col_name,
                        names=contribucion_categorias.index,
                        title=f"Distribuci√≥n de Rotaci√≥n {periodo} ({tipo})"
                    )
                    st.plotly_chart(fig, use_container_width=True)

        # --- Gr√°fico de barras comparativo ---
        st.subheader("üìä Comparaci√≥n de Contribuciones por M√©tricas")
        contrib_data_melted = contribucion_categorias[[
            '% Ventas','% Volumen','% Popularidad','% Unidades','% Cajas'
        ]].reset_index().melt(id_vars=['Clase_SuperABC'], 
                            var_name='M√©trica', value_name='Porcentaje')

        fig_barras = px.bar(
            contrib_data_melted,
            x='Clase_SuperABC',
            y='Porcentaje',
            color='M√©trica',
            barmode='group',
            title="Comparaci√≥n de Contribuciones por Categor√≠a ABC"
        )
        fig_barras.update_layout(xaxis_title="Categor√≠a ABC", yaxis_title="Porcentaje (%)")
        st.plotly_chart(fig_barras, use_container_width=True)

        # --- Insights autom√°ticos ---
        st.subheader("üí° Insights Autom√°ticos")
        insights = []

        # Ventas y concentraci√≥n
        top_categoria = contribucion_categorias['% Ventas'].idxmax()
        top_ventas = contribucion_categorias.loc[top_categoria,'% Ventas']
        insights.append(f"üéØ **Categor√≠a l√≠der:** {top_categoria} representa {top_ventas}% de las ventas totales")

        categorias_80 = contribucion_categorias[contribucion_categorias['% Ventas'].cumsum() <= 80]
        insights.append(f"üìä **Concentraci√≥n 80/20:** {len(categorias_80)} categor√≠as concentran 80% de las ventas")

        categorias_bajas = contribucion_categorias[contribucion_categorias['% Ventas'] < 5]
        if len(categorias_bajas) > 0:
            insights.append(f"üìâ **Baja contribuci√≥n:** {len(categorias_bajas)} categor√≠as <5% de ventas")
            insights.append(f"üîç **Revisar categor√≠as:** {', '.join(categorias_bajas.index)}")

        # Top rotaciones
        for tipo in tipos:
            for periodo in periodos:
                col_name = f'Rotaci√≥n {periodo} ({tipo})'
                if col_name in contribucion_categorias.columns:
                    top_rot = contribucion_categorias.sort_values(col_name, ascending=False).head(3)
                    insights.append(f"‚ö° **Mayor rotaci√≥n {periodo} ({tipo}):** {', '.join(top_rot.index)}")

        for insight in insights:
            st.info(insight)


    with st.expander("üè≠ Sugerencias de Distribuci√≥n de Bodega", expanded=False):
        # -------------------------------
        # Sugerencias de Distribuci√≥n de Bodega
        # -------------------------------
        st.header('üè≠ Sugerencias de Distribuci√≥n de Bodega')
        
        st.markdown("""
        Esta secci√≥n permite calcular la distribuci√≥n √≥ptima de racks en la bodega bas√°ndose en el an√°lisis ABC 
        y las dimensiones f√≠sicas de pallets, bays, racks y la bodega. El sistema calcula autom√°ticamente 
        la capacidad de almacenamiento y sugiere la distribuci√≥n de racks por categor√≠a ABC.
        
        **üí° Nota importante:** El porcentaje de almacenamiento representa qu√© parte del √°rea total de la bodega 
        se destinar√° espec√≠ficamente para almacenamiento (el resto se usa para pasillos, oficinas, √°reas de 
        recepci√≥n/despacho, etc.). Un valor t√≠pico es entre 60-80%.
        """)
        
        # Verificar que tenemos datos de S√∫per ABC
        if 'Clase_SuperABC' not in by_item.columns:
            st.warning("‚ö†Ô∏è Primero debes calcular el S√∫per ABC para usar esta funcionalidad.")
        else:
            # Crear columnas para organizar los par√°metros
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("üì¶ Dimensiones de Pallets (metros)")
                largo_pallet = st.number_input("Largo del pallet (m)", min_value=0.1, value=1.2, step=0.01)
                ancho_pallet = st.number_input("Ancho del pallet (m)", min_value=0.1, value=1.0, step=0.01)
                alto_pallet = st.number_input("Alto del pallet (m)", min_value=0.1, value=1.5, step=0.01)
                factor_llenado = st.number_input("Factor de llenado (%)", min_value=0.1, max_value=100.0, value=85.0, step=1.0) / 100.0

                st.subheader("üèóÔ∏è Dimensiones de Bay (metros)")
                largo_bay = st.number_input("Largo de Bay (m)", min_value=0.1, value=2.5, step=0.01)
                profundidad_bay = st.number_input("Profundidad del Bay (m)", min_value=0.1, value=1.2, step=0.01)
                niveles = st.number_input("Niveles", min_value=1, value=5, step=1)
                
            with col2:
                st.subheader("üè¢ Informaci√≥n de Rack")
                bays_por_rack = st.number_input("Bays por rack", min_value=1, value=10, step=1)

                st.subheader("üè≠ Dimensiones de Bodega (metros)")
                ancho_bodega = st.number_input("Ancho de bodega (m)", min_value=0.1, value=30.0, step=0.01)
                largo_bodega = st.number_input("Largo de bodega (m)", min_value=0.1, value=60.0, step=0.01)
                porcentaje_almacenamiento = st.number_input("Porcentaje para almacenamiento (%)", min_value=1.0, max_value=100.0, value=70.0, step=1.0) / 100.0
                ancho_pasillo = st.number_input("Ancho de pasillo (m)", min_value=0.1, value=3.6, step=0.01)
            
            # Bot√≥n para calcular distribuci√≥n
            if st.button("üßÆ Calcular Distribuci√≥n de Bodega"):
                
                # -------------------------------
                # C√°lculos de Capacidad en metros
                # -------------------------------
                st.subheader("üìä C√°lculos de Capacidad")

                # Volumen de pallet (m¬≥)
                volumen_pallet = largo_pallet * ancho_pallet * alto_pallet * factor_llenado

                # Pallets por nivel
                pallets_por_nivel = int((largo_bay // largo_pallet) * (profundidad_bay // ancho_pallet))

                # √Årea de bay (m¬≤)
                area_bay = largo_bay * profundidad_bay

                # √Årea de rack (m¬≤)
                area_rack = area_bay * bays_por_rack

                # √Årea de bodega total (m¬≤)
                area_bodega_total = ancho_bodega * largo_bodega

                # √Årea efectiva de almacenamiento (m¬≤)
                area_efectiva_almacenamiento = area_bodega_total * porcentaje_almacenamiento

                # √Årea de pasillo (m¬≤)
                area_pasillo = largo_bay * ancho_pasillo * bays_por_rack

                # √Årea de rack + pasillo (m¬≤)
                area_rack_pasillo = area_rack + area_pasillo

                # Pallets por rack
                pallets_por_rack = pallets_por_nivel * niveles * bays_por_rack
                
                
                # Mostrar c√°lculos
                calculos_df = pd.DataFrame({
                    'M√©trica': [
                        'Volumen de pallet (m¬≥)',
                        'Pallets por nivel',
                        '√Årea de bay (m¬≤)',
                        '√Årea de rack (m¬≤)',
                        '√Årea de bodega (m¬≤)',
                        f'√Årea efectiva de almacenamiento (m¬≤) - {porcentaje_almacenamiento*100:.0f}%',
                        '√Årea de pasillo (m¬≤)',
                        '√Årea de rack + pasillo (m¬≤)',
                        'Pallets por rack'
                    ],
                    'Valor': [
                        round(volumen_pallet, 3),
                        pallets_por_nivel,
                        round(area_bay, 2),
                        round(area_rack, 2),
                        round(area_bodega_total, 2),
                        round(area_efectiva_almacenamiento, 2),
                        round(area_pasillo, 2),
                        round(area_rack_pasillo, 2),
                        pallets_por_rack
                    ]
                })
                st.dataframe(calculos_df, use_container_width=True)

                
                # -------------------------------
                # Tabla previa de preparaci√≥n (solicitada)
                # -------------------------------
                st.subheader("üìã Tabla base previa (detalle limpio)")
                base_pre = base.copy()
                base_pre['MesyA√±o'] = base_pre['Fecha'].dt.to_period('M').astype(str)
                # Volumen por unidad: cuidar divisiones por 0
                base_pre['Volumen por unidad'] = (base_pre['Volumen_m3'] / base_pre['Unidades'].replace(0, np.nan)).fillna(0)
                tabla_previa = base_pre[['NumDoc','Articulo','Unidades','Cajas_vendidas','Unidades_por_caja','Fecha','Volumen_m3','MesyA√±o','Volumen por unidad']].copy()
                tabla_previa.columns = ['Num. Doc','Art√≠culo','Unid. Vend','Cajas vend.','Cant x caja','Fecha Doc','Volumen total (p3)','MesyA√±o','Volumen por unidad']
                st.dataframe(tabla_previa, use_container_width=True)

                # -------------------------------
                # An√°lisis de Inventario por SKU (Art√≠culo)
                # -------------------------------
                st.subheader("üìã An√°lisis por SKU (Art√≠culo)")

                # Utilidades
                SCORES = {
                "A": 0.99,
                "B": 0.90,
                "C": 0.75
                }

                def calcular_csl(categoria):
                    if not isinstance(categoria, str):
                        return 0.70
                    valores = [SCORES.get(letra, 0.70) for letra in categoria] # Define un score por cada letra, y el CSL de la combinaci√≥n es el promedio
                    return round(sum(valores) / len(valores), 2)


                def calcular_z_score(csl):
                    from scipy.stats import norm
                    return float(norm.ppf(csl))
                
                def calcular_safety_stock(demanda_promedio, desviacion, z_score, lead_time=1):
                    return z_score * desviacion * np.sqrt(lead_time)
                
                # 1) Tabla mensual de Unidades por SKU
                base_mes = base.copy()
                base_mes['YearMonth'] = base_mes['Fecha'].dt.to_period('M').astype(str)
                pivot_mes = pd.pivot_table(
                    base_mes,
                    index='Articulo',
                    columns='YearMonth',
                    values='Unidades',
                    aggfunc='sum',
                    fill_value=0
                )
                # ordenar columnas cronol√≥gicamente
                pivot_mes = pivot_mes.reindex(sorted(pivot_mes.columns), axis=1)

                # 2) C√°lculos por SKU: totales y estad√≠sticas de demanda
                totales = base.groupby('Articulo').agg(
                    unidades_totales=('Unidades','sum'),
                    volumen_total=('Volumen_m3','sum')
                )
                vol_por_unidad = (totales['volumen_total'] / totales['unidades_totales'].replace(0, np.nan)).fillna(0)

                # Unidades por caja por SKU: usar la moda (valor m√°s frecuente) de 'Cant x Caja'
                upc_series = pd.to_numeric(base['Unidades_por_caja'], errors='coerce')
                upc_por_sku = base.assign(Unidades_por_caja=upc_series).groupby('Articulo')['Unidades_por_caja'].agg(
                    lambda s: s.mode().iloc[0] if not s.mode().empty else s.dropna().iloc[0] if not s.dropna().empty else 1
                )
                upc_por_sku = upc_por_sku.fillna(1).replace(0, 1)

                # Mapear categor√≠a S√∫per ABC por SKU EXACTAMENTE como fue calculada (sin reordenar letras)
                # Usar by_item del session_state que contiene las categor√≠as ABC originales
                by_item_original = st.session_state['by_item']
                mapa_abc = by_item_original['Clase_SuperABC'].reindex(pivot_mes.index)
                # Filtrar solo SKUs que tienen clasificaci√≥n ABC v√°lida
                skus_con_abc = mapa_abc.dropna()
                pivot_mes_filtrado = pivot_mes.reindex(skus_con_abc.index)
                
                # Demanda promedio y desviaci√≥n: usar promedio mensual directo del pivote filtrado
                demanda_prom = pivot_mes_filtrado.mean(axis=1)
                # Desviaci√≥n muestral (como DESVEST.M en Excel)
                desviacion = pivot_mes_filtrado.std(axis=1, ddof=1).fillna(0)
                
                csl = skus_con_abc.apply(calcular_csl)
                z_vals = csl.apply(calcular_z_score)
                ss_vals = calcular_safety_stock(demanda_prom, desviacion, z_vals)
                inv_max = demanda_prom + ss_vals

                # Vol√∫menes y cajas (usar solo SKUs con ABC v√°lido)
                vol_por_caja = vol_por_unidad.reindex(skus_con_abc.index).fillna(0) * upc_por_sku.reindex(skus_con_abc.index).fillna(1)
                vol_total_unidades = inv_max * vol_por_unidad.reindex(skus_con_abc.index).fillna(0)
                cant_cajas = np.ceil(inv_max / upc_por_sku.reindex(skus_con_abc.index).replace(0, 1))
                vol_total_cajas = cant_cajas * vol_por_caja

                # Construir tabla final por SKU (solo con SKUs que tienen ABC)
                sku_df = pivot_mes_filtrado.copy()
                sku_df['Total general'] = pivot_mes_filtrado.sum(axis=1)
                sku_df['Demanda promedio'] = demanda_prom.round(2)
                sku_df['Desviaci√≥n'] = desviacion.round(2)
                sku_df['ABC'] = skus_con_abc
                sku_df['CSL'] = csl
                sku_df['Z'] = z_vals.round(2)
                sku_df['ss'] = ss_vals.round(2)
                sku_df['Inventario m√°ximo'] = inv_max.round(2)
                sku_df['Volumen por unidad (m¬≥)'] = vol_por_unidad.reindex(skus_con_abc.index).fillna(0).round(4)
                sku_df['Volumen Total (unidades, m¬≥)'] = vol_total_unidades.round(2)
                sku_df['Unidades por caja'] = upc_por_sku.reindex(skus_con_abc.index).fillna(1).astype(int)
                sku_df['Cantidad de cajas'] = cant_cajas.astype(int)
                sku_df['Volumen por caja (m¬≥)'] = vol_por_caja.round(4)
                sku_df['Volumen Total (cajas, m¬≥)'] = vol_total_cajas.round(2)

                st.dataframe(sku_df.reset_index(), use_container_width=True)

                # Totales generales previos a demanda: sumar meses, Total general y Volumen Total (cajas)
                totales_previos = {
                    'Total general (unidades)': float(sku_df['Total general'].sum()),
                    'Volumen Total (cajas, m¬≥)': float(sku_df['Volumen Total (cajas, m¬≥)'].sum())
                }
                st.write('Totales generales:', {k: round(v, 2) for k, v in totales_previos.items()})
                
                # -------------------------------
                # Tabla de Vol√∫menes por Categor√≠a (antes de racks)
                # -------------------------------
                st.subheader("üìä Vol√∫menes por Categor√≠a ABC")
                
                # Agregar vol√∫menes por categor√≠a (sku_df ya est√° filtrado por ABC v√°lido)
                vol_por_categoria = sku_df.groupby('ABC')['Volumen Total (cajas, m¬≥)'].sum().sort_index()
                vol_total_general = vol_por_categoria.sum()
                
                tabla_volumenes = pd.DataFrame({
                    'Suma de Volumen Total': vol_por_categoria,
                    'Porcentaje del Total': (vol_por_categoria / vol_total_general * 100)
                }).round(4)

                # % agrupado por primera letra
                tabla_volumenes['Primera_Letra'] = tabla_volumenes.index.astype(str).str[0]
                pct_grouped = (tabla_volumenes.groupby('Primera_Letra')['Porcentaje del Total'].sum()).round(4)
                tabla_volumenes['Porcentaje agrupado'] = tabla_volumenes['Primera_Letra'].map(pct_grouped)

                # A√±adir Total General
                total_row = pd.DataFrame({
                    'Suma de Volumen Total': [vol_total_general],
                    'Porcentaje del Total': [100.0],
                    'Porcentaje agrupado': [pct_grouped.sum()]
                }, index=['Total General'])
                tabla_mostrar = pd.concat([tabla_volumenes[['Suma de Volumen Total', 'Porcentaje del Total', 'Porcentaje agrupado']].round(2), total_row], axis=0)
                tabla_mostrar.index.name = 'Etiquetas de fila'
                st.dataframe(tabla_mostrar, use_container_width=True)

                st.dataframe(vol_por_categoria.to_frame('Volumen Total (cajas)').round(2), use_container_width=True)
                
                # -------------------------------
                # C√°lculo de Racks Necesarios
                # -------------------------------
                st.subheader("üèóÔ∏è C√°lculo de Racks Necesarios")
                
                # Crear tabla de racks por categor√≠a usando los vol√∫menes ya calculados
                racks_categorias = pd.DataFrame({'VolumenTotal_m3': vol_por_categoria})
                racks_categorias.index.name = 'Clase_SuperABC'
                
                # C√°lculos paso a paso 
                racks_categorias['Pallets_Necesarios'] = np.ceil(racks_categorias['VolumenTotal_m3'] / volumen_pallet)
                racks_categorias['Equivalente_en_Niveles'] = racks_categorias['Pallets_Necesarios'] / pallets_por_nivel
                racks_categorias['Equivalente_en_Bays'] = racks_categorias['Equivalente_en_Niveles'] / niveles
                racks_categorias['Equivalente_en_Racks'] = racks_categorias['Equivalente_en_Bays'] / bays_por_rack
                
                # Calcular distribuci√≥n de racks en porcentaje respecto a racks redondeados (espacio no usado)
                total_racks = racks_categorias['Equivalente_en_Racks'].sum()
                if total_racks == 0:
                    racks_categorias['Distribucion_de_Racks_%'] = 0.0
                else:
                    racks_disponibles = np.ceil(total_racks)
                    racks_categorias['Distribucion_de_Racks_%'] = (racks_categorias['Equivalente_en_Racks'] / racks_disponibles * 100).round(2)

                    # Calcular sobrante
                    sobrante_pct = 100 - racks_categorias['Distribucion_de_Racks_%'].sum()
                    if sobrante_pct > 0:
                        sobrante_row = pd.DataFrame({
                            'VolumenTotal_m3': [0],
                            'Pallets_Necesarios': [0],
                            'Equivalente_en_Niveles': [0],
                            'Equivalente_en_Bays': [0],
                            'Equivalente_en_Racks': [racks_disponibles - total_racks],
                            'Distribucion_de_Racks_%': [sobrante_pct]
                        }, index=['Sobrante'])
                        racks_categorias = pd.concat([racks_categorias, sobrante_row])

                # Mostrar tabla de racks
                st.dataframe(racks_categorias, use_container_width=True)
                
                # -------------------------------
                # Resumen de Distribuci√≥n
                # -------------------------------
                st.subheader("üìä Resumen de Distribuci√≥n")
                
                # Calcular m√©tricas de utilizaci√≥n
                racks_necesarios = np.ceil(racks_categorias['Pallets_Necesarios'].sum() / pallets_por_rack)
                area_en_uso = area_rack_pasillo * racks_necesarios
                utilizacion_espacio = (area_en_uso / area_efectiva_almacenamiento * 100).round(2)
                
                resumen_df = pd.DataFrame({
                    'M√©trica': [
                        'Racks necesarios total',
                        '√Årea en uso (m¬≤)',
                        'Utilizaci√≥n de espacio (%)'
                    ],
                    'Valor': [
                        int(racks_necesarios),
                        round(area_en_uso, 2),
                        utilizacion_espacio
                    ]
                })
                
                st.dataframe(resumen_df, use_container_width=True)
                
                # -------------------------------
                # Gr√°fico de Distribuci√≥n
                # -------------------------------
                st.subheader("üìä Gr√°fico de Distribuci√≥n de Racks por Categor√≠a")
                
                fig_distribucion = px.pie(
                    values=racks_categorias['Distribucion_de_Racks_%'],
                    names=racks_categorias.index,
                    title="Distribuci√≥n de Racks por Categor√≠a ABC"
                )
                st.plotly_chart(fig_distribucion, use_container_width=True)
                
                # -------------------------------
                # Guardar resultados en session_state
                # -------------------------------
                st.session_state['calculos_capacidad'] = calculos_df
                st.session_state['analisis_categorias'] = sku_df
                st.session_state['racks_categorias'] = racks_categorias
                st.session_state['resumen_distribucion'] = resumen_df               
                st.success("‚úÖ Distribuci√≥n de bodega calculada exitosamente!")


# =============================================================================
# SECCI√ìN DE DESCARGAS
# =============================================================================

from openpyxl import load_workbook
from openpyxl.chart import BarChart, Reference, PieChart, LineChart
from openpyxl.chart.axis import DateAxis, NumericAxis

st.markdown("---")
st.header("üì• Descargas y Exportaci√≥n")

with st.expander("üìä Descargar Resultados Completos", expanded=False):
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìà Perfiles de Actividad")
        if st.session_state.get('want_csv', True):
            if st.button("üì• Exportar perfiles a Excel"):
                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
                    # Hoja Portada primero
                    df_portada.to_excel(writer, sheet_name='Portada', index=False)

                    # Guardamos nombres de hojas para generar gr√°ficos luego
                    hoja_nombres = []

                    for key, df in st.session_state.items():
                        if key.startswith("perfil_") or key == "perfil_by_item":
                            hoja = key.replace("perfil_", "")[:30]  # hoja ‚â§ 31 chars
                            # ‚úÖ Si el DataFrame tiene √≠ndice con nombre, lo pasamos a columna
                            if df.index.name is not None:
                                df = df.reset_index()
                            df.to_excel(writer, sheet_name=hoja, index=False)
                            hoja_nombres.append((hoja, df))

                # Abrir libro para a√±adir gr√°ficos
                buffer.seek(0)
                wb = load_workbook(buffer)

                for hoja, df in hoja_nombres:
                    ws = wb[hoja]
                    chart = BarChart()  # default, lo cambiaremos seg√∫n hoja

                    # Selecci√≥n de datos seg√∫n tipo de hoja
                    if hoja.lower() in ["dias", "lineas", "carga", "cubicaje"]:
                        # Columna 1 = etiquetas, columna 2 = valores
                        data = Reference(ws, min_col=2, min_row=1, max_row=ws.max_row)
                        cats = Reference(ws, min_col=1, min_row=2, max_row=ws.max_row)
                        chart.add_data(data, titles_from_data=True)
                        chart.set_categories(cats)
                        chart.title = f"Gr√°fico {hoja}"
                        chart.y_axis.title = "Cantidad"
                        chart.x_axis.title = "Categor√≠a"
                        ws.add_chart(chart, "H5")  # colocar gr√°fico a la derecha
                    elif hoja.lower() == "pareto":
                        chart = LineChart()
                        chart.title = "Pareto de Picks"
                        chart.style = 10  # estilo opcional
                        chart.legend = None  # sin leyenda
                        
                        # Datos Y = cum_pct_picks (columna C)
                        data = Reference(ws, min_col=3, min_row=2, max_row=ws.max_row)
                        chart.add_data(data, titles_from_data=False)
                        
                        # Eje X = pct_sku (columna E)
                        cats = Reference(ws, min_col=5, min_row=2, max_row=ws.max_row)
                        chart.set_categories(cats)
                        
                        # Etiquetas de ejes
                        chart.x_axis.title = "% acumulado de SKU"
                        chart.y_axis.title = "% acumulado de Picks"
                        
                        # Configurar l√≠neas de graduaci√≥n cada 10%
                        chart.x_axis.majorUnit = 10
                        chart.x_axis.minorUnit = 5
                        chart.y_axis.majorUnit = 10
                        chart.y_axis.minorUnit = 5
                        
                        # Posici√≥n del gr√°fico en la hoja
                        ws.add_chart(chart, "H5")
                    else:
                        continue  # saltar hojas no reconocidas
                    
                # Guardar cambios
                buffer = io.BytesIO()
                wb.save(buffer)
                buffer.seek(0)

                st.download_button(
                    "üìä Descargar Excel con perfiles",
                    data=buffer.getvalue(),
                    file_name="perfiles_distribuciones.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
        else:
            st.info("No hay perfiles generados para descargar. Marca la opci√≥n 'Generar Excel' y vuelve a calcular.")
    with col2:
        st.subheader("üèóÔ∏è Distribuci√≥n de Bodega")
        if st.session_state.get('want_csv', True):
            if st.button("üì• Exportar an√°lisis de bodega", key="download_warehouse"):
                if 'analisis_categorias' in st.session_state:
                    buffer = io.BytesIO()
                    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
                        # Hoja An√°lisis por SKU
                        st.session_state['analisis_categorias'].to_excel(writer, sheet_name='Analisis_SKU', index=True)
                        
                        # Hoja C√°lculos de Capacidad
                        if 'calculos_capacidad' in st.session_state:
                            st.session_state['calculos_capacidad'].to_excel(writer, sheet_name='Calculos_Capacidad', index=True)
                    
                        # Hoja Racks por Categor√≠a
                        if 'racks_categorias' in st.session_state:
                            st.session_state['racks_categorias'].to_excel(writer, sheet_name='Distribucion_Racks', index=True)
                        
                        # Hoja Resumen de Distribuci√≥n
                        if 'resumen_distribucion' in st.session_state:
                            st.session_state['resumen_distribucion'].to_excel(writer, sheet_name='Resumen_Distribucion', index=False)


                    from openpyxl import load_workbook
                    # üîπ Cargar el libro desde el mismo buffer
                    buffer.seek(0)
                    wb = load_workbook(buffer)

                    from openpyxl.chart import PieChart, Reference
                    from openpyxl.chart.label import DataLabelList


                    # üîπ Insertar gr√°fico en hoja Distribucion_Racks
                    if 'Distribucion_Racks' in wb.sheetnames:
                        ws2 = wb['Distribucion_Racks']
                        chart2 = PieChart()
                        labels2 = Reference(ws2, min_col=1, min_row=2, max_row=ws2.max_row)  # categor√≠as
                        data2 = Reference(ws2, min_col=7, min_row=1, max_row=ws2.max_row)    # columna con % racks
                        chart2.add_data(data2, titles_from_data=True)
                        chart2.set_categories(labels2)
                        chart2.title = "Distribuci√≥n de Racks por Categor√≠a"
                        chart2.dataLabels = DataLabelList()
                        chart2.dataLabels.showVal = True      # Muestra valores
                        chart2.dataLabels.showPercent = True  # (opcional) muestra % en vez de valores
                        chart2.dataLabels.showCatName = True  # (opcional) muestra nombre de categor√≠a
                        ws2.add_chart(chart2, "H5")  # posici√≥n del gr√°fico

                    # üîπ Guardar de nuevo en buffer
                    new_buffer = io.BytesIO()
                    wb.save(new_buffer)
                    new_buffer.seek(0)

                    st.download_button(
                        "üì• Descargar Excel de Bodega",
                        data=new_buffer.getvalue(),
                        file_name='distribucion_bodega.xlsx',
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )

                else:
                    st.warning("Primero debes calcular la distribuci√≥n de bodega")

with st.expander("üìÑ Reportes PDF", expanded=False):
    # -------------------------------
    # Generar PDF completo robusto y profesional (mejorado)
    # -------------------------------
    if st.session_state.get('gen_pdf', False):
        if not PDF_LIBS_AVAILABLE:
            st.error('Para generar PDFs instala: pip install reportlab matplotlib')
        else:
            if st.button('4) Generar informe PDF'):
                from reportlab.lib import colors
                from reportlab.platypus import TableStyle, Image, PageBreak
                from reportlab.pdfgen import canvas
                from reportlab.lib.units import cm, mm
                from reportlab.platypus import BaseDocTemplate, Frame, PageTemplate
                import io, matplotlib.pyplot as plt

                # --- Pie de p√°gina con numeraci√≥n
                def add_page_number(canvas, doc):
                    page_num = canvas.getPageNumber()
                    text = f"P√°gina {page_num}"
                    canvas.setFont('Helvetica', 8)
                    canvas.drawRightString(200*mm, 10*mm, text)

                buffer = io.BytesIO()
                doc = BaseDocTemplate(
                    buffer,
                    pagesize=letter,
                    rightMargin=25, leftMargin=25,
                    topMargin=25, bottomMargin=18
                )
                frame = Frame(doc.leftMargin, doc.bottomMargin,
                            doc.width, doc.height, id='normal')
                template = PageTemplate(id='with-number',
                                        frames=frame,
                                        onPage=add_page_number)
                doc.addPageTemplates([template])

                styles = getSampleStyleSheet()
                elems = []

                # -------------------------------
                # Encabezado
                # -------------------------------
                elems.append(Paragraph('üìä Informe de An√°lisis - S√∫per ABC & Perfiles', styles['Title']))
                elems.append(Spacer(1, 14))

                # -------------------------------
                # Texto explicativo inicial
                # -------------------------------
                intro_text = """
                <b>Clasificaci√≥n de zonas de bodega:</b><br/>
                - <b>Zona Oro (Close to door, close to floor):</b> √Årea de mayor valor, ubicada estrat√©gicamente cerca de las puertas de entrada y salida de la bodega. Se destina a los productos de <b>alta rotaci√≥n</b>, minimizando tiempo de viaje y esfuerzo de los operarios.<br/>
                - <b>Zona Plata (Close to floor):</b> Ubicada a una distancia media de las puertas. Se utiliza para productos de <b>rotaci√≥n media</b>. El tiempo de acceso es moderado.<br/>
                - <b>Zona Bronce (Far from door, far from floor):</b> √Årea m√°s alejada de las puertas. Reservada para productos de <b>baja rotaci√≥n</b>. Aunque implica mayor tiempo de acceso, la baja frecuencia de movimiento lo justifica.<br/><br/>

                <b>Pol√≠ticas de inventario:</b><br/>
                - <b>ROP-OUL:</b> Reordenar al alcanzar el punto de pedido (ROP), con un l√≠mite superior (OUL) para evitar exceso de inventario.<br/>
                - <b>RTP-EOQ:</b> Pol√≠tica de revisi√≥n peri√≥dica (RTP), aplicando el tama√±o de lote econ√≥mico (EOQ) como cantidad √≥ptima de pedido.<br/>
                - <b>ROP-EOQ:</b> Pol√≠tica de reorden continuo (ROP), usando el EOQ como lote de reposici√≥n.<br/><br/>

                <b>Fill rate:</b> M√©trica de nivel de servicio que mide el porcentaje de demanda atendida en el primer intento con el inventario disponible. Un fill rate alto indica capacidad de satisfacer pedidos sin generar faltantes.<br/><br/>

                <b>IRA (Inventory Record Accuracy):</b> KPI que mide la exactitud del inventario, comparando los registros te√≥ricos del sistema con la realidad f√≠sica del stock disponible en un almac√©n. Un IRA alto indica que la informaci√≥n del sistema es confiable, lo que permite una gesti√≥n de inventarios m√°s eficiente, reduciendo p√©rdidas, excedentes y retrasos en los pedidos.  <br/><br/>

                <b>Recuento c√≠clico:</b> Estrategia de control de inventarios que consiste en revisar y contar de forma peri√≥dica subgrupos de productos a lo largo del a√±o. Se enfoca m√°s en art√≠culos cr√≠ticos o de mayor rotaci√≥n (categor√≠a A o AA), garantizando precisi√≥n de inventario sin necesidad de inventarios generales completos.
                """

                elems.append(Paragraph(intro_text, styles['Normal']))
                elems.append(Spacer(1, 14))

                # -------------------------------
                # Datos generales
                # -------------------------------
                file_name = st.session_state.get('file_name', uploaded_file.name if uploaded_file else 'Archivo no registrado')
                sheet_used = st.session_state.get('sheet_name', sheet_name or 'Hoja no registrada')
                vol_units = st.session_state.get('vol_units', unit_vol)
                criterios_usados = st.session_state.get('criterios_seleccionados', [crit1, crit2])
                cortes_abc = st.session_state.get('cortes_abc', {})
                
                # Para compatibilidad con c√≥digo existente
                crit1 = criterios_usados[0] if criterios_usados else 'Popularidad'
                crit2 = criterios_usados[1] if len(criterios_usados) > 1 else criterios_usados[0] if criterios_usados else 'Ventas'
                
                # Obtener cortes de la nueva estructura
                A_cut_1 = cortes_abc.get(crit1, {}).get('A', 0.8) if cortes_abc else 0.8
                B_cut_1 = cortes_abc.get(crit1, {}).get('B', 0.95) if cortes_abc else 0.95
                A_cut_2 = cortes_abc.get(crit2, {}).get('A', 0.8) if cortes_abc else 0.8
                B_cut_2 = cortes_abc.get(crit2, {}).get('B', 0.95) if cortes_abc else 0.95

                general_info = f"""
                <b>Documento le√≠do:</b> {file_name}<br/>
                <b>Hoja utilizada:</b> {sheet_used}<br/>
                <b>Unidades de volumen:</b> {vol_units}<br/>
                <b>Criterios utilizados:</b> {', '.join(criterios_usados)}<br/>
                """
                
                # Agregar cortes para cada criterio
                for criterio in criterios_usados:
                    if criterio in cortes_abc:
                        general_info += f"<b>Corte A ({criterio}):</b> {cortes_abc[criterio]['A']*100:.1f}%<br/>"
                        general_info += f"<b>Corte B ({criterio}):</b> {cortes_abc[criterio]['B']*100:.1f}%<br/>"
                elems.append(Paragraph(general_info, styles['Normal']))
                elems.append(Spacer(1, 12))

                by_item = st.session_state['by_item']
                base = st.session_state['base']

                # -------------------------------
                # Tabla resumen Super ABC (columnas compactas)
                # -------------------------------
                summary_table = by_item.groupby('Clase_SuperABC').agg(
                    Cantidad=('Clase_SuperABC','count'),
                    Zona_Bodega=('Zona_Bodega','first'),
                    Politica=('Pol√≠tica_Inv','first'),
                    FillRate=('FillRate_obj','first'),
                    Frecuencia_Recuento=('Frecuencia_Recuento','first'),
                    Ventas=('ventas','sum')
                ).reset_index()

                summary_table['Porcentaje'] = (summary_table['Cantidad']/summary_table['Cantidad'].sum()*100).round(2)
                total_sales = summary_table['Ventas'].sum()
                summary_table['% Ventas'] = (100 * summary_table['Ventas'] / (total_sales if total_sales>0 else 1)).round(2)
                summary_table['Ventas'] = summary_table['Ventas'].round(2)

                # üëâ Definir IRA seg√∫n categor√≠a usando la nueva funci√≥n
                summary_table['IRA'] = summary_table['Clase_SuperABC'].apply(ira_by_class)

                # Reordenar columnas para poner IRA despu√©s de FillRate
                cols = list(summary_table.columns)
                insert_pos = cols.index('FillRate') + 1
                cols = cols[:insert_pos] + ['IRA'] + cols[insert_pos:-1]  # dejamos % Ventas al final
                summary_table = summary_table[cols]

                # preparar datos y anchos
                data = [list(summary_table.columns)] + summary_table.round(2).astype(str).values.tolist()
                col_widths = []
                for col in summary_table.columns:
                    if col in ['Cantidad','Zona_Bodega','FillRate','IRA']:
                        col_widths.append(45)
                    elif col in ['Ventas','Porcentaje','% Ventas']:
                        col_widths.append(50)
                    elif col in ['Clase_SuperABC','Frecuencia_Recuento']:
                        col_widths.append(70)
                    else:
                        col_widths.append(97)

                t = Table(data, colWidths=col_widths, hAlign='CENTER')
                t.setStyle(TableStyle([
                    ('GRID', (0,0), (-1,-1), 0.5, colors.black),
                    ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),
                    ('FONTSIZE', (0,0), (-1,-1), 7),
                    ('ALIGN',(0,0),(-1,-1),'CENTER')
                ]))
                elems.append(Paragraph('üìë Resumen por categor√≠a (AA..CC)', styles['Heading2']))
                elems.append(t)
                elems.append(PageBreak())

                # -------------------------------
                # Funci√≥n auxiliar para a√±adir figuras
                # -------------------------------
                def add_fig(fig, title='', width=450, height=240):
                    img_buf = io.BytesIO()
                    fig.tight_layout()
                    fig.savefig(img_buf, format='png', dpi=130)
                    plt.close(fig)
                    img_buf.seek(0)
                    elems.append(Paragraph(title, styles['Heading3']))
                    elems.append(Image(img_buf, width=width, height=height))
                    elems.append(Spacer(1, 12))
                # -------------------------------
                # Gr√°fica Pareto
                # -------------------------------

                pareto = by_item.sort_values('popularidad', ascending=False).copy()
                pareto['cum_picks'] = pareto['popularidad'].cumsum()
                total_picks = pareto['popularidad'].sum()
                pareto['cum_pct_picks'] = 100*pareto['cum_picks']/(total_picks if total_picks>0 else 1)
                pareto['pct_sku'] = 100 * np.arange(1,len(pareto)+1)/len(pareto)
                fig1, ax1 = plt.subplots(figsize=(6,3))
                ax1.plot(pareto['pct_sku'], pareto['cum_pct_picks'], marker='o')
                ax1.set_xlabel('% SKU (acumulado)')
                ax1.set_ylabel('% picks (acumulado)')
                ax1.set_title('Distribuci√≥n de popularidad')
                add_fig(fig1, 'Pareto de popularidad')
                            
                pareto_intro = """
                Este perfil muestra qu√© porcentaje acumulado de los movimientos de picking corresponde a qu√© porcentaje acumulado de SKUs seg√∫n el principio de Pareto (muchos triviales, pocos vitales). 
                Permite identificar los productos que concentran la mayor parte de la actividad y que deben recibir prioridad en la bodega.
                """
                elems.append(Paragraph(pareto_intro, styles['Normal']))
                elems.append(Spacer(1, 6))

                elems.append(PageBreak())

                # -------------------------------
                # L√≠neas por orden
                # -------------------------------
                lines_per_order = base.groupby('NumDoc').agg(lineas=('Articulo','nunique')).reset_index()
                dist_lines = lines_per_order.groupby('lineas').size().rename('conteo').reset_index()
                total_orders = dist_lines['conteo'].sum()
                dist_lines['%_ordenes'] = 100*dist_lines['conteo']/(total_orders if total_orders>0 else 1)
                fig2, ax2 = plt.subplots(figsize=(6,3))
                ax2.bar(dist_lines['lineas'].astype(str), dist_lines['%_ordenes'])
                ax2.set_xlabel('L√≠neas por orden')
                ax2.set_ylabel('% de √≥rdenes')
                ax2.set_title('Distribuci√≥n de l√≠neas por orden')
                add_fig(fig2, 'L√≠neas por orden')
                
                lines_intro = """
                Este perfil muestra cu√°ntas l√≠neas (SKUs distintos) tiene cada pedido y qu√© porcentaje de √≥rdenes corresponde a cada cantidad de l√≠neas. 
                Permite evaluar la complejidad de los pedidos y planificar recursos de picking y personal.
                """
                elems.append(Paragraph(lines_intro, styles['Normal']))
                elems.append(Spacer(1, 6))
                elems.append(PageBreak())

                # -------------------------------
                # Cubicaje por orden
                # -------------------------------

                cubic_per_order = base.groupby('NumDoc').agg(volumen_total=('Volumen_m3','sum')).reset_index()
                vol_bins = [-1,1,2,5,10,20,50,1e9]
                vol_labels = ['‚â§1','1-2','2-5','5-10','10-20','20-50','>50']
                cubic_per_order['vol_bin'] = pd.cut(cubic_per_order['volumen_total'], bins=vol_bins, labels=vol_labels)
                dist_cubic = cubic_per_order.groupby('vol_bin').size().rename('conteo').reset_index()
                total_orders2 = dist_cubic['conteo'].sum()
                dist_cubic['%_ordenes'] = 100*dist_cubic['conteo']/(total_orders2 if total_orders2>0 else 1)
                fig3, ax3 = plt.subplots(figsize=(6,3))
                ax3.bar(dist_cubic['vol_bin'].astype(str), dist_cubic['%_ordenes'])
                ax3.set_xlabel('Rango volumen (pies¬≥)')
                ax3.set_ylabel('% de √≥rdenes')
                ax3.set_title('Distribuci√≥n de volumen por orden')
                add_fig(fig3, 'Volumen por orden')

                cubic_intro = """
                El presente perfil ilustra mediante una gr√°fica el rango de volumen total de los pedidos y su porcentaje sobre el total de √≥rdenes. 
                Es √∫til para dimensionar espacio de almacenamiento, cajas, pallets y veh√≠culos de transporte, seg√∫n requerimientos de espacio y rotaci√≥n.
                """
                elems.append(Paragraph(cubic_intro, styles['Normal']))
                elems.append(Spacer(1, 6))
                elems.append(PageBreak())

                # Recalcular lv y dist_incremento para el PDF
                lv = base.groupby('NumDoc').agg(
                    lineas=('Articulo','nunique'),
                    volumen_total=('Volumen_m3','sum')
                ).reset_index()

                VOLUMEN_TARIMA = st.session_state.get('vol_tarima', 42.38)
                lv['%_carga_unidad'] = 100 * lv['volumen_total'] / VOLUMEN_TARIMA
                lv['%_carga_unidad'] = lv['%_carga_unidad'].clip(upper=100)
                carga_bins = list(range(0, 105, 5))
                carga_labels = [f'{i}-{i+5}%' for i in range(0, 100, 5)]
                lv['r_carga'] = pd.cut(lv['%_carga_unidad'], bins=carga_bins, labels=carga_labels, right=True, include_lowest=True)
                dist_incremento = lv.groupby(['r_carga']).agg(
                    pedidos=('NumDoc', 'count'),
                    lineas_prom=('lineas', 'mean')
                ).reset_index()
                dist_incremento['%_lineas_pedido'] = 100 * dist_incremento['pedidos'] / dist_incremento['pedidos'].sum()

                # Gr√°fica de incremento de pedidos (carga unitaria vs % l√≠neas de pedido)
                fig_inc, ax_inc = plt.subplots(figsize=(6,3))
                ax_inc.bar(dist_incremento['r_carga'].astype(str), dist_incremento['%_lineas_pedido'])
                ax_inc.set_xlabel('% de carga unitaria (tarima)')
                ax_inc.set_ylabel('% de l√≠neas de pedido')
                ax_inc.set_title('Distribuci√≥n por incremento de pedidos')
                plt.setp(ax_inc.get_xticklabels(), rotation=60, ha='right', fontsize=7)  # Rota y reduce fuente
                add_fig(fig_inc, 'Distribuci√≥n por incremento de pedidos')

                inc_intro = """
                Esta gr√°fica muestra la proporci√≥n de l√≠neas de pedido seg√∫n el porcentaje de carga unitaria (por ejemplo, respecto a una tarima completa).
                Permite visualizar cu√°ntos pedidos representan cargas parciales o completas, facilitando la planificaci√≥n log√≠stica y el uso eficiente de espacio.
                """
                elems.append(Paragraph(inc_intro, styles['Normal']))
                elems.append(Spacer(1, 6))
                elems.append(PageBreak())

                # -------------------------------
                # Distribuci√≥n por d√≠a de la semana
                # -------------------------------

                orders_dates = base.groupby('NumDoc').agg(fecha=('Fecha','max')).reset_index()
                orders_dates['dia'] = orders_dates['fecha'].dt.day_name()
                mapping_days = {'Monday':'Lunes','Tuesday':'Martes','Wednesday':'Mi√©rcoles','Thursday':'Jueves',
                                'Friday':'Viernes','Saturday':'S√°bado','Sunday':'Domingo'}
                orders_dates['dia'] = orders_dates['dia'].replace(mapping_days)
                day_order = ['Lunes','Martes','Mi√©rcoles','Jueves','Viernes','S√°bado','Domingo']
                dist_days = orders_dates.groupby('dia').size().reindex(day_order).fillna(0).astype(int).rename('conteo').reset_index()
                dist_days['%_ordenes'] = 100*dist_days['conteo']/dist_days['conteo'].sum()
                fig4, ax4 = plt.subplots(figsize=(6,3))
                ax4.bar(dist_days['dia'], dist_days['%_ordenes'])
                ax4.set_xlabel('D√≠a')
                ax4.set_ylabel('% de √≥rdenes')
                ax4.set_title('Distribuci√≥n de √≥rdenes por d√≠a de la semana')
                add_fig(fig4, '√ìrdenes por d√≠a de la semana')

                days_intro = """
                Este perfil muestra c√≥mo se distribuyen los pedidos a lo largo de la semana y su porcentaje sobre el total. 
                Permite planificar personal, turnos y recursos log√≠sticos en funci√≥n de los picos y valles de demanda, identificando qu√© d√≠as presentan mayor ingreso de √≥rdenes.
                """
                elems.append(Paragraph(days_intro, styles['Normal']))
                elems.append(PageBreak())

                # -------------------------------
                # Tabla cruzada l√≠neas x volumen con % pedidos, Totales y Total L√≠nea
                # -------------------------------

                lv = base.groupby('NumDoc').agg(
                    lineas=('Articulo','nunique'),
                    volumen_total=('Volumen_m3','sum')
                ).reset_index()

                # Definir rangos (misma l√≥gica que en Streamlit)
                line_labels = ['1','2-5','6-9','10+']
                vol_labels2 = ['0-1','1-2','2-5','5-10','10-20','20+']

                # Categorizar (igual que en la app)
                lv['r_lineas'] = pd.cut(lv['lineas'], bins=[0,1,5,9,1e9], labels=line_labels, right=True, include_lowest=True)
                lv['r_vol'] = pd.cut(lv['volumen_total'], bins=[0,1,2,5,10,20,1e9], labels=vol_labels2, right=True, include_lowest=True)

                # Conteos y totales
                ct_counts = pd.crosstab(lv['r_lineas'], lv['r_vol'], dropna=False)
                ct_counts = ct_counts.reindex(index=line_labels, columns=vol_labels2, fill_value=0)
                ct_counts['Totales'] = ct_counts.sum(axis=1)

                # üîπ Total de l√≠neas (sumando l√≠neas, no volumen)
                pivot_lines = pd.pivot_table(
                    lv, index='r_lineas',
                    values='lineas', aggfunc='sum', fill_value=0
                ).reindex(index=line_labels, fill_value=0)
                pivot_lines['% linea'] = (pivot_lines['lineas'] / pivot_lines['lineas'].sum() * 100).round(2)

                # Volumen total (solo para fila de "Espacio total")
                pivot_vol = pd.pivot_table(
                    lv, index='r_lineas', columns='r_vol',
                    values='volumen_total', aggfunc='sum', fill_value=0
                ).reindex(index=line_labels, columns=vol_labels2, fill_value=0).round(2)

                # Construir tabla combinada
                data_cross = []

                # Encabezado combinado
                data_cross.append(
                    ['L√≠neas por orden'] 
                    + ['Volumen por pedido (pies¬≥)']*len(vol_labels2) 
                    + ['Totales','% pedidos','Total L√≠nea','% l√≠nea']
                )
                data_cross.append(
                    [''] + vol_labels2 + ['Totales','% pedidos','Total L√≠nea','% l√≠nea']
                )

                # Filas por r_lineas
                for idx in line_labels:
                    row_counts = ct_counts.loc[idx, vol_labels2].tolist()
                    row_total = ct_counts.loc[idx, 'Totales']
                    row_pct_pedidos = (row_total / ct_counts['Totales'].sum() * 100).round(2)
                    row_total_linea = int(pivot_lines.loc[idx, 'lineas'])  # üîπ ahora es la suma de l√≠neas
                    row_pct_linea = float(pivot_lines.loc[idx, '% linea'])
                    data_cross.append([idx] + row_counts + [row_total, row_pct_pedidos, row_total_linea, row_pct_linea])

                # üëâ Fila de Totales
                tot_row_counts = ct_counts[vol_labels2].sum().tolist()
                tot_total = ct_counts['Totales'].sum()
                tot_pct_pedidos = 100.0
                tot_total_linea = int(pivot_lines['lineas'].sum())  # üîπ total l√≠neas global
                tot_pct_linea = 100.0
                data_cross.append(['Totales'] + tot_row_counts + [tot_total, tot_pct_pedidos, tot_total_linea, tot_pct_linea])

                # Fila de % pedidos (por columna de volumen + total)
                pct_pedidos_cols = (ct_counts[vol_labels2].sum() / ct_counts['Totales'].sum() * 100).round(2).tolist()
                pct_pedidos_total = round(sum(pct_pedidos_cols), 2)
                row_pct_pedidos = ['% pedidos'] + pct_pedidos_cols + [pct_pedidos_total, '', '', '']
                data_cross.append(row_pct_pedidos)

                # Fila de volumen total por columna
                vol_values = pivot_vol[vol_labels2].sum().round(2).tolist()
                row_vol_total = ['Espacio total'] + vol_values + [pivot_vol.values.sum().round(2), '', '', '']
                data_cross.append(row_vol_total)

                # Configurar tabla PDF
                col_widths_cross = [50] + [50]*len(vol_labels2) + [50,50,50,50]
                t_cross = Table(data_cross, colWidths=col_widths_cross, hAlign='CENTER')
                t_cross.setStyle(TableStyle([
                    ('SPAN',(1,0),(len(vol_labels2),0)),  # unir fila 0 columnas de volumen
                    ('SPAN',(len(vol_labels2)+1,0),(len(vol_labels2)+1,1)),  # Totales
                    ('SPAN',(len(vol_labels2)+2,0),(len(vol_labels2)+2,1)),  # % pedidos
                    ('SPAN',(len(vol_labels2)+3,0),(len(vol_labels2)+3,1)),  # Total L√≠nea
                    ('SPAN',(len(vol_labels2)+4,0),(len(vol_labels2)+4,1)),  # % l√≠nea
                    ('GRID',(0,0),(-1,-1),0.5,colors.black),
                    ('BACKGROUND',(0,0),(-1,1),colors.lightgrey),
                    ('BACKGROUND',(0,-3),(-1,-3),colors.lightgrey),  # Totales fila
                    ('BACKGROUND',(0,-2),(-1,-2),colors.whitesmoke),  # % pedidos
                    ('BACKGROUND',(0,-1),(-1,-1),colors.whitesmoke),  # espacio total
                    ('FONTSIZE',(0,0),(-1,-1),6),
                    ('ALIGN',(0,0),(-1,-1),'CENTER'),
                    ('VALIGN',(0,0),(-1,-1),'MIDDLE')
                ]))
                elems.append(Paragraph('Tabla cruzada: l√≠neas por orden vs volumen', styles['Heading2']))
                cross_intro = """
                Permite ver cu√°ntos pedidos combinan cierta cantidad de l√≠neas con un rango de volumen determinado, 
                junto con totales, porcentaje de pedidos y porcentaje de l√≠neas. 
                Esto ayuda a identificar combinaciones de pedidos frecuentes o cr√≠ticas y optimizar la disposici√≥n de la bodega y flujos de picking.
                """
                elems.append(Paragraph(cross_intro, styles['Normal']))
                elems.append(Spacer(1, 6))
                elems.append(t_cross)
                elems.append(Spacer(1, 10))


                # -------------------------------
                # Construir PDF
                # -------------------------------
                doc.build(elems)
                buffer.seek(0)
                st.download_button(
                    'üìÑ Descargar Informe PDF',
                    data=buffer.getvalue(),
                    file_name='informe_super_abc_completo.pdf',
                    mime='application/pdf'
                )
            else:
                st.info("Haz clic en el bot√≥n para generar el informe PDF.")
    else:
        st.warning("Habilita 'Generar informe PDF' en la configuraci√≥n del sidebar para usar esta funci√≥n.")

st.success('C√°lculos finalizados. Ajusta cortes y vuelve a calcular seg√∫n necesites.')

# =============================
# WMS y posiciones del almac√©n
# =============================
st.header('WMS y Posiciones del Almac√©n')

# Inicializar variables en session_state si no existen
if 'posiciones_filtradas' not in st.session_state:
    st.session_state['posiciones_filtradas'] = pd.DataFrame()
if 'registro_movimientos' not in st.session_state:
    st.session_state['registro_movimientos'] = pd.DataFrame(columns=[
        "Tipo", "Art√≠culo", "Camas", "Cajas", "Rack Origen", "Cuerpo Origen", "Nivel Origen", "Posici√≥n Origen",
        "Rack Destino", "Cuerpo Destino", "Nivel Destino", "Posici√≥n Destino"
    ])

# =============================
# Carga del archivo de posiciones
# =============================
uploaded_positions = st.file_uploader("Cargar archivo de posiciones del almac√©n", type=["xlsx"])
if uploaded_positions:
    xls = pd.ExcelFile(uploaded_positions)
    hojas = xls.sheet_names
    hoja_seleccionada = st.selectbox("Selecciona la hoja a cargar", hojas)
    
    if hoja_seleccionada:
        columnas_necesarias = ['Rack', 'Cuerpo', 'Nivel', 'Posici√≥n', 'Zona', 'Art√≠culo', 'Camas', 'Cajas']
        posiciones = pd.read_excel(uploaded_positions, sheet_name=hoja_seleccionada, usecols=columnas_necesarias)
        st.success(f"Hoja '{hoja_seleccionada}' cargada correctamente")

        # Limpieza b√°sica
        posiciones['Art√≠culo'] = posiciones['Art√≠culo'].astype(str).str.strip().str.upper()
        posiciones['Nivel'] = pd.to_numeric(posiciones['Nivel'], errors='coerce').fillna(0).astype(int)
        posiciones['Posici√≥n'] = posiciones['Posici√≥n'].astype(str).fillna('')
        
        # Separar m√∫ltiples SKUs por fila
        posiciones['Art√≠culos_lista'] = posiciones['Art√≠culo'].str.split(' - ')

        # Filtrar racks y niveles relevantes
        posiciones_filtradas = posiciones[
            ((posiciones['Rack'] == 1) & (posiciones['Nivel'].isin([1,2,3,4,5]))) |
            ((posiciones['Rack'] == 2) & (posiciones['Nivel'].isin([1,2,3,4,5])))
        ].copy()
        
        st.session_state['posiciones_filtradas'] = posiciones_filtradas
        st.write("Posiciones del almac√©n:")
        st.dataframe(posiciones_filtradas)

# =============================
# Verificar correspondencia con S√∫per ABC
# =============================
if 'by_item' in st.session_state and not st.session_state['posiciones_filtradas'].empty:
    by_item = st.session_state['by_item']
    posiciones_filtradas = st.session_state['posiciones_filtradas']

    articulos_posiciones = set([sku for sublist in posiciones_filtradas['Art√≠culos_lista'] for sku in sublist])
    articulos_by_item = set(by_item.index)
    articulos_faltantes = articulos_posiciones - articulos_by_item - {"", "VAC√çO"}
    if articulos_faltantes:
        st.warning(f"‚ö†Ô∏è Los siguientes art√≠culos en posiciones no est√°n en el S√∫per ABC: {articulos_faltantes}")
    else:
        st.success("‚úÖ Todos los art√≠culos en posiciones tienen correspondencia en el S√∫per ABC.")

# =============================
# Funci√≥n para determinar zona por SKU
# =============================
zonas_prioridad = {'Oro': 3, 'Plata': 2, 'Bronce': 1, 'MP': 0}

def zona_ideal_sku(sku):
    sku = sku.strip().upper()
    if sku in ["", "VAC√çO"]:
        return None  # vac√≠os no se consideran
    if sku in by_item.index:
        zona = by_item.loc[sku, 'Zona_Bodega']
        return zona if pd.notna(zona) else 'Bronce'
    return 'MP'

def zona_prioritaria_fila(articulos):
    """
    Determina la zona prioritaria de una fila (tarima) con m√∫ltiples SKUs,
    ignorando vac√≠os. Retorna None si todos son vac√≠os.
    """
    skus = [sku.strip().upper() for sku in articulos if sku.strip().upper() not in ["", "VAC√çO"]]
    if not skus:
        return None
    zonas = [zona_ideal_sku(sku) for sku in skus if zona_ideal_sku(sku) is not None]
    if not zonas:
        return None
    zonas_sorted = sorted(zonas, key=lambda z: zonas_prioridad.get(z,0), reverse=True)
    return zonas_sorted[0]

# =============================
# Reubicaci√≥n autom√°tica de tarimas
# =============================
if not st.session_state['posiciones_filtradas'].empty:
    posiciones_filtradas = st.session_state['posiciones_filtradas'].copy()
    posiciones_filtradas['Zona_Ideal_Fila'] = posiciones_filtradas['Art√≠culos_lista'].apply(zona_prioritaria_fila)

    # Filas mal ubicadas (ignorando vac√≠os)
    mal_ubicadas = posiciones_filtradas[
        (posiciones_filtradas['Zona'] != posiciones_filtradas['Zona_Ideal_Fila']) &
        (posiciones_filtradas['Zona_Ideal_Fila'].notna())
    ].copy()

    if not mal_ubicadas.empty:
        mal_ubicadas['Ubicaci√≥n_Actual'] = mal_ubicadas.apply(
            lambda r: f"Rack {r['Rack']}, Cuerpo {r['Cuerpo']}, Nivel {r['Nivel']}, Posici√≥n {r['Posici√≥n']}", axis=1
        )
        st.subheader("üìä Filas mal ubicadas")
        st.dataframe(mal_ubicadas[['Art√≠culos_lista','Zona','Zona_Ideal_Fila','Ubicaci√≥n_Actual']])
        # -----------------------------
        # Gr√°fica de filas mal ubicadas por zona (excluyendo MP)
        # -----------------------------
        # Filtrar MP y contar por la zona actual
        conteo_zonas = mal_ubicadas[mal_ubicadas['Zona'] != 'MP']['Zona'].value_counts().reindex(['Oro','Plata','Bronce'], fill_value=0).reset_index()
        conteo_zonas.columns = ['Zona', 'Filas Mal Ubicadas']

        # Colores fijos
        colores = {'Oro': '#FFD700', 'Plata': '#C0C0C0', 'Bronce': '#CD7F32'}

        fig = px.bar(
            conteo_zonas,
            x='Zona',
            y='Filas Mal Ubicadas',
            color='Zona',
            color_discrete_map=colores,
            text='Filas Mal Ubicadas',
            title="Filas mal ubicadas por Zona (Oro, Plata, Bronce)"
        )
        fig.update_layout(showlegend=False)
        st.plotly_chart(fig)

        posiciones_reconfiguradas = posiciones_filtradas.copy()

        for idx, fila in mal_ubicadas.iterrows():
            zona_objetivo = fila['Zona_Ideal_Fila']

            # Buscar slots vac√≠os en la zona objetivo (priorizar niveles bajos y cuerpos cercanos)
            vacios = posiciones_reconfiguradas[
                (posiciones_reconfiguradas['Art√≠culo'].str.upper().isin(["", "VAC√çO"])) &
                (posiciones_reconfiguradas['Zona'] == zona_objetivo)
            ].sort_values(by=['Nivel', 'Cuerpo', 'Rack', 'Posici√≥n'])

            if not vacios.empty:
                slot = vacios.iloc[0]
                # Mover tarima completa
                posiciones_reconfiguradas.loc[slot.name, ['Art√≠culo','Camas','Cajas']] = \
                    [fila['Art√≠culo'], fila['Camas'], fila['Cajas']]
                posiciones_reconfiguradas.loc[idx, ['Art√≠culo','Camas','Cajas']] = ["VAC√çO", np.nan, np.nan]
            else:
                # fallback a zonas de menor prioridad (tambi√©n priorizando niveles bajos)
                prioridad_actual = zonas_prioridad[zona_objetivo]
                for z, p in sorted(zonas_prioridad.items(), key=lambda x: -x[1]):
                    if p < prioridad_actual:
                        vacios_alt = posiciones_reconfiguradas[
                            (posiciones_reconfiguradas['Art√≠culo'].str.upper().isin(["", "VAC√çO"])) &
                            (posiciones_reconfiguradas['Zona'] == z)
                        ].sort_values(by=['Nivel', 'Cuerpo', 'Rack', 'Posici√≥n'])
                        if not vacios_alt.empty:
                            slot = vacios_alt.iloc[0]
                            posiciones_reconfiguradas.loc[slot.name, ['Art√≠culo','Camas','Cajas']] = \
                                [fila['Art√≠culo'], fila['Camas'], fila['Cajas']]
                            posiciones_reconfiguradas.loc[idx, ['Art√≠culo','Camas','Cajas']] = ["VAC√çO", np.nan, np.nan]
                            break

        st.subheader("üîÑ Reubicaci√≥n recomendada")
        st.dataframe(posiciones_reconfiguradas)

        # =============================
        # Secci√≥n para descarga de resultados
        # =============================
        from io import BytesIO
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            posiciones_reconfiguradas.to_excel(writer, index=False, sheet_name='Posiciones')

        output.seek(0)  # mover el cursor al inicio del archivo

        st.download_button(
            label="üì• Descargar posiciones reconfiguradas",
            data=output,
            file_name='posiciones_reconfiguradas.xlsx',
            mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )


    import pandas as pd
    from openpyxl import load_workbook

    def guardar_configuracion_y_movimientos(posiciones, movimientos, archivo_salida="almacen_actualizado.xlsx"):
        """
        Guarda la configuraci√≥n actual del almac√©n y los movimientos realizados en un archivo Excel.

        Args:
            posiciones (pd.DataFrame): DataFrame con la configuraci√≥n actual del almac√©n.
            movimientos (pd.DataFrame): DataFrame con el registro de movimientos realizados.
            archivo_salida (str): Nombre del archivo Excel de salida.

        Returns:
            str: Ruta del archivo Excel generado.
        """
        with pd.ExcelWriter(archivo_salida, engine="openpyxl") as writer:
            # Guardar la configuraci√≥n actual del almac√©n
            posiciones.to_excel(writer, sheet_name="Configuraci√≥n Actual", index=False)

            # Guardar el registro de movimientos
            movimientos.to_excel(writer, sheet_name="Registro de Movimientos", index=False)

        return archivo_salida

    # Registro de movimientos
    st.subheader("üìã Registro de Movimientos")

    # Selecci√≥n del tipo de movimiento
    tipo_movimiento = st.selectbox("Tipo de movimiento", ["Ingreso", "Salida", "Traslado"])

    # Datos comunes para todos los movimientos
    articulo = st.text_input("C√≥digo del art√≠culo")
    camas = st.number_input("Camas", min_value=0, step=1)
    cajas = st.number_input("Cajas", min_value=0, step=1)

    # Crear un DataFrame para registrar los movimientos
    if "registro_movimientos" not in st.session_state:
        st.session_state["registro_movimientos"] = pd.DataFrame(columns=[
            "Tipo", "Art√≠culo", "Camas", "Cajas", "Rack Origen", "Cuerpo Origen", "Nivel Origen", "Posici√≥n Origen",
            "Rack Destino", "Cuerpo Destino", "Nivel Destino", "Posici√≥n Destino"
        ])

    registro_movimientos = st.session_state["registro_movimientos"]

    if tipo_movimiento == "Ingreso":
        # Mostrar ubicaciones sugeridas antes de registrar el ingreso
        if articulo in by_item.index:
            prioridad_actual = by_item.loc[articulo, 'Clase_SuperABC']
            zona_prioridad = map_zone(prioridad_actual)

            # Filtrar posiciones disponibles seg√∫n la zona de prioridad
            disponibles = posiciones_filtradas[posiciones_filtradas['Art√≠culo'].isna()]
            if zona_prioridad == 'Oro':
                sugerencias = disponibles[
                    (disponibles['Rack'] == 1) &
                    (disponibles['Cuerpo'].isin([1, 2])) &
                    (disponibles['Nivel'].isin([1, 2]))
                ]
            elif zona_prioridad == 'Plata':
                sugerencias = disponibles[
                    (disponibles['Cuerpo'].isin([3, 4, 5])) &
                    (disponibles['Nivel'].isin([1, 2]))
                ]
            else:  # Bronce
                sugerencias = disponibles[
                    (disponibles['Nivel'] == 3)
                ]

            if sugerencias.empty:
                st.warning(f"No se encontraron ubicaciones disponibles para el art√≠culo '{articulo}' en la zona {zona_prioridad}.")
            else:
                st.write(f"üìç Ubicaciones sugeridas para el art√≠culo '{articulo}' (Zona: {zona_prioridad}):")
                st.dataframe(sugerencias.head(5))  # Mostrar las primeras 5 sugerencias

        # Datos espec√≠ficos para ingreso
        rack = st.number_input("Rack (destino)", min_value=1, step=1)
        cuerpo = st.number_input("Cuerpo (destino)", min_value=1, step=1)
        nivel = st.number_input("Nivel (destino)", min_value=1, max_value=5, step=1)
        posicion = st.text_input("Posici√≥n (destino, ej. I1, C1, D1)")

        if st.button("Registrar Ingreso"):
            # Verificar si la ubicaci√≥n est√° disponible
            ubicacion_disponible = posiciones_filtradas[
                (posiciones_filtradas['Rack'] == rack) &
                (posiciones_filtradas['Cuerpo'] == cuerpo) &
                (posiciones_filtradas['Nivel'] == nivel) &
                (posiciones_filtradas['Posici√≥n'] == posicion) &
                (posiciones_filtradas['Art√≠culo'].isna())
            ]

            if not ubicacion_disponible.empty:
                st.success(f"Ingreso registrado: {articulo} - Rack {rack}, Cuerpo {cuerpo}, Nivel {nivel}, Posici√≥n {posicion}, Camas {camas}, Cajas {cajas}")
                # Actualizar la ubicaci√≥n en el DataFrame
                posiciones_filtradas.loc[
                    (posiciones_filtradas['Rack'] == rack) &
                    (posiciones_filtradas['Cuerpo'] == cuerpo) &
                    (posiciones_filtradas['Nivel'] == nivel) &
                    (posiciones_filtradas['Posici√≥n'] == posicion),
                    ['Art√≠culo', 'Camas', 'Cajas']
                ] = [articulo, camas, cajas]

                # Registrar el movimiento
                nuevo_movimiento = pd.DataFrame([{
                    "Tipo": "Ingreso",
                    "Art√≠culo": articulo,
                    "Camas": camas,
                    "Cajas": cajas,
                    "Rack Origen": None,
                    "Cuerpo Origen": None,
                    "Nivel Origen": None,
                    "Posici√≥n Origen": None,
                    "Rack Destino": rack,
                    "Cuerpo Destino": cuerpo,
                    "Nivel Destino": nivel,
                    "Posici√≥n Destino": posicion
                }])

                registro_movimientos = pd.concat([registro_movimientos, nuevo_movimiento], ignore_index=True)
                st.session_state["registro_movimientos"] = registro_movimientos

                # Guardar la configuraci√≥n y los movimientos en un archivo Excel
                archivo_actualizado = guardar_configuracion_y_movimientos(posiciones_filtradas, registro_movimientos)
                st.success("Archivo actualizado con el movimiento registrado.")
                with open(archivo_actualizado, "rb") as file:
                    st.download_button(
                        label="üì• Descargar archivo actualizado",
                        data=file,
                        file_name=archivo_actualizado,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
            else:
                st.error("La ubicaci√≥n seleccionada no est√° disponible. Por favor, selecciona una de las ubicaciones sugeridas.")

    import json

    def guardar_estado_json():
        """
        Guarda el estado completo de la aplicaci√≥n en un archivo JSON.
        """
        estado = {
            "posiciones_filtradas": posiciones_filtradas.to_dict() if 'posiciones_filtradas' in locals() else None,
            "registro_movimientos": registro_movimientos.to_dict() if 'registro_movimientos' in locals() else None,
            "criterios_seleccionados": st.session_state.get("criterios_seleccionados", []),
            "cortes_abc": st.session_state.get("cortes_abc", {}),
            "by_item": st.session_state.get("by_item", {}).to_dict() if "by_item" in st.session_state else None,
            "ubicaciones_clasificacion": st.session_state.get("ubicaciones_clasificacion", {}).to_dict() if "ubicaciones_clasificacion" in st.session_state else None
        }
        with open("estado_app.json", "w") as f:
            json.dump(estado, f)
        st.success("Estado guardado correctamente.")

    def cargar_estado_json():
        """
        Carga el estado completo de la aplicaci√≥n desde un archivo JSON.
        """
        global posiciones_filtradas, registro_movimientos
        try:
            with open("estado_app.json", "r") as f:
                estado = json.load(f)
            
            # Restaurar los datos en las variables globales y session_state
            if estado.get("posiciones_filtradas"):
                posiciones_filtradas = pd.DataFrame.from_dict(estado["posiciones_filtradas"])
            if estado.get("registro_movimientos"):
                registro_movimientos = pd.DataFrame.from_dict(estado["registro_movimientos"])
            st.session_state["criterios_seleccionados"] = estado.get("criterios_seleccionados", [])
            st.session_state["cortes_abc"] = estado.get("cortes_abc", {})
            if estado.get("by_item"):
                st.session_state["by_item"] = pd.DataFrame.from_dict(estado["by_item"])
            if estado.get("ubicaciones_clasificacion"):
                st.session_state["ubicaciones_clasificacion"] = pd.DataFrame.from_dict(estado["ubicaciones_clasificacion"])
            
            st.success("Estado cargado correctamente.")
        except FileNotFoundError:
            st.warning("No se encontr√≥ un archivo de estado previo. Inicia desde cero.")
        except Exception as e:
            st.error(f"Error al cargar el estado: {e}")

if st.button("Cargar estado previo"):
    cargar_estado_json()

if st.button("Guardar estado actual"):
    guardar_estado_json()
